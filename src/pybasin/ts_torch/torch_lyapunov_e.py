# pyright: basic
"""PyTorch implementation of Eckmann algorithm for multiple Lyapunov exponents.

This module provides GPU-accelerated computation of multiple Lyapunov exponents
using the Eckmann algorithm, vectorized for batch processing.

Reference:
    J. P. Eckmann, S. O. Kamphorst, D. Ruelle, and S. Ciliberto,
    "Liapunov exponents from time series," Physical Review A,
    vol. 34, no. 6, pp. 4971-4979, 1986.
"""

import torch
from torch import Tensor

from pybasin.ts_torch.torch_feature_utilities import delay_embedding


@torch.no_grad()
def lyap_e_single(
    data: Tensor,
    emb_dim: int = 10,
    matrix_dim: int = 4,
    min_nb: int = 8,
    min_tsep: int = 0,
    tau: float = 1.0,
) -> Tensor:
    """Compute multiple Lyapunov exponents for a single 1D time series.

    :param data: 1D time series tensor of shape (N,) where N is the number of time points.
    :param emb_dim: Embedding dimension (must satisfy (emb_dim-1) % (matrix_dim-1) == 0).
        Determines the phase space reconstruction dimension. Default is 10.
    :param matrix_dim: Matrix dimension for Jacobian estimation (number of exponents to compute).
        Default is 4.
    :param min_nb: Minimal number of neighbors required for reliable estimation. Default is 8.
    :param min_tsep: Minimal temporal separation between neighbors (to avoid spurious correlations).
        Default is 0.
    :param tau: Time step size for normalization of the exponents. Default is 1.0.
    :return: Tensor of shape (matrix_dim,) containing the Lyapunov exponents sorted from largest
        to smallest. Returns inf values for unbounded/divergent trajectories or when computation fails.
    """
    # Handle unbounded trajectories
    if not torch.all(torch.isfinite(data)):
        return torch.full((matrix_dim,), float("inf"), dtype=data.dtype, device=data.device)

    m = (emb_dim - 1) // (matrix_dim - 1)

    # Build orbit (delay embedding)
    orbit = delay_embedding(data[:-m], emb_dim, lag=1)
    n_orbit = len(orbit)

    old_q = torch.eye(matrix_dim, device=data.device, dtype=data.dtype)
    lexp = torch.zeros(matrix_dim, device=data.device, dtype=data.dtype)
    lexp_counts = torch.zeros(matrix_dim, device=data.device, dtype=data.dtype)

    # Pre-compute stepped data
    step_offsets = torch.arange(matrix_dim, device=data.device) * m
    stepped_data = data[
        torch.arange(n_orbit, device=data.device).unsqueeze(1) + step_offsets.unsqueeze(0)
    ]
    beta_data = data[torch.arange(n_orbit, device=data.device) + matrix_dim * m]

    all_indices = torch.arange(n_orbit, device=data.device)

    for i in range(n_orbit):
        # Compute Chebyshev distances
        diffs = torch.max(torch.abs(orbit - orbit[i]), dim=1).values
        diffs[i] = float("inf")

        # Temporal masking
        time_mask = torch.abs(all_indices - i) <= min_tsep
        diffs = torch.where(time_mask, torch.tensor(float("inf"), device=data.device), diffs)

        # Find neighbors
        sorted_diffs, _ = torch.sort(diffs)
        r = sorted_diffs[min_nb - 1]

        if torch.isinf(r):
            continue

        neighbor_mask = diffs <= r
        n_neighbors = neighbor_mask.sum()

        if n_neighbors < min_nb:
            continue

        # Build least squares matrices
        orbit_i_stepped = stepped_data[i]
        beta_i = beta_data[i]

        x_diff = stepped_data - orbit_i_stepped
        beta_diff = beta_data - beta_i

        # Apply neighbor mask
        x_masked = x_diff[neighbor_mask]
        beta_masked = beta_diff[neighbor_mask]

        # Solve least squares using normal equations
        xtx = x_masked.T @ x_masked + 1e-10 * torch.eye(
            matrix_dim, device=data.device, dtype=data.dtype
        )
        xty = x_masked.T @ beta_masked

        try:
            a = torch.linalg.solve(xtx, xty)
        except RuntimeError:
            continue

        # Build T matrix
        t_mat = torch.zeros((matrix_dim, matrix_dim), device=data.device, dtype=data.dtype)
        t_mat[:-1, 1:] = torch.eye(matrix_dim - 1, device=data.device, dtype=data.dtype)
        t_mat[-1, :] = a

        # QR decomposition
        mat_q, mat_r = torch.linalg.qr(t_mat @ old_q)

        # Force positive diagonal
        sign_diag = torch.sign(torch.diag(mat_r))
        sign_diag = torch.where(sign_diag == 0, torch.ones_like(sign_diag), sign_diag)
        mat_q = mat_q @ torch.diag(sign_diag)
        mat_r = torch.diag(sign_diag) @ mat_r

        old_q = mat_q

        # Accumulate Lyapunov exponents
        diag_r = torch.diag(mat_r)
        pos_mask = diag_r > 0
        lexp[pos_mask] += torch.log(diag_r[pos_mask])
        lexp_counts[pos_mask] += 1

    # Normalize
    valid_mask = lexp_counts > 0
    lexp[valid_mask] /= lexp_counts[valid_mask]
    lexp[~valid_mask] = float("inf")
    lexp /= tau
    lexp /= m

    return lexp


@torch.no_grad()
def lyap_e_batch(
    data: Tensor,
    emb_dim: int = 10,
    matrix_dim: int = 4,
    min_nb: int = 8,
    min_tsep: int = 0,
    tau: float = 1.0,
) -> Tensor:
    """Compute multiple Lyapunov exponents for batch of multi-state trajectories.

    This function processes multiple ODE solutions in parallel, computing Lyapunov exponents
    for each state variable of each initial condition independently.

    :param data: Trajectories tensor of shape (N, B, S) where:
        - N: number of time points in the trajectory
        - B: batch size (number of different initial conditions)
        - S: number of state variables in the dynamical system
    :param emb_dim: Embedding dimension for phase space reconstruction (must satisfy
        (emb_dim-1) % (matrix_dim-1) == 0). Default is 10.
    :param matrix_dim: Matrix dimension for Jacobian estimation, determines how many exponents
        to compute. Default is 4.
    :param min_nb: Minimal number of neighbors required for reliable estimation. Default is 8.
    :param min_tsep: Minimal temporal separation between neighbors. Default is 0.
    :param tau: Time step size for normalization. Default is 1.0.
    :return: Tensor of shape (B, S, matrix_dim) containing Lyapunov exponents. For each
        batch and state, returns matrix_dim exponents sorted from largest to smallest.
        Shape interpretation:
        - First dimension (B): corresponds to different initial conditions
        - Second dimension (S): corresponds to different state variables
        - Third dimension (matrix_dim): the Lyapunov exponents for that state/batch
    """
    n_time, batch_size, n_states = data.shape

    # Transpose to (B, S, N)
    data_transposed = data.permute(1, 2, 0)

    results = torch.zeros(batch_size, n_states, matrix_dim, device=data.device)

    for b in range(batch_size):
        for s in range(n_states):
            series = data_transposed[b, s]
            results[b, s] = lyap_e_single(series, emb_dim, matrix_dim, min_nb, min_tsep, tau)

    return results
