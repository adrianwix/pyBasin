{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pyBasin","text":"<p>Basin stability estimation for dynamical systems</p> <p> </p> <p>pyBasin is a Python library for estimating basin stability in dynamical systems. It's a port of the MATLAB bSTAB library with additional features including adaptive sampling and neural network-based classification.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Basin Stability Estimation: Calculate the probability that a system ends up in a specific attractor</li> <li>Adaptive Sampling: Intelligent sampling strategies that focus on uncertain regions</li> <li>Multiple Solvers: Support for various ODE solvers including neural ODE</li> <li>Visualization Tools: Built-in plotting utilities for basin stability results</li> <li>Extensible: Easy to add custom feature extractors and classifiers</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pybasin\n</code></pre> <p>For development:</p> <pre><code># Clone the repository\ngit clone https://github.com/adrianwix/pyBasin.git\ncd pyBasinWorkspace\n\n# Install with UV\nuv add -e \".[dev,docs]\"\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from pybasin import BasinStabilityEstimator, ODESystem\nimport numpy as np\n\n# Define your dynamical system\nclass MySystem(ODESystem):\n    def dynamics(self, t, state):\n        x, y = state\n        dx = -x + y\n        dy = -y - x**3\n        return np.array([dx, dy])\n\n    def classify_attractor(self, solution):\n        # Classify final state\n        final_state = solution.y[:, -1]\n        if np.linalg.norm(final_state) &lt; 0.1:\n            return 0  # Attractor 1\n        return 1  # Attractor 2\n\n# Create estimator\nsystem = MySystem()\nestimator = BasinStabilityEstimator(system)\n\n# Define sampling region\nbounds = [(-2, 2), (-2, 2)]  # x and y bounds\n\n# Estimate basin stability\nresults = estimator.estimate(bounds, n_samples=1000)\n\nprint(f\"Basin stability: {results.basin_stability}\")\nprint(f\"Attractor distribution: {results.attractor_counts}\")\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Full documentation is available at https://adrianwix.github.io/pyBasin/</p>"},{"location":"#case-studies","title":"Case Studies","text":"<p>This repository includes several case studies from the original bSTAB paper:</p> <ul> <li>Duffing Oscillator: Forced oscillator with two attractors</li> <li>Lorenz System: Classic chaotic system</li> <li>Pendulum: Forced pendulum with bifurcations</li> <li>Friction System: System with friction effects</li> </ul> <p>See the <code>case_studies/</code> directory for implementations.</p>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>pyBasinWorkspace/\n\u251c\u2500\u2500 src/pybasin/          # Main library code\n\u251c\u2500\u2500 case_studies/         # Research case studies\n\u251c\u2500\u2500 tests/                # Unit and integration tests\n\u251c\u2500\u2500 docs/                 # Documentation source\n\u251c\u2500\u2500 artifacts/            # Generated figures and results\n\u2514\u2500\u2500 notebooks/            # Jupyter notebook examples\n</code></pre>"},{"location":"#development","title":"Development","text":""},{"location":"#setup","title":"Setup","text":"<pre><code># Install all dependencies including dev tools\nuv add -e \".[all]\"\n</code></pre>"},{"location":"#running-tests","title":"Running Tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"#building-documentation","title":"Building Documentation","text":"<pre><code>mkdocs serve  # Local preview\nmkdocs build  # Build static site\n</code></pre>"},{"location":"#related-projects","title":"Related Projects","text":"<ul> <li>bSTAB: Original MATLAB implementation - GitHub</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use pyBasin in your research, please cite:</p> <pre><code>@software{pybasin2025,\n  author = {Wix, Adrian},\n  title = {pyBasin: Basin Stability Estimation for Dynamical Systems},\n  year = {2025},\n  url = {https://github.com/adrianwix/pyBasin}\n}\n</code></pre>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<ul> <li>Based on the bSTAB MATLAB library</li> <li>Part of a bachelor thesis on basin stability estimation</li> </ul>"},{"location":"macros/","title":"Macros","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"MkDocs macros for case study documentation.\n\nThis module provides macros for rendering comparison tables from JSON artifacts\nand loading code snippets from source files.\n\"\"\"\n</pre> \"\"\"MkDocs macros for case study documentation.  This module provides macros for rendering comparison tables from JSON artifacts and loading code snippets from source files. \"\"\" <p>pyright: reportUnknownMemberType=false, reportUnknownArgumentType=false pyright: reportUnknownVariableType=false, reportMissingTypeArgument=false</p> In\u00a0[\u00a0]: Copied! <pre>import ast\nimport json\nfrom pathlib import Path\nfrom typing import Any\n</pre> import ast import json from pathlib import Path from typing import Any In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport pandas as pd\nfrom scipy import stats as scipy_stats\n</pre> import numpy as np import pandas as pd from scipy import stats as scipy_stats In\u00a0[\u00a0]: Copied! <pre>ARTIFACTS_DIR = Path(__file__).parent.parent / \"artifacts\" / \"results\"\n</pre> ARTIFACTS_DIR = Path(__file__).parent.parent / \"artifacts\" / \"results\" In\u00a0[\u00a0]: Copied! <pre>Z_THRESHOLD_OK = 2.0\nZ_THRESHOLD_WARNING = 3.0\n</pre> Z_THRESHOLD_OK = 2.0 Z_THRESHOLD_WARNING = 3.0 In\u00a0[\u00a0]: Copied! <pre>def _format_bs_with_se(bs: float, se: float) -&gt; str:\n    \"\"\"Format basin stability with standard error.\"\"\"\n    return f\"{bs:.4f} \u00b1 {se:.4f}\"\n</pre> def _format_bs_with_se(bs: float, se: float) -&gt; str:     \"\"\"Format basin stability with standard error.\"\"\"     return f\"{bs:.4f} \u00b1 {se:.4f}\" In\u00a0[\u00a0]: Copied! <pre>def comparison_table(case_id: str) -&gt; str:\n    \"\"\"Render a comparison table from a JSON artifact.\n\n    For single-point tests, renders a table with columns:\n    Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 | MCC\n\n    For parameter sweep tests, adds a Parameter column first:\n    Parameter | Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 | MCC\n\n    For unsupervised tests, adds cluster quality metrics and purity column:\n    Attractor | DBSCAN | Purity | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 | MCC\n\n    For paper validation tests (no ground truth labels), shows confidence intervals:\n    Attractor | pyBasin BS \u00b1 SE | Paper BS \u00b1 SE | Difference | 95% CI | Status\n\n    Also shows overall Macro F1 and MCC in a summary section.\n\n    :param case_id: Case identifier (e.g., \"pendulum_case1\", \"pendulum_case2\").\n    :return: Markdown table string.\n    \"\"\"\n    json_path = ARTIFACTS_DIR / f\"{case_id}_comparison.json\"\n\n    if not json_path.exists():\n        return f'!!! warning \"Missing Data\"\\n    Comparison data not found: `{case_id}_comparison.json`\\n    Run tests with `--generate-artifacts` to generate.'\n\n    with open(json_path) as f:\n        data: dict[str, Any] = json.load(f)\n\n    # Detect paper validation case: attractors have f1_score == 0.0 (N/A)\n    is_paper_validation = False\n    if \"attractors\" in data:\n        attractors: list[dict[str, Any]] = data[\"attractors\"]\n        if attractors and attractors[0].get(\"f1_score\", 1.0) == 0.0:\n            is_paper_validation = True\n    elif \"parameter_results\" in data:\n        param_results: list[dict[str, Any]] = data[\"parameter_results\"]\n        if param_results and \"attractors\" in param_results[0]:\n            first_attractors: list[dict[str, Any]] = param_results[0][\"attractors\"]\n            if first_attractors and first_attractors[0].get(\"f1_score\", 1.0) == 0.0:\n                is_paper_validation = True\n\n    if is_paper_validation:\n        if \"parameter_results\" in data:\n            return _render_paper_validation_sweep_table(data)\n        return _render_paper_validation_table(data)\n\n    if \"parameter_results\" in data:\n        return _render_parameter_sweep_table(data)\n    if \"overall_agreement\" in data:\n        return _render_unsupervised_table(data)\n    return _render_single_point_table(data)\n</pre> def comparison_table(case_id: str) -&gt; str:     \"\"\"Render a comparison table from a JSON artifact.      For single-point tests, renders a table with columns:     Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 | MCC      For parameter sweep tests, adds a Parameter column first:     Parameter | Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 | MCC      For unsupervised tests, adds cluster quality metrics and purity column:     Attractor | DBSCAN | Purity | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 | MCC      For paper validation tests (no ground truth labels), shows confidence intervals:     Attractor | pyBasin BS \u00b1 SE | Paper BS \u00b1 SE | Difference | 95% CI | Status      Also shows overall Macro F1 and MCC in a summary section.      :param case_id: Case identifier (e.g., \"pendulum_case1\", \"pendulum_case2\").     :return: Markdown table string.     \"\"\"     json_path = ARTIFACTS_DIR / f\"{case_id}_comparison.json\"      if not json_path.exists():         return f'!!! warning \"Missing Data\"\\n    Comparison data not found: `{case_id}_comparison.json`\\n    Run tests with `--generate-artifacts` to generate.'      with open(json_path) as f:         data: dict[str, Any] = json.load(f)      # Detect paper validation case: attractors have f1_score == 0.0 (N/A)     is_paper_validation = False     if \"attractors\" in data:         attractors: list[dict[str, Any]] = data[\"attractors\"]         if attractors and attractors[0].get(\"f1_score\", 1.0) == 0.0:             is_paper_validation = True     elif \"parameter_results\" in data:         param_results: list[dict[str, Any]] = data[\"parameter_results\"]         if param_results and \"attractors\" in param_results[0]:             first_attractors: list[dict[str, Any]] = param_results[0][\"attractors\"]             if first_attractors and first_attractors[0].get(\"f1_score\", 1.0) == 0.0:                 is_paper_validation = True      if is_paper_validation:         if \"parameter_results\" in data:             return _render_paper_validation_sweep_table(data)         return _render_paper_validation_table(data)      if \"parameter_results\" in data:         return _render_parameter_sweep_table(data)     if \"overall_agreement\" in data:         return _render_unsupervised_table(data)     return _render_single_point_table(data) In\u00a0[\u00a0]: Copied! <pre>def _render_paper_validation_table(data: dict[str, Any]) -&gt; str:\n    \"\"\"Render table for paper validation (statistical comparison).\"\"\"\n    attractors: list[dict[str, Any]] = data.get(\"attractors\", [])\n\n    if not attractors:\n        return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'\n\n    # Table header\n    table_lines: list[str] = [\n        \"| Attractor | pyBasin BS \u00b1 SE | Paper BS \u00b1 SE | Difference | 95% CI | Status |\",\n        \"|-----------|-----------------|---------------|------------|--------|--------|\",\n    ]\n\n    for a in attractors:\n        python_bs: float = a[\"python_bs\"]\n        python_se: float = a[\"python_se\"]\n        matlab_bs: float = a[\"matlab_bs\"]\n        matlab_se: float = a[\"matlab_se\"]\n\n        python_str = _format_bs_with_se(python_bs, python_se)\n        matlab_str = _format_bs_with_se(matlab_bs, matlab_se)\n\n        # Compute difference and 95% confidence interval\n        diff = python_bs - matlab_bs\n        # For 95% confidence, z = 1.96\n        combined_se = (python_se**2 + matlab_se**2) ** 0.5\n        ci_margin = 1.96 * combined_se\n\n        # Check if difference is within CI (difference should contain 0)\n        within_ci = abs(diff) &lt;= ci_margin\n        status = \"\u2713\" if within_ci else \"\u2717\"\n\n        diff_str = f\"{diff:+.4f}\"\n        ci_str = f\"\u00b1{ci_margin:.4f}\"\n\n        table_lines.append(\n            f\"| {a['label']} | {python_str} | {matlab_str} | {diff_str} | {ci_str} | {status} |\"\n        )\n\n    return \"\\n\".join(table_lines)\n</pre> def _render_paper_validation_table(data: dict[str, Any]) -&gt; str:     \"\"\"Render table for paper validation (statistical comparison).\"\"\"     attractors: list[dict[str, Any]] = data.get(\"attractors\", [])      if not attractors:         return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'      # Table header     table_lines: list[str] = [         \"| Attractor | pyBasin BS \u00b1 SE | Paper BS \u00b1 SE | Difference | 95% CI | Status |\",         \"|-----------|-----------------|---------------|------------|--------|--------|\",     ]      for a in attractors:         python_bs: float = a[\"python_bs\"]         python_se: float = a[\"python_se\"]         matlab_bs: float = a[\"matlab_bs\"]         matlab_se: float = a[\"matlab_se\"]          python_str = _format_bs_with_se(python_bs, python_se)         matlab_str = _format_bs_with_se(matlab_bs, matlab_se)          # Compute difference and 95% confidence interval         diff = python_bs - matlab_bs         # For 95% confidence, z = 1.96         combined_se = (python_se**2 + matlab_se**2) ** 0.5         ci_margin = 1.96 * combined_se          # Check if difference is within CI (difference should contain 0)         within_ci = abs(diff) &lt;= ci_margin         status = \"\u2713\" if within_ci else \"\u2717\"          diff_str = f\"{diff:+.4f}\"         ci_str = f\"\u00b1{ci_margin:.4f}\"          table_lines.append(             f\"| {a['label']} | {python_str} | {matlab_str} | {diff_str} | {ci_str} | {status} |\"         )      return \"\\n\".join(table_lines) In\u00a0[\u00a0]: Copied! <pre>def _render_single_point_table(data: dict[str, Any]) -&gt; str:\n    \"\"\"Render table for single-point comparison.\"\"\"\n    attractors: list[dict[str, Any]] = data.get(\"attractors\", [])\n\n    if not attractors:\n        return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'\n\n    # Get overall metrics\n    macro_f1 = data.get(\"macro_f1\", 0.0)\n    mcc = data.get(\"matthews_corrcoef\", 0.0)\n\n    # Summary metrics\n    summary_lines: list[str] = [\n        \"**Overall Classification Quality:**\",\n        \"\",\n        f\"- Macro F1-score: {macro_f1:.4f}\",\n        f\"- Matthews Correlation Coefficient: {mcc:.4f}\",\n        \"\",\n    ]\n\n    # Attractor table\n    table_lines: list[str] = [\n        \"| Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 |\",\n        \"|-----------|-----------------|---------------|-----|\",\n    ]\n\n    for a in attractors:\n        python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])\n        matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])\n        f1_score: float = a[\"f1_score\"]\n\n        table_lines.append(f\"| {a['label']} | {python_str} | {matlab_str} | {f1_score:.4f} |\")\n\n    return \"\\n\".join(summary_lines + table_lines)\n</pre> def _render_single_point_table(data: dict[str, Any]) -&gt; str:     \"\"\"Render table for single-point comparison.\"\"\"     attractors: list[dict[str, Any]] = data.get(\"attractors\", [])      if not attractors:         return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'      # Get overall metrics     macro_f1 = data.get(\"macro_f1\", 0.0)     mcc = data.get(\"matthews_corrcoef\", 0.0)      # Summary metrics     summary_lines: list[str] = [         \"**Overall Classification Quality:**\",         \"\",         f\"- Macro F1-score: {macro_f1:.4f}\",         f\"- Matthews Correlation Coefficient: {mcc:.4f}\",         \"\",     ]      # Attractor table     table_lines: list[str] = [         \"| Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 |\",         \"|-----------|-----------------|---------------|-----|\",     ]      for a in attractors:         python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])         matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])         f1_score: float = a[\"f1_score\"]          table_lines.append(f\"| {a['label']} | {python_str} | {matlab_str} | {f1_score:.4f} |\")      return \"\\n\".join(summary_lines + table_lines) In\u00a0[\u00a0]: Copied! <pre>def _render_unsupervised_table(data: dict[str, Any]) -&gt; str:\n    \"\"\"Render table for unsupervised clustering comparison.\"\"\"\n    attractors: list[dict[str, Any]] = data.get(\"attractors\", [])\n\n    if not attractors:\n        return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'\n\n    # Cluster quality metrics summary\n    n_found = data.get(\"n_clusters_found\", 0)\n    n_expected = data.get(\"n_clusters_expected\", 0)\n    agreement = data.get(\"overall_agreement\", 0.0)\n    ari = data.get(\"adjusted_rand_index\", 0.0)\n    macro_f1 = data.get(\"macro_f1\", 0.0)\n    mcc = data.get(\"matthews_corrcoef\", 0.0)\n\n    summary_lines: list[str] = [\n        \"**Cluster Quality Metrics:**\",\n        \"\",\n        f\"- Clusters found: {n_found} (expected: {n_expected})\",\n        f\"- Overall agreement: {agreement:.1%}\",\n        f\"- Adjusted Rand Index: {ari:.4f}\",\n        f\"- Macro F1-score: {macro_f1:.4f}\",\n        f\"- Matthews Correlation Coefficient: {mcc:.4f}\",\n        \"\",\n    ]\n\n    # Attractor table with purity info\n    table_lines: list[str] = [\n        \"| Attractor | DBSCAN | Purity | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 |\",\n        \"|-----------|--------|--------|-----------------|---------------|-----|\",\n    ]\n\n    for a in attractors:\n        python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])\n        matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])\n        f1_score: float = a[\"f1_score\"]\n        dbscan_label = a.get(\"dbscan_label\", \"-\")\n        purity = a.get(\"purity\", 0.0)\n        purity_str = f\"{purity:.1%}\"\n\n        table_lines.append(\n            f\"| {a['label']} | {dbscan_label} | {purity_str} | {python_str} | {matlab_str} | {f1_score:.4f} |\"\n        )\n\n    return \"\\n\".join(summary_lines + table_lines)\n</pre> def _render_unsupervised_table(data: dict[str, Any]) -&gt; str:     \"\"\"Render table for unsupervised clustering comparison.\"\"\"     attractors: list[dict[str, Any]] = data.get(\"attractors\", [])      if not attractors:         return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'      # Cluster quality metrics summary     n_found = data.get(\"n_clusters_found\", 0)     n_expected = data.get(\"n_clusters_expected\", 0)     agreement = data.get(\"overall_agreement\", 0.0)     ari = data.get(\"adjusted_rand_index\", 0.0)     macro_f1 = data.get(\"macro_f1\", 0.0)     mcc = data.get(\"matthews_corrcoef\", 0.0)      summary_lines: list[str] = [         \"**Cluster Quality Metrics:**\",         \"\",         f\"- Clusters found: {n_found} (expected: {n_expected})\",         f\"- Overall agreement: {agreement:.1%}\",         f\"- Adjusted Rand Index: {ari:.4f}\",         f\"- Macro F1-score: {macro_f1:.4f}\",         f\"- Matthews Correlation Coefficient: {mcc:.4f}\",         \"\",     ]      # Attractor table with purity info     table_lines: list[str] = [         \"| Attractor | DBSCAN | Purity | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 |\",         \"|-----------|--------|--------|-----------------|---------------|-----|\",     ]      for a in attractors:         python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])         matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])         f1_score: float = a[\"f1_score\"]         dbscan_label = a.get(\"dbscan_label\", \"-\")         purity = a.get(\"purity\", 0.0)         purity_str = f\"{purity:.1%}\"          table_lines.append(             f\"| {a['label']} | {dbscan_label} | {purity_str} | {python_str} | {matlab_str} | {f1_score:.4f} |\"         )      return \"\\n\".join(summary_lines + table_lines) In\u00a0[\u00a0]: Copied! <pre>def _render_paper_validation_sweep_table(data: dict[str, Any]) -&gt; str:\n    \"\"\"Render table for paper validation parameter sweep (statistical comparison).\"\"\"\n    parameter_results: list[dict[str, Any]] = data.get(\"parameter_results\", [])\n\n    if not parameter_results:\n        return '!!! warning \"No Data\"\\n    No parameter data found in comparison.'\n\n    param_name: str = data.get(\"parameter_name\", \"Parameter\")\n    sections: list[str] = []\n\n    for result in parameter_results:\n        param_value: float | None = result.get(\"parameter_value\")\n        param_str = f\"{param_value:.4f}\" if param_value is not None else \"-\"\n\n        lines: list[str] = [\n            f\"#### {param_name} = {param_str}\",\n            \"\",\n            \"| Attractor | pyBasin BS \u00b1 SE | Paper BS \u00b1 SE | Difference | 95% CI | Status |\",\n            \"|-----------|-----------------|---------------|------------|--------|--------|\",\n        ]\n\n        attractors: list[dict[str, Any]] = result.get(\"attractors\", [])\n        for a in attractors:\n            python_bs: float = a[\"python_bs\"]\n            python_se: float = a[\"python_se\"]\n            matlab_bs: float = a[\"matlab_bs\"]\n            matlab_se: float = a[\"matlab_se\"]\n\n            python_str = _format_bs_with_se(python_bs, python_se)\n            matlab_str = _format_bs_with_se(matlab_bs, matlab_se)\n\n            # Compute difference and 95% confidence interval\n            diff = python_bs - matlab_bs\n            # For 95% confidence, z = 1.96\n            combined_se = (python_se**2 + matlab_se**2) ** 0.5\n            ci_margin = 1.96 * combined_se\n\n            # Check if difference is within CI (difference should contain 0)\n            within_ci = abs(diff) &lt;= ci_margin\n            status = \"\u2713\" if within_ci else \"\u2717\"\n\n            diff_str = f\"{diff:+.4f}\"\n            ci_str = f\"\u00b1{ci_margin:.4f}\"\n\n            lines.append(\n                f\"| {a['label']} | {python_str} | {matlab_str} | {diff_str} | {ci_str} | {status} |\"\n            )\n\n        sections.append(\"\\n\".join(lines))\n\n    return \"\\n\\n\".join(sections)\n</pre> def _render_paper_validation_sweep_table(data: dict[str, Any]) -&gt; str:     \"\"\"Render table for paper validation parameter sweep (statistical comparison).\"\"\"     parameter_results: list[dict[str, Any]] = data.get(\"parameter_results\", [])      if not parameter_results:         return '!!! warning \"No Data\"\\n    No parameter data found in comparison.'      param_name: str = data.get(\"parameter_name\", \"Parameter\")     sections: list[str] = []      for result in parameter_results:         param_value: float | None = result.get(\"parameter_value\")         param_str = f\"{param_value:.4f}\" if param_value is not None else \"-\"          lines: list[str] = [             f\"#### {param_name} = {param_str}\",             \"\",             \"| Attractor | pyBasin BS \u00b1 SE | Paper BS \u00b1 SE | Difference | 95% CI | Status |\",             \"|-----------|-----------------|---------------|------------|--------|--------|\",         ]          attractors: list[dict[str, Any]] = result.get(\"attractors\", [])         for a in attractors:             python_bs: float = a[\"python_bs\"]             python_se: float = a[\"python_se\"]             matlab_bs: float = a[\"matlab_bs\"]             matlab_se: float = a[\"matlab_se\"]              python_str = _format_bs_with_se(python_bs, python_se)             matlab_str = _format_bs_with_se(matlab_bs, matlab_se)              # Compute difference and 95% confidence interval             diff = python_bs - matlab_bs             # For 95% confidence, z = 1.96             combined_se = (python_se**2 + matlab_se**2) ** 0.5             ci_margin = 1.96 * combined_se              # Check if difference is within CI (difference should contain 0)             within_ci = abs(diff) &lt;= ci_margin             status = \"\u2713\" if within_ci else \"\u2717\"              diff_str = f\"{diff:+.4f}\"             ci_str = f\"\u00b1{ci_margin:.4f}\"              lines.append(                 f\"| {a['label']} | {python_str} | {matlab_str} | {diff_str} | {ci_str} | {status} |\"             )          sections.append(\"\\n\".join(lines))      return \"\\n\\n\".join(sections) In\u00a0[\u00a0]: Copied! <pre>def _render_parameter_sweep_table(data: dict[str, Any]) -&gt; str:\n    \"\"\"Render table for parameter sweep comparison.\"\"\"\n    parameter_results: list[dict[str, Any]] = data.get(\"parameter_results\", [])\n\n    if not parameter_results:\n        return '!!! warning \"No Data\"\\n    No parameter data found in comparison.'\n\n    param_name: str = data.get(\"parameter_name\", \"Parameter\")\n    sections: list[str] = []\n\n    for result in parameter_results:\n        param_value: float | None = result.get(\"parameter_value\")\n        param_str = f\"{param_value:.4f}\" if param_value is not None else \"-\"\n        macro_f1 = result.get(\"macro_f1\", 0.0)\n        mcc = result.get(\"matthews_corrcoef\", 0.0)\n\n        lines: list[str] = [\n            f\"#### {param_name} = {param_str}\",\n            \"\",\n            f\"**Macro F1:** {macro_f1:.4f} | **MCC:** {mcc:.4f}\",\n            \"\",\n            \"| Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 |\",\n            \"|-----------|-----------------|---------------|-----|\",\n        ]\n\n        attractors: list[dict[str, Any]] = result.get(\"attractors\", [])\n        for a in attractors:\n            python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])\n            matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])\n            f1_score: float = a[\"f1_score\"]\n\n            lines.append(f\"| {a['label']} | {python_str} | {matlab_str} | {f1_score:.4f} |\")\n\n        sections.append(\"\\n\".join(lines))\n\n    return \"\\n\\n\".join(sections)\n</pre> def _render_parameter_sweep_table(data: dict[str, Any]) -&gt; str:     \"\"\"Render table for parameter sweep comparison.\"\"\"     parameter_results: list[dict[str, Any]] = data.get(\"parameter_results\", [])      if not parameter_results:         return '!!! warning \"No Data\"\\n    No parameter data found in comparison.'      param_name: str = data.get(\"parameter_name\", \"Parameter\")     sections: list[str] = []      for result in parameter_results:         param_value: float | None = result.get(\"parameter_value\")         param_str = f\"{param_value:.4f}\" if param_value is not None else \"-\"         macro_f1 = result.get(\"macro_f1\", 0.0)         mcc = result.get(\"matthews_corrcoef\", 0.0)          lines: list[str] = [             f\"#### {param_name} = {param_str}\",             \"\",             f\"**Macro F1:** {macro_f1:.4f} | **MCC:** {mcc:.4f}\",             \"\",             \"| Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | F1 |\",             \"|-----------|-----------------|---------------|-----|\",         ]          attractors: list[dict[str, Any]] = result.get(\"attractors\", [])         for a in attractors:             python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])             matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])             f1_score: float = a[\"f1_score\"]              lines.append(f\"| {a['label']} | {python_str} | {matlab_str} | {f1_score:.4f} |\")          sections.append(\"\\n\".join(lines))      return \"\\n\\n\".join(sections) In\u00a0[\u00a0]: Copied! <pre>def load_snippet(spec: str) -&gt; str:\n    \"\"\"Load a code snippet from a source file.\n\n    :param spec: Specification in format \"path/to/file.py::function_name\"\n                 Path should be relative to the workspace root.\n    :return: Markdown-formatted code block with the extracted function.\n    \"\"\"\n    try:\n        file_path_str, func_name = spec.split(\"::\")\n    except ValueError:\n        return f'!!! error \"Invalid Format\"\\n    Expected format: `path/to/file.py::function_name`\\n    Got: `{spec}`'\n\n    workspace_root = Path(__file__).parent.parent\n    file_path = workspace_root / file_path_str\n\n    if not file_path.exists():\n        return f'!!! error \"File Not Found\"\\n    Could not find file: `{file_path_str}`'\n\n    try:\n        source_code = file_path.read_text()\n        tree = ast.parse(source_code)\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef) and node.name == func_name:\n                lines = source_code.splitlines()\n                start_line = node.lineno - 1\n                end_line = node.end_lineno if node.end_lineno else len(lines)\n\n                function_code = \"\\n\".join(lines[start_line:end_line])\n\n                return f\"```python\\n{function_code}\\n```\"\n\n        return f'!!! warning \"Function Not Found\"\\n    Could not find function `{func_name}` in `{file_path_str}`'\n\n    except SyntaxError as e:\n        return f'!!! error \"Syntax Error\"\\n    Failed to parse `{file_path_str}`: {e}'\n    except Exception as e:\n        return f'!!! error \"Error\"\\n    Failed to load snippet: {e}'\n</pre> def load_snippet(spec: str) -&gt; str:     \"\"\"Load a code snippet from a source file.      :param spec: Specification in format \"path/to/file.py::function_name\"                  Path should be relative to the workspace root.     :return: Markdown-formatted code block with the extracted function.     \"\"\"     try:         file_path_str, func_name = spec.split(\"::\")     except ValueError:         return f'!!! error \"Invalid Format\"\\n    Expected format: `path/to/file.py::function_name`\\n    Got: `{spec}`'      workspace_root = Path(__file__).parent.parent     file_path = workspace_root / file_path_str      if not file_path.exists():         return f'!!! error \"File Not Found\"\\n    Could not find file: `{file_path_str}`'      try:         source_code = file_path.read_text()         tree = ast.parse(source_code)          for node in ast.walk(tree):             if isinstance(node, ast.FunctionDef) and node.name == func_name:                 lines = source_code.splitlines()                 start_line = node.lineno - 1                 end_line = node.end_lineno if node.end_lineno else len(lines)                  function_code = \"\\n\".join(lines[start_line:end_line])                  return f\"```python\\n{function_code}\\n```\"          return f'!!! warning \"Function Not Found\"\\n    Could not find function `{func_name}` in `{file_path_str}`'      except SyntaxError as e:         return f'!!! error \"Syntax Error\"\\n    Failed to parse `{file_path_str}`: {e}'     except Exception as e:         return f'!!! error \"Error\"\\n    Failed to load snippet: {e}' In\u00a0[\u00a0]: Copied! <pre>BENCHMARK_RESULTS_DIR = Path(__file__).parent.parent / \"benchmarks\" / \"end_to_end\" / \"results\"\nSOLVER_COMPARISON_RESULTS_DIR = (\n    Path(__file__).parent.parent / \"benchmarks\" / \"solver_comparison\" / \"results\"\n)\n</pre> BENCHMARK_RESULTS_DIR = Path(__file__).parent.parent / \"benchmarks\" / \"end_to_end\" / \"results\" SOLVER_COMPARISON_RESULTS_DIR = (     Path(__file__).parent.parent / \"benchmarks\" / \"solver_comparison\" / \"results\" ) In\u00a0[\u00a0]: Copied! <pre>def solver_comparison_table() -&gt; str:\n    \"\"\"Render solver comparison table from CSV data.\n\n    :return: Markdown table string.\n    \"\"\"\n    csv_path = SOLVER_COMPARISON_RESULTS_DIR / \"solver_comparison.csv\"\n\n    if not csv_path.exists():\n        return '!!! warning \"Missing Data\"\\n    Solver comparison data not found. Run `uv run python benchmarks/solver_comparison/compare_matlab_vs_python.py` to generate.'\n\n    df = pd.read_csv(csv_path)\n\n    n_values = sorted(df[\"N\"].unique())\n    sections: list[str] = []\n\n    for n in n_values:\n        n_data = df[df[\"N\"] == n].sort_values(\"mean_time\")\n        matlab_row = n_data[n_data[\"solver\"] == \"MATLAB ode45\"]\n        matlab_time = matlab_row[\"mean_time\"].values[0] if len(matlab_row) &gt; 0 else None\n\n        table_lines: list[str] = [\n            f\"### N = {n:,}\",\n            \"\",\n            \"| Solver | Device | Time (s) | Std Dev | vs MATLAB |\",\n            \"|--------|--------|----------:|--------:|----------:|\",\n        ]\n\n        for _, row in n_data.iterrows():\n            if matlab_time is not None:\n                speedup = matlab_time / row[\"mean_time\"]\n                speedup_str = f\"{speedup:.2f}x\"\n            else:\n                speedup_str = \"-\"\n            table_lines.append(\n                f\"| {row['solver']} | {row['device'].upper()} | {row['mean_time']:.2f} | \u00b1{row['std_time']:.2f} | {speedup_str} |\"\n            )\n\n        sections.append(\"\\n\".join(table_lines))\n\n    return \"\\n\\n\".join(sections)\n</pre> def solver_comparison_table() -&gt; str:     \"\"\"Render solver comparison table from CSV data.      :return: Markdown table string.     \"\"\"     csv_path = SOLVER_COMPARISON_RESULTS_DIR / \"solver_comparison.csv\"      if not csv_path.exists():         return '!!! warning \"Missing Data\"\\n    Solver comparison data not found. Run `uv run python benchmarks/solver_comparison/compare_matlab_vs_python.py` to generate.'      df = pd.read_csv(csv_path)      n_values = sorted(df[\"N\"].unique())     sections: list[str] = []      for n in n_values:         n_data = df[df[\"N\"] == n].sort_values(\"mean_time\")         matlab_row = n_data[n_data[\"solver\"] == \"MATLAB ode45\"]         matlab_time = matlab_row[\"mean_time\"].values[0] if len(matlab_row) &gt; 0 else None          table_lines: list[str] = [             f\"### N = {n:,}\",             \"\",             \"| Solver | Device | Time (s) | Std Dev | vs MATLAB |\",             \"|--------|--------|----------:|--------:|----------:|\",         ]          for _, row in n_data.iterrows():             if matlab_time is not None:                 speedup = matlab_time / row[\"mean_time\"]                 speedup_str = f\"{speedup:.2f}x\"             else:                 speedup_str = \"-\"             table_lines.append(                 f\"| {row['solver']} | {row['device'].upper()} | {row['mean_time']:.2f} | \u00b1{row['std_time']:.2f} | {speedup_str} |\"             )          sections.append(\"\\n\".join(table_lines))      return \"\\n\\n\".join(sections) In\u00a0[\u00a0]: Copied! <pre>def solver_matlab_speedup_table() -&gt; str:\n    \"\"\"Render speedup vs MATLAB table from CSV data.\n\n    :return: Markdown table string.\n    \"\"\"\n    csv_path = SOLVER_COMPARISON_RESULTS_DIR / \"solver_comparison.csv\"\n\n    if not csv_path.exists():\n        return '!!! warning \"Missing Data\"\\n    Solver comparison data not found.'\n\n    df = pd.read_csv(csv_path)\n\n    n_values = sorted(df[\"N\"].unique())\n\n    table_lines: list[str] = [\n        \"| N | Solver | Device | Time (s) | vs MATLAB |\",\n        \"|--:|--------|--------|----------:|----------:|\",\n    ]\n\n    for n in n_values:\n        n_data = df[df[\"N\"] == n]\n        matlab_row = n_data[n_data[\"solver\"] == \"MATLAB ode45\"]\n\n        if matlab_row.empty:\n            continue\n\n        matlab_time = matlab_row[\"mean_time\"].values[0]\n\n        for _, row in (\n            n_data[n_data[\"solver\"] != \"MATLAB ode45\"].sort_values(\"mean_time\").iterrows()\n        ):\n            speedup = matlab_time / row[\"mean_time\"]\n            direction = \"faster\" if speedup &gt; 1 else \"slower\"\n            speedup_str = f\"{speedup:.2f}x {direction}\"\n            table_lines.append(\n                f\"| {n:,} | {row['solver']} | {row['device'].upper()} | {row['mean_time']:.2f} | {speedup_str} |\"\n            )\n\n        table_lines.append(f\"| {n:,} | MATLAB ode45 | CPU | {matlab_time:.2f} | *baseline* |\")\n\n    return \"\\n\".join(table_lines)\n</pre> def solver_matlab_speedup_table() -&gt; str:     \"\"\"Render speedup vs MATLAB table from CSV data.      :return: Markdown table string.     \"\"\"     csv_path = SOLVER_COMPARISON_RESULTS_DIR / \"solver_comparison.csv\"      if not csv_path.exists():         return '!!! warning \"Missing Data\"\\n    Solver comparison data not found.'      df = pd.read_csv(csv_path)      n_values = sorted(df[\"N\"].unique())      table_lines: list[str] = [         \"| N | Solver | Device | Time (s) | vs MATLAB |\",         \"|--:|--------|--------|----------:|----------:|\",     ]      for n in n_values:         n_data = df[df[\"N\"] == n]         matlab_row = n_data[n_data[\"solver\"] == \"MATLAB ode45\"]          if matlab_row.empty:             continue          matlab_time = matlab_row[\"mean_time\"].values[0]          for _, row in (             n_data[n_data[\"solver\"] != \"MATLAB ode45\"].sort_values(\"mean_time\").iterrows()         ):             speedup = matlab_time / row[\"mean_time\"]             direction = \"faster\" if speedup &gt; 1 else \"slower\"             speedup_str = f\"{speedup:.2f}x {direction}\"             table_lines.append(                 f\"| {n:,} | {row['solver']} | {row['device'].upper()} | {row['mean_time']:.2f} | {speedup_str} |\"             )          table_lines.append(f\"| {n:,} | MATLAB ode45 | CPU | {matlab_time:.2f} | *baseline* |\")      return \"\\n\".join(table_lines) In\u00a0[\u00a0]: Copied! <pre>def benchmark_comparison_table() -&gt; str:\n    \"\"\"Render benchmark comparison table from CSV data.\n\n    :return: Markdown table string.\n    \"\"\"\n    csv_path = BENCHMARK_RESULTS_DIR / \"end_to_end_comparison.csv\"\n\n    if not csv_path.exists():\n        return '!!! warning \"Missing Data\"\\n    Benchmark data not found. Run `uv run python benchmarks/end_to_end/compare_matlab_vs_python.py` to generate.'\n\n    df = pd.read_csv(csv_path)\n\n    n_values = sorted(df[\"N\"].unique())\n\n    table_lines: list[str] = [\n        \"| N | MATLAB (s) | Python CPU (s) | Python CUDA (s) | CPU vs MATLAB | GPU vs MATLAB |\",\n        \"|--:|----------:|---------------:|----------------:|--------------:|--------------:|\",\n    ]\n\n    for n in n_values:\n        n_data = df[df[\"N\"] == n]\n\n        matlab_row = n_data[n_data[\"implementation\"] == \"MATLAB\"]\n        cpu_row = n_data[n_data[\"implementation\"] == \"Python CPU\"]\n        cuda_row = n_data[n_data[\"implementation\"] == \"Python CUDA\"]\n\n        matlab_time = matlab_row[\"mean_time\"].values[0] if len(matlab_row) &gt; 0 else float(\"nan\")\n        cpu_time = cpu_row[\"mean_time\"].values[0] if len(cpu_row) &gt; 0 else float(\"nan\")\n        cuda_time = cuda_row[\"mean_time\"].values[0] if len(cuda_row) &gt; 0 else float(\"nan\")\n\n        cpu_speedup = matlab_time / cpu_time if cpu_time &gt; 0 else float(\"nan\")\n        gpu_speedup = matlab_time / cuda_time if cuda_time &gt; 0 else float(\"nan\")\n\n        table_lines.append(\n            f\"| {n:,} | {matlab_time:.2f} | {cpu_time:.2f} | {cuda_time:.2f} | {cpu_speedup:.1f}x | {gpu_speedup:.1f}x |\"\n        )\n\n    return \"\\n\".join(table_lines)\n</pre> def benchmark_comparison_table() -&gt; str:     \"\"\"Render benchmark comparison table from CSV data.      :return: Markdown table string.     \"\"\"     csv_path = BENCHMARK_RESULTS_DIR / \"end_to_end_comparison.csv\"      if not csv_path.exists():         return '!!! warning \"Missing Data\"\\n    Benchmark data not found. Run `uv run python benchmarks/end_to_end/compare_matlab_vs_python.py` to generate.'      df = pd.read_csv(csv_path)      n_values = sorted(df[\"N\"].unique())      table_lines: list[str] = [         \"| N | MATLAB (s) | Python CPU (s) | Python CUDA (s) | CPU vs MATLAB | GPU vs MATLAB |\",         \"|--:|----------:|---------------:|----------------:|--------------:|--------------:|\",     ]      for n in n_values:         n_data = df[df[\"N\"] == n]          matlab_row = n_data[n_data[\"implementation\"] == \"MATLAB\"]         cpu_row = n_data[n_data[\"implementation\"] == \"Python CPU\"]         cuda_row = n_data[n_data[\"implementation\"] == \"Python CUDA\"]          matlab_time = matlab_row[\"mean_time\"].values[0] if len(matlab_row) &gt; 0 else float(\"nan\")         cpu_time = cpu_row[\"mean_time\"].values[0] if len(cpu_row) &gt; 0 else float(\"nan\")         cuda_time = cuda_row[\"mean_time\"].values[0] if len(cuda_row) &gt; 0 else float(\"nan\")          cpu_speedup = matlab_time / cpu_time if cpu_time &gt; 0 else float(\"nan\")         gpu_speedup = matlab_time / cuda_time if cuda_time &gt; 0 else float(\"nan\")          table_lines.append(             f\"| {n:,} | {matlab_time:.2f} | {cpu_time:.2f} | {cuda_time:.2f} | {cpu_speedup:.1f}x | {gpu_speedup:.1f}x |\"         )      return \"\\n\".join(table_lines) In\u00a0[\u00a0]: Copied! <pre>def benchmark_scaling_analysis() -&gt; str:\n    \"\"\"Render scaling analysis summary from benchmark data.\n\n    :return: Markdown summary string.\n    \"\"\"\n    csv_path = BENCHMARK_RESULTS_DIR / \"end_to_end_comparison.csv\"\n\n    if not csv_path.exists():\n        return '!!! warning \"Missing Data\"\\n    Benchmark data not found.'\n\n    df = pd.read_csv(csv_path)\n\n    implementations = [\"MATLAB\", \"Python CPU\", \"Python CUDA\"]\n    results: list[str] = [\n        \"| Implementation | Scaling | Exponent \u03b1 | R\u00b2 |\",\n        \"|----------------|---------|------------|-----|\",\n    ]\n\n    for impl in implementations:\n        impl_data = df[df[\"implementation\"] == impl].sort_values(\"N\")\n        if len(impl_data) &lt; 3:\n            continue\n\n        n_vals = impl_data[\"N\"].values.astype(float)\n        t_vals = impl_data[\"mean_time\"].values\n\n        log_n = np.log(n_vals)\n        log_t = np.log(t_vals)\n        slope, intercept, r_value, p_value, std_err = scipy_stats.linregress(log_n, log_t)\n        alpha = slope\n        alpha_ci = 1.96 * std_err\n        r2 = r_value**2\n\n        if alpha &lt; 0.15:\n            complexity = \"O(1)\"\n        elif abs(alpha - 1.0) &lt; 0.15:\n            complexity = \"O(N)\"\n        elif abs(alpha - 2.0) &lt; 0.15:\n            complexity = \"O(N\u00b2)\"\n        else:\n            complexity = f\"O(N^{alpha:.2f})\"\n\n        results.append(f\"| {impl} | {complexity} | {alpha:.2f} \u00b1 {alpha_ci:.2f} | {r2:.3f} |\")\n\n    return \"\\n\".join(results)\n</pre> def benchmark_scaling_analysis() -&gt; str:     \"\"\"Render scaling analysis summary from benchmark data.      :return: Markdown summary string.     \"\"\"     csv_path = BENCHMARK_RESULTS_DIR / \"end_to_end_comparison.csv\"      if not csv_path.exists():         return '!!! warning \"Missing Data\"\\n    Benchmark data not found.'      df = pd.read_csv(csv_path)      implementations = [\"MATLAB\", \"Python CPU\", \"Python CUDA\"]     results: list[str] = [         \"| Implementation | Scaling | Exponent \u03b1 | R\u00b2 |\",         \"|----------------|---------|------------|-----|\",     ]      for impl in implementations:         impl_data = df[df[\"implementation\"] == impl].sort_values(\"N\")         if len(impl_data) &lt; 3:             continue          n_vals = impl_data[\"N\"].values.astype(float)         t_vals = impl_data[\"mean_time\"].values          log_n = np.log(n_vals)         log_t = np.log(t_vals)         slope, intercept, r_value, p_value, std_err = scipy_stats.linregress(log_n, log_t)         alpha = slope         alpha_ci = 1.96 * std_err         r2 = r_value**2          if alpha &lt; 0.15:             complexity = \"O(1)\"         elif abs(alpha - 1.0) &lt; 0.15:             complexity = \"O(N)\"         elif abs(alpha - 2.0) &lt; 0.15:             complexity = \"O(N\u00b2)\"         else:             complexity = f\"O(N^{alpha:.2f})\"          results.append(f\"| {impl} | {complexity} | {alpha:.2f} \u00b1 {alpha_ci:.2f} | {r2:.3f} |\")      return \"\\n\".join(results) In\u00a0[\u00a0]: Copied! <pre>def define_env(env: Any) -&gt; None:\n    \"\"\"Define macros for mkdocs-macros-plugin.\n\n    :param env: The macro environment.\n    \"\"\"\n    env.macro(comparison_table, \"comparison_table\")\n    env.macro(load_snippet, \"load_snippet\")\n    env.macro(benchmark_comparison_table, \"benchmark_comparison_table\")\n    env.macro(benchmark_scaling_analysis, \"benchmark_scaling_analysis\")\n    env.macro(solver_comparison_table, \"solver_comparison_table\")\n    env.macro(solver_matlab_speedup_table, \"solver_matlab_speedup_table\")\n</pre> def define_env(env: Any) -&gt; None:     \"\"\"Define macros for mkdocs-macros-plugin.      :param env: The macro environment.     \"\"\"     env.macro(comparison_table, \"comparison_table\")     env.macro(load_snippet, \"load_snippet\")     env.macro(benchmark_comparison_table, \"benchmark_comparison_table\")     env.macro(benchmark_scaling_analysis, \"benchmark_scaling_analysis\")     env.macro(solver_comparison_table, \"solver_comparison_table\")     env.macro(solver_matlab_speedup_table, \"solver_matlab_speedup_table\")"},{"location":"api/adaptive-sampling/","title":"BasinStabilityStudy","text":""},{"location":"api/adaptive-sampling/#pybasin.basin_stability_study.BasinStabilityStudy","title":"pybasin.basin_stability_study.BasinStabilityStudy","text":"<p>Basin Stability Study.</p>"},{"location":"api/adaptive-sampling/#pybasin.basin_stability_study.BasinStabilityStudy-attributes","title":"Attributes","text":""},{"location":"api/adaptive-sampling/#pybasin.basin_stability_study.BasinStabilityStudy.parameter_values","title":"parameter_values  <code>property</code>","text":"<pre><code>parameter_values: list[Any]\n</code></pre> <p>Legacy access to parameter values (for backward compatibility).</p> <p>Returns:</p> Type Description <code>list[Any]</code> <p>List of parameter values from labels.</p>"},{"location":"api/adaptive-sampling/#pybasin.basin_stability_study.BasinStabilityStudy-functions","title":"Functions","text":""},{"location":"api/adaptive-sampling/#pybasin.basin_stability_study.BasinStabilityStudy.__init__","title":"__init__","text":"<pre><code>__init__(\n    n: int,\n    ode_system: ODESystemProtocol,\n    sampler: Sampler,\n    solver: SolverProtocol,\n    feature_extractor: FeatureExtractor,\n    cluster_classifier: LabelPredictor,\n    study_params: StudyParams,\n    save_to: str | None = \"results\",\n    verbose: bool = False,\n)\n</code></pre> <p>Initialize the Basin Stability Study.</p> <p>Sets up the estimator for a parameter study where one or more parameters are systematically varied across multiple values. Parameters can be in any component (ODE system, sampler, solver, feature extractor, or predictor).</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of initial conditions (samples) to generate for each parameter value.</p> required <code>ode_system</code> <code>ODESystemProtocol</code> <p>The ODE system model (ODESystem or JaxODESystem).</p> required <code>sampler</code> <code>Sampler</code> <p>The Sampler object to generate initial conditions.</p> required <code>solver</code> <code>SolverProtocol</code> <p>The Solver object to integrate the ODE system (Solver or JaxSolver).</p> required <code>feature_extractor</code> <code>FeatureExtractor</code> <p>The FeatureExtractor object to extract features from trajectories.</p> required <code>cluster_classifier</code> <code>LabelPredictor</code> <p>The LabelPredictor object to assign attractor labels.</p> required <code>study_params</code> <code>StudyParams</code> <p>Parameter study specification (SweepStudyParams, GridStudyParams, etc.).</p> required <code>save_to</code> <code>str | None</code> <p>Folder path where results will be saved, or None to disable saving.</p> <code>'results'</code> <code>verbose</code> <code>bool</code> <p>If True, show detailed logs from BasinStabilityEstimator instances. If False, suppress INFO logs to reduce output clutter during parameter sweeps.</p> <code>False</code>"},{"location":"api/adaptive-sampling/#pybasin.basin_stability_study.BasinStabilityStudy.estimate_as_bs","title":"estimate_as_bs","text":"<pre><code>estimate_as_bs() -&gt; tuple[\n    list[dict[str, Any]],\n    list[dict[str, float]],\n    list[AdaptiveStudyResult],\n]\n</code></pre> <p>Estimate basin stability for each parameter combination in the study.</p> <p>Performs basin stability estimation by systematically varying parameters across the provided combinations. For each configuration:</p> <ol> <li>Applies all parameter assignments from the RunConfig</li> <li>Creates a new BasinStabilityEstimator instance</li> <li>Estimates basin stability and computes error estimates</li> <li>Stores results including basin stability values, errors, and solution metadata</li> </ol> <p>Uses GPU acceleration automatically when available for significant performance gains. Memory is explicitly freed after each iteration to prevent accumulation.</p> <p>Returns:</p> Type Description <code>tuple[list[dict[str, Any]], list[dict[str, float]], list[AdaptiveStudyResult]]</code> <p>Tuple of three lists with matching indices:  - labels: List of label dictionaries identifying each run - basin_stabilities: List of basin stability dictionaries (label -&gt; fraction) - results: List of AdaptiveStudyResult with complete information including errors</p>"},{"location":"api/adaptive-sampling/#pybasin.basin_stability_study.BasinStabilityStudy.save","title":"save","text":"<pre><code>save() -&gt; None\n</code></pre> <p>Save the basin stability results to a JSON file. Handles numpy arrays and Solution objects by converting them to standard Python types.</p>"},{"location":"api/adaptive-sampling/#pybasin.basin_stability_study.BasinStabilityStudy.get_errors","title":"get_errors","text":"<pre><code>get_errors(param_index: int) -&gt; dict[str, ErrorInfo]\n</code></pre> <p>Get error information for basin stability estimates at a specific parameter value.</p> <p>Retrieves the pre-computed error estimates (absolute and relative standard errors) for all attractor labels at the specified parameter index.</p> <p>Parameters:</p> Name Type Description Default <code>param_index</code> <code>int</code> <p>Index of the parameter value in the adaptive study (0-based).</p> required <p>Returns:</p> Type Description <code>dict[str, ErrorInfo]</code> <p>Dictionary mapping each attractor label to its ErrorInfo containing e_abs and e_rel.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If estimate_as_bs() has not been called yet.</p> <code>ValueError</code> <p>If param_index is out of range.</p>"},{"location":"api/adaptive-sampling/#study-parameters","title":"Study Parameters","text":"<p>options: heading_level: 3</p> <p>options: heading_level: 3</p> <p>options: heading_level: 3</p> <p>options: heading_level: 3</p> <p>options: heading_level: 3</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.StudyParams","title":"pybasin.study_params.StudyParams","text":"<p>               Bases: <code>ABC</code></p> <p>Base class for study parameter generators.</p> <p>Subclasses must implement iter to yield RunConfig objects and len to return the total number of runs.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.StudyParams-functions","title":"Functions","text":""},{"location":"api/adaptive-sampling/#pybasin.study_params.StudyParams.__iter__","title":"__iter__  <code>abstractmethod</code>","text":"<pre><code>__iter__() -&gt; Iterator[RunConfig]\n</code></pre> <p>Yield RunConfig for each parameter combination.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.StudyParams.__len__","title":"__len__  <code>abstractmethod</code>","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return the total number of runs.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.SweepStudyParams","title":"pybasin.study_params.SweepStudyParams","text":"<p>               Bases: <code>StudyParams</code></p> <p>Single parameter sweep (current behavior).</p> <p>Iterates over a single parameter's values, yielding one RunConfig per value.</p> <p>Example:</p> <pre><code>study_params = SweepStudyParams(\n    name='ode_system.params[\"T\"]',\n    values=np.arange(0.01, 0.97, 0.05),\n)\n</code></pre> <p>Attributes:</p> Name Type Description <code>name</code> <p>The parameter path to vary.</p> <code>values</code> <code>list[Any]</code> <p>List of values to sweep through.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.SweepStudyParams-functions","title":"Functions","text":""},{"location":"api/adaptive-sampling/#pybasin.study_params.SweepStudyParams.__init__","title":"__init__","text":"<pre><code>__init__(name: str, values: list[Any]) -&gt; None\n</code></pre> <p>Initialize the sweep study parameters.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The parameter path to vary, e.g., 'ode_system.params[\"T\"]'.</p> required <code>values</code> <code>list[Any]</code> <p>Array or list of values to sweep through.</p> required"},{"location":"api/adaptive-sampling/#pybasin.study_params.SweepStudyParams.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Iterator[RunConfig]\n</code></pre> <p>Yield RunConfig for each parameter value.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.SweepStudyParams.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return the number of parameter values.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.GridStudyParams","title":"pybasin.study_params.GridStudyParams","text":"<p>               Bases: <code>StudyParams</code></p> <p>Cartesian product of multiple parameters.</p> <p>Creates all combinations of the provided parameter values (grid study).</p> <p>Example:</p> <pre><code>study_params = GridStudyParams(\n    **{\n        'ode_system.params[\"K\"]': k_values,\n        'ode_system.params[\"sigma\"]': sigma_values,\n    }\n)\n# Runs: K[0]\u00d7sigma[0], K[0]\u00d7sigma[1], ..., K[n]\u00d7sigma[m]\n</code></pre>"},{"location":"api/adaptive-sampling/#pybasin.study_params.GridStudyParams-functions","title":"Functions","text":""},{"location":"api/adaptive-sampling/#pybasin.study_params.GridStudyParams.__init__","title":"__init__","text":"<pre><code>__init__(**params: list[Any]) -&gt; None\n</code></pre> <p>Initialize the grid study parameters.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>list[Any]</code> <p>Keyword arguments mapping parameter names to value arrays. e.g., GridStudyParams(**{'ode_system.params[\"T\"]': t_values})</p> <code>{}</code>"},{"location":"api/adaptive-sampling/#pybasin.study_params.GridStudyParams.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Iterator[RunConfig]\n</code></pre> <p>Yield RunConfig for each parameter combination (Cartesian product).</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.GridStudyParams.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return the total number of combinations.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.ZipStudyParams","title":"pybasin.study_params.ZipStudyParams","text":"<p>               Bases: <code>StudyParams</code></p> <p>Parallel iteration of multiple parameters (must have same length).</p> <p>Iterates through parameters in parallel (like Python's zip), where values at the same index are used together.</p> <p>Example:</p> <pre><code>t_values = np.arange(0.01, 0.97, 0.05)\nsamplers = [CsvSampler(f\"gt_T_{t:.2f}.csv\") for t in t_values]\n\nstudy_params = ZipStudyParams(\n    **{\n        'ode_system.params[\"T\"]': t_values,\n        \"sampler\": samplers,\n    }\n)\n</code></pre>"},{"location":"api/adaptive-sampling/#pybasin.study_params.ZipStudyParams-functions","title":"Functions","text":""},{"location":"api/adaptive-sampling/#pybasin.study_params.ZipStudyParams.__init__","title":"__init__","text":"<pre><code>__init__(**params: list[Any]) -&gt; None\n</code></pre> <p>Initialize the zip study parameters.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>list[Any]</code> <p>Keyword arguments mapping parameter names to value arrays. All arrays must have the same length.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If parameter arrays have different lengths.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.ZipStudyParams.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Iterator[RunConfig]\n</code></pre> <p>Yield RunConfig for each parameter tuple (parallel iteration).</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.ZipStudyParams.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return the number of parameter tuples.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.CustomStudyParams","title":"pybasin.study_params.CustomStudyParams","text":"<p>               Bases: <code>StudyParams</code></p> <p>User-provided list of configurations.</p> <p>Allows full control over parameter combinations by providing explicit RunConfig objects.</p> <p>Example:</p> <pre><code>configs = [\n    RunConfig(\n        assignments=[\n            ParamAssignment(\"ode_system\", ode),\n            ParamAssignment('ode_system.params[\"K\"]', K),\n        ],\n        label={\"K\": K, \"p\": p},\n    )\n    for K, p in product(k_values, p_values)\n]\nstudy_params = CustomStudyParams(configs)\n</code></pre>"},{"location":"api/adaptive-sampling/#pybasin.study_params.CustomStudyParams-functions","title":"Functions","text":""},{"location":"api/adaptive-sampling/#pybasin.study_params.CustomStudyParams.__init__","title":"__init__","text":"<pre><code>__init__(configs: list[RunConfig]) -&gt; None\n</code></pre> <p>Initialize with a list of RunConfig objects.</p> <p>Parameters:</p> Name Type Description Default <code>configs</code> <code>list[RunConfig]</code> <p>List of RunConfig objects defining each run.</p> required"},{"location":"api/adaptive-sampling/#pybasin.study_params.CustomStudyParams.__iter__","title":"__iter__","text":"<pre><code>__iter__() -&gt; Iterator[RunConfig]\n</code></pre> <p>Yield each RunConfig.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.CustomStudyParams.__len__","title":"__len__","text":"<pre><code>__len__() -&gt; int\n</code></pre> <p>Return the number of configurations.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.CustomStudyParams.from_dicts","title":"from_dicts  <code>classmethod</code>","text":"<pre><code>from_dicts(\n    param_dicts: list[dict[str, Any]],\n) -&gt; CustomStudyParams\n</code></pre> <p>Create from a list of {param_name: value} dictionaries.</p> <p>Example:</p> <pre><code>study_params = CustomStudyParams.from_dicts(\n    [\n        {'ode_system.params[\"K\"]': 0.1, \"n\": 500},\n        {'ode_system.params[\"K\"]': 0.2, \"n\": 1000},\n    ]\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>param_dicts</code> <code>list[dict[str, Any]]</code> <p>List of dictionaries where each dict maps parameter names to values for one run.</p> required <p>Returns:</p> Type Description <code>CustomStudyParams</code> <p>CustomStudyParams instance.</p>"},{"location":"api/adaptive-sampling/#configuration-types","title":"Configuration Types","text":"<p>options: heading_level: 3</p> <p>options: heading_level: 3</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.ParamAssignment","title":"pybasin.study_params.ParamAssignment  <code>dataclass</code>","text":"<p>A single parameter assignment.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The parameter path, e.g., 'ode_system.params[\"T\"]' or 'sampler'.</p> <code>value</code> <code>Any</code> <p>The value to assign to the parameter.</p>"},{"location":"api/adaptive-sampling/#pybasin.study_params.RunConfig","title":"pybasin.study_params.RunConfig  <code>dataclass</code>","text":"<p>Configuration for a single BSE run with multiple parameter assignments.</p> <p>Attributes:</p> Name Type Description <code>assignments</code> <code>list[ParamAssignment]</code> <p>List of parameter assignments to apply for this run.</p> <code>label</code> <code>dict[str, Any]</code> <p>Dictionary for results indexing, e.g., {\"T\": 0.5, \"p\": 0.2}.</p>"},{"location":"api/adaptive-sampling/#result-types","title":"Result Types","text":"<p>options: heading_level: 3</p> <p>options: heading_level: 3 heading_level: 3</p>"},{"location":"api/adaptive-sampling/#pybasin.types.AdaptiveStudyResult","title":"pybasin.types.AdaptiveStudyResult","text":"<p>               Bases: <code>TypedDict</code></p> <p>Results for a single parameter value in an adaptive parameter study.</p> <p>Contains complete information about basin stability estimation at one parameter value, including the basin stability values, error estimates, sample metadata, and optional detailed solution data.</p> <p>Attributes:</p> Name Type Description <code>param_value</code> <code>float | None</code> <p>The parameter value used for this estimation, or None if no parameter is being varied.</p> <code>basin_stability</code> <code>dict[str, float]</code> <p>Dictionary mapping attractor labels to their basin stability values (fraction of samples).</p> <code>errors</code> <code>dict[str, ErrorInfo]</code> <p>Dictionary mapping attractor labels to their ErrorInfo (absolute and relative errors).</p> <code>n_samples</code> <code>int</code> <p>Number of initial conditions actually used (may differ from requested N due to grid rounding).</p> <code>labels</code> <code>ndarray[Any, Any] | None</code> <p>Array of attractor labels for each initial condition, or None if not available.</p> <code>bifurcation_amplitudes</code> <code>Tensor | None</code> <p>Amplitude values for bifurcation analysis, or None if not computed.</p>"},{"location":"api/adaptive-sampling/#pybasin.types.ErrorInfo","title":"pybasin.types.ErrorInfo","text":"<p>               Bases: <code>TypedDict</code></p> <p>Standard error information for basin stability estimates.</p> <p>Basin stability errors are computed using Bernoulli experiment statistics:</p> <ul> <li>e_abs = sqrt(S_B(A) * (1 - S_B(A)) / N) - absolute standard error</li> <li>e_rel = 1 / sqrt(N * S_B(A)) - relative standard error</li> </ul> <p>Attributes:</p> Name Type Description <code>e_abs</code> <code>float</code> <p>Absolute standard error of the basin stability estimate.</p> <code>e_rel</code> <code>float</code> <p>Relative standard error of the basin stability estimate.</p>"},{"location":"api/basin-stability-estimator/","title":"BasinStabilityEstimator","text":""},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator","title":"pybasin.basin_stability_estimator.BasinStabilityEstimator","text":"<p>Core class for basin stability analysis.</p> <p>Configures the analysis with an ODE system, sampler, and solver, and provides methods to estimate basin stability and save results.</p> <p>Attributes:</p> Name Type Description <code>bs_vals</code> <code>dict[str, float] | None</code> <p>Basin stability values (fraction of samples per class).</p> <code>y0</code> <code>Tensor | None</code> <p>Initial conditions tensor.</p> <code>solution</code> <code>Solution | None</code> <p>Solution instance containing trajectory and analysis results.</p>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator-functions","title":"Functions","text":""},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.__init__","title":"__init__","text":"<pre><code>__init__(\n    ode_system: ODESystemProtocol,\n    sampler: Sampler,\n    n: int = 10000,\n    solver: SolverProtocol | None = None,\n    feature_extractor: FeatureExtractor | None = None,\n    predictor: LabelPredictor | None = None,\n    feature_selector: BaseEstimator | None = _USE_DEFAULT,\n    detect_unbounded: bool = True,\n    save_to: str | None = None,\n)\n</code></pre> <p>Initialize the BasinStabilityEstimator.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of initial conditions (samples) to generate.</p> <code>10000</code> <code>ode_system</code> <code>ODESystemProtocol</code> <p>The ODE system model (ODESystem or JaxODESystem).</p> required <code>sampler</code> <code>Sampler</code> <p>The Sampler object to generate initial conditions.</p> required <code>solver</code> <code>SolverProtocol | None</code> <p>The Solver object to integrate the ODE system (Solver or JaxSolver). If None, automatically instantiates JaxSolver for JaxODESystem or TorchDiffEqSolver for ODESystem with time_span=(0, 1000), n_steps=1000, and device from sampler.</p> <code>None</code> <code>feature_extractor</code> <code>FeatureExtractor | None</code> <p>The FeatureExtractor object to extract features from trajectories. If None, defaults to TorchFeatureExtractor with minimal+dynamical features.</p> <code>None</code> <code>predictor</code> <code>LabelPredictor | None</code> <p>The LabelPredictor object to assign labels. If None, defaults to HDBSCANClusterer with auto_tune=True and assign_noise=True.</p> <code>None</code> <code>feature_selector</code> <code>BaseEstimator | None</code> <p>Feature filtering sklearn transformer with get_support() method. Defaults to DefaultFeatureSelector(). Pass None to disable filtering. Accepts any sklearn transformer (VarianceThreshold, SelectKBest, etc.) or Pipeline.</p> <code>_USE_DEFAULT</code> <code>detect_unbounded</code> <code>bool</code> <p>Enable unboundedness detection before feature extraction (default: True). Only activates when solver has event_fn configured (e.g., JaxSolver with event_fn). When enabled, unbounded trajectories are separated and labeled as \"unbounded\" before feature extraction to prevent imputed Inf values from contaminating features.</p> <code>True</code> <code>save_to</code> <code>str | None</code> <p>Optional file path to save results.</p> <code>None</code>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.estimate_bs","title":"estimate_bs","text":"<pre><code>estimate_bs(\n    parallel_integration: bool = True,\n) -&gt; dict[str, float]\n</code></pre> <p>Estimate basin stability by:     1. Generating initial conditions using the sampler.     2. Integrating the ODE system for each sample (in parallel) to produce a Solution.     3. Extracting features from each Solution.     4. Clustering/classifying the feature space.     5. Computing the fraction of samples in each basin.</p> <p>This method sets:     - self.y0     - self.solution     - self.bs_vals</p> <p>Parameters:</p> Name Type Description Default <code>parallel_integration</code> <code>bool</code> <p>If True and using ClassifierPredictor, run main integration and template integration in parallel (default: True).</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>A dictionary of basin stability values per class.</p>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.get_errors","title":"get_errors","text":"<pre><code>get_errors() -&gt; dict[str, ErrorInfo]\n</code></pre> <p>Compute absolute and relative errors for basin stability estimates.</p> <p>The errors are based on Bernoulli experiment statistics:</p> <ul> <li>e_abs = sqrt(S_B(A) * (1 - S_B(A)) / N) \u2014 absolute standard error</li> <li>e_rel = 1 / sqrt(N * S_B(A)) \u2014 relative error</li> </ul> <p>Returns:</p> Type Description <code>dict[str, ErrorInfo]</code> <p>Dictionary mapping each label to an ErrorInfo with <code>e_abs</code> and <code>e_rel</code> keys.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>estimate_bs()</code> has not been called yet.</p>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.save","title":"save","text":"<pre><code>save() -&gt; None\n</code></pre> <p>Save the basin stability results to a JSON file.</p> <p>Converts numpy arrays and Solution objects to standard Python types.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>estimate_bs()</code> has not been called yet.</p> <code>ValueError</code> <p>If <code>save_to</code> path is not defined.</p>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.save_to_excel","title":"save_to_excel","text":"<pre><code>save_to_excel() -&gt; None\n</code></pre> <p>Save the basin stability results to an Excel file.</p> <p>Includes grid samples, labels, and bifurcation amplitudes.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>estimate_bs()</code> has not been called yet.</p> <code>ValueError</code> <p>If <code>save_to</code> path is not defined.</p> <code>ValueError</code> <p>If no solution data is available.</p>"},{"location":"api/feature-extractors/","title":"Feature Extractors","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor","title":"pybasin.feature_extractors.feature_extractor.FeatureExtractor","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for extracting features from ODE solutions.</p> <p>Feature extractors transform ODE solution trajectories into feature vectors that can be used for basin of attraction classification. This class provides utilities for filtering solutions by time (to remove transients).</p> <pre><code>class AmplitudeExtractor(FeatureExtractor):\n    def extract_features(self, solution: Solution) -&gt; torch.Tensor:\n        y_filtered = self.filter_time(solution)\n        return torch.max(torch.abs(y_filtered), dim=0)[0]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Only data after this time will be used for feature extraction. Default of 0.0 uses the entire time series. A common choice is the last 10% of the integration time to avoid transient behavior.</p> <code>0.0</code>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names.</p> <p>If not explicitly set by a subclass, automatically generates names using the pattern: _. The class name is converted to snake_case and the suffix 'FeatureExtractor' is removed (if present). <p>Returns:</p> Type Description <code>list[str]</code> <p>List of feature names. Length must match the number of features (F) in the output tensor from extract_features().</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor.extract_features","title":"extract_features  <code>abstractmethod</code>","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract features from an ODE solution.</p> <p>This method must be implemented by subclasses to define how features are computed from solution trajectories.</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution containing time series data for one or more trajectories. The solution.y tensor has shape (N, B, S) where N is the number of time steps, B is the batch size (number of initial conditions), and S is the number of state variables.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Feature tensor of shape (B, F) where B is the batch size and F is the number of features extracted per trajectory.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor.filter_time","title":"filter_time","text":"<pre><code>filter_time(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Filter out transient behavior by removing early time steps.</p> <p>Removes time steps before <code>time_steady</code> to exclude transient dynamics from feature extraction. This ensures features are computed only from steady-state or long-term behavior.</p> <pre><code># Extract features only from the last 10% of integration time\nextractor = FeatureExtractor(time_steady=9.0)  # if time_span=(0, 10)\nfiltered = extractor.filter_time(solution)\n# Only time points t &gt; 9.0 are included\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution with time tensor of shape (N,) and y tensor of shape (N, B, S) where N is time steps, B is batch size, and S is number of state variables.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Filtered tensor of shape (N', B, S) where N' is the number of time steps after time_steady. If time_steady is 0 or less than all time points, returns the original solution.y unchanged.</p>"},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor","title":"pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor","text":"<p>               Bases: <code>FeatureExtractor</code></p> <p>PyTorch-based feature extractor for time series features.</p> <p>Supports per-state variable feature configuration using tsfresh-style FCParameters dictionaries, allowing different feature sets for different state variables.</p> <p>For CPU extraction, uses multiprocessing to parallelize across batches. For GPU extraction, uses batched CUDA operations for optimal performance.</p> <pre><code># Default: use comprehensive features for all states on CPU\nextractor = TorchFeatureExtractor(time_steady=9.0)\n\n# GPU extraction with default features\nextractor = TorchFeatureExtractor(time_steady=9.0, device=\"gpu\")\n\n# Custom features for specific states, skip others\nextractor = TorchFeatureExtractor(\n    time_steady=9.0,\n    features=None,  # Don't extract features by default\n    features_per_state={\n        1: {\"maximum\": None, \"minimum\": None},  # Only extract for state 1\n    },\n)\n\n# Global features with per-state override\nextractor = TorchFeatureExtractor(\n    time_steady=9.0,\n    features_per_state={\n        0: {\"maximum\": None},  # Override state 0\n        1: None,  # Skip state 1\n    },\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Default 0.0.</p> <code>0.0</code> <code>features</code> <code>Literal['comprehensive', 'minimal'] | FCParameters | None</code> <p>Default feature configuration to apply to all states. Can be:  - 'comprehensive': Use TORCH_COMPREHENSIVE_FC_PARAMETERS (default) - 'minimal': Use TORCH_MINIMAL_FC_PARAMETERS (10 basic features) - FCParameters dict: Custom feature configuration - None: Skip states not explicitly configured in features_per_state</p> <code>'comprehensive'</code> <code>features_per_state</code> <code>dict[int, FCParameters | None] | None</code> <p>Optional dict mapping state indices to FCParameters. Overrides <code>features</code> for specified states. Use None as value to skip a state. States not in this dict use the global <code>features</code> config.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>Whether to apply z-score normalization. Default True.</p> <code>True</code> <code>device</code> <code>Literal['cpu', 'gpu']</code> <p>Execution device ('cpu' or 'gpu'). Default 'cpu'.</p> <code>'cpu'</code> <code>n_jobs</code> <code>int | None</code> <p>Number of worker processes for CPU extraction. If None, uses all available CPU cores. Ignored when device='gpu'.</p> <code>None</code> <code>impute_method</code> <code>Literal['extreme', 'tsfresh']</code> <p>Method for handling NaN/inf values in features:  - 'extreme': Replace with extreme values (1e10) to distinguish unbounded trajectories. Best for systems with divergent solutions. (default) - 'tsfresh': Replace using tsfresh-style imputation (inf-&gt;max/min, NaN-&gt;median). Better when all trajectories are bounded.</p> <code>'extreme'</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If device='gpu' but CUDA is not available.</p>"},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names in the format 'state_X__feature_name'.</p>"},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor.extract_features","title":"extract_features","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract features from an ODE solution using PyTorch.</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution containing time series data with y tensor of shape (N, B, S) where N=timesteps, B=batch size, S=state variables.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Feature tensor of shape (B, F) where F is the total number of features.</p>"},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor.reset_scaler","title":"reset_scaler","text":"<pre><code>reset_scaler() -&gt; None\n</code></pre> <p>Reset the normalization parameters.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor","title":"pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor","text":"<p>               Bases: <code>FeatureExtractor</code></p> <p>JAX-based feature extractor for time series features.</p> <p>Supports per-state variable feature configuration using tsfresh-style FCParameters dictionaries, allowing different feature sets for different state variables.</p> <p>Warning:     Using JAX_COMPREHENSIVE_FC_PARAMETERS may cause very long JIT compile times     (~40 minutes). Use JAX_MINIMAL_FC_PARAMETERS or a custom subset for faster     compilation.</p> <pre><code># Default: use minimal features for all states\nextractor = JaxFeatureExtractor(time_steady=9.0)\n\n# Custom features for specific states, skip others\nextractor = JaxFeatureExtractor(\n    time_steady=9.0,\n    features=None,  # Don't extract features by default\n    features_per_state={\n        1: {\"log_delta\": None},  # Only extract for state 1\n    },\n)\n\n# Global features with per-state override\nextractor = JaxFeatureExtractor(\n    time_steady=9.0,\n    features_per_state={\n        0: {\"maximum\": None},  # Override state 0\n        1: None,  # Skip state 1\n    },\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Default 0.0.</p> <code>0.0</code> <code>features</code> <code>FCParameters | None</code> <p>Default FCParameters configuration to apply to all states. Defaults to JAX_MINIMAL_FC_PARAMETERS. Set to None to skip states not explicitly configured in features_per_state.</p> <code>JAX_MINIMAL_FC_PARAMETERS</code> <code>features_per_state</code> <code>dict[int, FCParameters | None] | None</code> <p>Optional dict mapping state indices to FCParameters. Overrides <code>features</code> for specified states. Use None as value to skip a state. States not in this dict use the global <code>features</code> config.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>Whether to apply z-score normalization. Default True.</p> <code>True</code> <code>use_jit</code> <code>bool</code> <p>Whether to JIT-compile extraction. Default True.</p> <code>True</code> <code>device</code> <code>str | None</code> <p>JAX device to use ('cpu', 'gpu', 'cuda', 'cuda:N', or None for auto).</p> <code>None</code> <code>impute_method</code> <code>Literal['extreme', 'tsfresh']</code> <p>Method for handling NaN/inf values in features. Options:  - 'extreme': Replace with extreme values (1e10) to distinguish unbounded trajectories. Best for systems with divergent solutions. (default)  - 'tsfresh': Replace using tsfresh-style imputation (inf-&gt;max/min, NaN-&gt;median). Better when all trajectories are bounded.</p> <code>'extreme'</code>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names in the format 'state_X__feature_name'.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor.extract_features","title":"extract_features","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract features from an ODE solution using JAX.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor.reset_scaler","title":"reset_scaler","text":"<pre><code>reset_scaler() -&gt; None\n</code></pre> <p>Reset the normalization parameters.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor","title":"pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor","text":"<p>               Bases: <code>FeatureExtractor</code></p> <p>Feature extractor using tsfresh for comprehensive time series analysis.</p> <p>This extractor uses the tsfresh library to automatically extract a large number of time series features from ODE solutions. It converts PyTorch/JAX tensors to pandas DataFrames for tsfresh processing, then converts the results back to tensors.</p> <p>Supports per-state variable feature configuration using tsfresh's kind_to_fc_parameters mechanism, allowing you to apply different feature sets to different state variables based on domain knowledge.</p> <pre><code># Same minimal features for all states\nextractor = TsfreshFeatureExtractor(\n    time_steady=9.0, default_fc_parameters=MinimalFCParameters(), n_jobs=-1, normalize=True\n)\n\n# Specific features for all states\nextractor = TsfreshFeatureExtractor(\n    time_steady=950.0,\n    default_fc_parameters={\"mean\": None, \"std\": None, \"maximum\": None},\n    n_jobs=-1,\n)\n\n# Different features per state (e.g., pendulum: position vs velocity)\nfrom tsfresh.feature_extraction import MinimalFCParameters, ComprehensiveFCParameters\n\nextractor = TsfreshFeatureExtractor(\n    time_steady=950.0,\n    kind_to_fc_parameters={\n        0: {\"mean\": None, \"maximum\": None, \"minimum\": None},  # Position: basic stats\n        1: ComprehensiveFCParameters(),  # Velocity: full spectral analysis\n    },\n    n_jobs=1,  # Use n_jobs=1 for deterministic results\n)\n</code></pre> <p>Note on parallelism:     Setting n_jobs &gt; 1 enables parallel feature extraction but introduces     non-determinism due to floating-point arithmetic order. This can cause     inconsistent classification results. Use n_jobs=1 for reproducible results.</p> <p>Note on normalization:     When normalize=True, the scaler is fitted on the FIRST dataset that calls     extract_features(). For best results with supervised classifiers:     - Either set normalize=False (recommended for KNN with few templates)     - Or call fit_scaler() explicitly with representative data before extraction</p> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Only data after this time will be used for feature extraction. Default of 0.0 uses the entire time series.</p> <code>0.0</code> <code>default_fc_parameters</code> <code>dict[str, Any] | Any | None</code> <p>Default feature extraction parameters for all states. Can be one of: - MinimalFCParameters() - Fast extraction with ~20 features - ComprehensiveFCParameters() - Full extraction with ~800 features - Custom dict like {\"mean\": None, \"maximum\": None} for specific features - None - must provide kind_to_fc_parameters Default is MinimalFCParameters().</p> <code>None</code> <code>kind_to_fc_parameters</code> <code>dict[int, dict[str, Any] | Any] | None</code> <p>Optional dict mapping state indices to FCParameters. Allows different feature sets per state variable. If provided, overrides default_fc_parameters for those states.</p> <code>None</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs for feature extraction. Default is 1. Set to -1 to use all available cores.</p> <code>1</code> <code>normalize</code> <code>bool</code> <p>Whether to apply StandardScaler normalization to features. Highly recommended for distance-based classifiers like KNN. Default is True.</p> <code>True</code>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of feature names from tsfresh extraction.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If extract_features has not been called yet.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor.reset_scaler","title":"reset_scaler","text":"<pre><code>reset_scaler() -&gt; None\n</code></pre> <p>Reset the scaler to unfitted state.</p> <p>Call this if you need to refit the scaler on different data.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor.extract_features","title":"extract_features","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract features from an ODE solution using tsfresh.</p> <p>Converts the solution tensor to pandas DataFrame format expected by tsfresh, extracts features for each trajectory and state variable, then converts back to PyTorch tensor.</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution with y tensor of shape (N, B, S) where N is time steps, B is batch size, and S is number of state variables.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Feature tensor of shape (B, F) where B is the batch size and F is the total number of features extracted by tsfresh across all state variables.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor","title":"pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor","text":"<p>               Bases: <code>FeatureExtractor</code></p> <p>Feature extractor using nolds for nonlinear dynamics analysis.</p> <p>Computes nonlinear dynamics features for each trajectory with multiprocessing parallelization. Uses tsfresh-style FCParameters configuration for specifying which features to extract and with what parameters.</p> <p>Available features (passed directly to nolds):     * <code>lyap_r</code>: Largest Lyapunov exponent (Rosenstein's algorithm)     * <code>lyap_e</code>: Largest Lyapunov exponent (Eckmann's algorithm)     * <code>sampen</code>: Sample entropy     * <code>hurst_rs</code>: Hurst exponent (R/S analysis)     * <code>corr_dim</code>: Correlation dimension     * <code>dfa</code>: Detrended fluctuation analysis     * <code>mfhurst_b</code>: Multifractal Hurst exponent (basic method)     * <code>mfhurst_dm</code>: Multifractal Hurst exponent (DM method)</p> <pre><code># Default: extract lyap_r and corr_dim from all states\nextractor = NoldsFeatureExtractor(time_steady=9.0)\n\n# Only extract Lyapunov exponents with custom parameters\nextractor = NoldsFeatureExtractor(\n    time_steady=9.0,\n    features={\"lyap_r\": [{\"emb_dim\": 15}]},\n)\n\n# Per-state configuration\nextractor = NoldsFeatureExtractor(\n    time_steady=9.0,\n    features=None,\n    features_per_state={\n        0: {\"lyap_r\": None},\n        1: {\"corr_dim\": [{\"emb_dim\": 10}]},\n    },\n)\n\n# Multiple parameter sets for same feature\nextractor = NoldsFeatureExtractor(\n    time_steady=9.0,\n    features={\n        \"lyap_r\": [\n            {\"emb_dim\": 5},\n            {\"emb_dim\": 10},\n        ],\n    },\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Default 0.0.</p> <code>0.0</code> <code>features</code> <code>NoldsFCParameters | None</code> <p>Feature configuration for all states. Can be: * NoldsFCParameters dict: Feature names mapped to parameter lists * None: Skip states not in features_per_state Default extracts both lyap_r and corr_dim with nolds defaults.</p> <code>None</code> <code>features_per_state</code> <code>dict[int, NoldsFCParameters | None] | None</code> <p>Optional dict mapping state indices to FCParameters. Overrides <code>features</code> for specified states. Use None to skip a state.</p> <code>None</code> <code>n_jobs</code> <code>int | None</code> <p>Number of worker processes. If None, uses all CPU cores.</p> <code>None</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If nolds library is not installed.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names in format 'state_X__feature__params'.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If extract_features has not been called yet.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor.extract_features","title":"extract_features","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract nolds features from an ODE solution.</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution with shape (N, B, S).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Features tensor of shape (B, F) where F depends on configuration.</p>"},{"location":"api/feature-selector/","title":"Feature Selector","text":""},{"location":"api/feature-selector/#pybasin.feature_selector.default_feature_selector.DefaultFeatureSelector","title":"pybasin.feature_selector.default_feature_selector.DefaultFeatureSelector","text":"<p>               Bases: <code>Pipeline</code></p> <p>Feature selector combining variance threshold and correlation filtering.</p> <p>This class extends sklearn's Pipeline with two steps:</p> <ol> <li>VarianceThreshold: Removes features with variance below threshold</li> <li>CorrelationSelector: Removes highly correlated features (|corr| &gt; threshold)</li> </ol> <p>The correlation threshold uses absolute correlation values, meaning both positive and negative correlations above the threshold will trigger removal.</p> <p>As a Pipeline subclass, this implements the full sklearn transformer API: fit(), transform(), fit_transform(), get_params(), set_params(), etc.</p> <pre><code>selector = DefaultFeatureSelector(variance_threshold=0.01, correlation_threshold=0.95)\nfeatures_filtered = selector.fit_transform(features)\n</code></pre> <p>Attributes:</p> Name Type Description <code>variance_threshold</code> <code>float</code> <p>Minimum variance required to keep a feature.</p> <code>correlation_threshold</code> <code>float</code> <p>Maximum absolute correlation allowed between features. Features with |correlation| &gt; threshold will be removed.</p> <code>min_features</code> <code>int</code> <p>Minimum number of features to keep.</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.default_feature_selector.DefaultFeatureSelector-functions","title":"Functions","text":""},{"location":"api/feature-selector/#pybasin.feature_selector.default_feature_selector.DefaultFeatureSelector.get_support","title":"get_support","text":"<pre><code>get_support(indices: bool = False) -&gt; np.ndarray\n</code></pre> <p>Get mask or indices of features that passed the filter.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>bool</code> <p>If True, returns indices. If False, returns boolean mask.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Boolean mask or integer indices of selected features.</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector","title":"pybasin.feature_selector.correlation_selector.CorrelationSelector","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>Scikit-learn transformer to remove highly correlated features.</p> <p>This transformer removes features with high pairwise correlations, keeping only one feature from each correlated group.</p> <p>Attributes:</p> Name Type Description <code>threshold</code> <code>float</code> <p>Correlation threshold. Features with absolute correlation above this value will be considered redundant.</p> <code>min_features</code> <code>int</code> <p>Minimum number of features to keep. If removing correlated features would result in fewer than this many, some correlated features are retained.</p> <code>support_</code> <p>Boolean mask of selected features.</p> <code>n_features_in_</code> <p>Number of input features.</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector-functions","title":"Functions","text":""},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector.fit","title":"fit","text":"<pre><code>fit(X: ndarray, y: ndarray | None = None)\n</code></pre> <p>Compute which features to keep.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Training data of shape (n_samples, n_features).</p> required <code>y</code> <code>ndarray | None</code> <p>Not used, present for API consistency.</p> <code>None</code> <p>Returns:</p> Type Description <p>Fitted transformer.</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector.transform","title":"transform","text":"<pre><code>transform(X: ndarray) -&gt; np.ndarray\n</code></pre> <p>Remove correlated features.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Input data of shape (n_samples, n_features).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Data with correlated features removed, shape (n_samples, n_features_out).</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector.get_support","title":"get_support","text":"<pre><code>get_support(indices: bool = False)\n</code></pre> <p>Get a mask or indices of selected features.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>bool</code> <p>If True, return feature indices. Otherwise, return boolean mask.</p> <code>False</code> <p>Returns:</p> Type Description <p>Boolean mask or integer indices of selected features.</p>"},{"location":"api/plotters/","title":"Plotters","text":""},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter","title":"pybasin.plotters.matplotlib_plotter.MatplotlibPlotter","text":""},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter-functions","title":"Functions","text":""},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.__init__","title":"__init__","text":"<pre><code>__init__(bse: BasinStabilityEstimator)\n</code></pre> <p>Initialize the Plotter with a BasinStabilityEstimator instance.</p> <p>Parameters:</p> Name Type Description Default <code>bse</code> <code>BasinStabilityEstimator</code> <p>An instance of BasinStabilityEstimator.</p> required"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_basin_stability_bars","title":"plot_basin_stability_bars","text":"<pre><code>plot_basin_stability_bars(ax: Axes | None = None)\n</code></pre> <p>Plot basin stability values as a bar chart.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>Matplotlib axes to plot on. If None, creates a new figure.</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_state_space","title":"plot_state_space","text":"<pre><code>plot_state_space(ax: Axes | None = None)\n</code></pre> <p>Plot initial conditions in state space, colored by their attractor labels.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>Matplotlib axes to plot on. If None, creates a new figure.</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_feature_space","title":"plot_feature_space","text":"<pre><code>plot_feature_space(ax: Axes | None = None)\n</code></pre> <p>Plot feature space with classifier results.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>Matplotlib axes to plot on. If None, creates a new figure.</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_bse_results","title":"plot_bse_results","text":"<pre><code>plot_bse_results()\n</code></pre> <p>Generate diagnostic plots using the data stored in self.solution:     1. A bar plot of basin stability values.     2. A scatter plot of initial conditions (state space).     3. A scatter plot of the feature space with classifier results.     4. A placeholder plot for future use.</p> <p>This method combines the individual plotting functions into a 2x2 grid. For individual plots, use plot_basin_stability_bars(), plot_state_space(), or plot_feature_space() directly.</p>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_templates_phase_space","title":"plot_templates_phase_space","text":"<pre><code>plot_templates_phase_space(\n    x_var: int = 0, y_var: int = 1, z_var: int | None = None\n)\n</code></pre> <p>Plot trajectories for the template initial conditions in 2D or 3D phase space.</p>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_templates_trajectories","title":"plot_templates_trajectories","text":"<pre><code>plot_templates_trajectories(\n    plotted_var: int,\n    time_span: tuple[float, float] | None = None,\n)\n</code></pre> <p>Plot trajectories for the template initial conditions.</p> <p>Parameters:</p> Name Type Description Default <code>plotted_var</code> <code>int</code> <p>Index of the variable to plot.</p> required <code>time_span</code> <code>tuple[float, float] | None</code> <p>Time range to plot (t_start, t_end).</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.interactive_plotter.plotter.InteractivePlotter","title":"pybasin.plotters.interactive_plotter.plotter.InteractivePlotter","text":"<p>Interactive web-based plotter for basin stability visualization.</p> <p>Uses Dash with Mantine components for a modern UI and Plotly for interactive visualizations. Each page owns its controls, plot, and callbacks.</p> <p>Attributes:</p> Name Type Description <code>bse</code> <code>BasinStabilityEstimator</code> <p>BasinStabilityEstimator instance with computed results.</p> <code>state_labels</code> <p>Optional mapping of state indices to custom labels.</p> <code>app</code> <code>Dash | None</code> <p>Dash application instance.</p>"},{"location":"api/plotters/#pybasin.plotters.interactive_plotter.plotter.InteractivePlotter-functions","title":"Functions","text":""},{"location":"api/plotters/#pybasin.plotters.interactive_plotter.plotter.InteractivePlotter.__init__","title":"__init__","text":"<pre><code>__init__(\n    bse: BasinStabilityEstimator | BasinStabilityStudy,\n    state_labels: dict[int, str] | None = None,\n    options: InteractivePlotterOptions | None = None,\n)\n</code></pre> <p>Initialize the Plotter.</p> <p>Parameters:</p> Name Type Description Default <code>bse</code> <code>BasinStabilityEstimator | BasinStabilityStudy</code> <p>BasinStabilityEstimator or BasinStabilityStudy instance.</p> required <code>state_labels</code> <code>dict[int, str] | None</code> <p>Optional dict mapping state indices to labels, e.g., {0: \"\u03b8\", 1: \"\u03c9\"} for a pendulum system.</p> <code>None</code> <code>options</code> <code>InteractivePlotterOptions | None</code> <p>Optional configuration for default control values.</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.interactive_plotter.plotter.InteractivePlotter.run","title":"run","text":"<pre><code>run(port: int = 8050, debug: bool = False) -&gt; None\n</code></pre> <p>Launch the interactive plotter as a standalone Dash server.</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>int</code> <p>Port to run the server on (default: 8050).</p> <code>8050</code> <code>debug</code> <code>bool</code> <p>Enable Dash debug mode (default: False).</p> <code>False</code>"},{"location":"api/plotters/#pybasin.matplotlib_study_plotter.MatplotlibStudyPlotter","title":"pybasin.matplotlib_study_plotter.MatplotlibStudyPlotter","text":"<p>Matplotlib-based plotter for adaptive study basin stability results.</p> <p>Attributes:</p> Name Type Description <code>as_bse</code> <p>BasinStabilityStudy instance with computed results.</p>"},{"location":"api/plotters/#pybasin.matplotlib_study_plotter.MatplotlibStudyPlotter-functions","title":"Functions","text":""},{"location":"api/plotters/#pybasin.matplotlib_study_plotter.MatplotlibStudyPlotter.__init__","title":"__init__","text":"<pre><code>__init__(as_bse: BasinStabilityStudy)\n</code></pre> <p>Initialize the plotter with an BasinStabilityStudy instance.</p> <p>Parameters:</p> Name Type Description Default <code>as_bse</code> <code>BasinStabilityStudy</code> <p>An instance of BasinStabilityStudy.</p> required"},{"location":"api/plotters/#pybasin.matplotlib_study_plotter.MatplotlibStudyPlotter.plot_basin_stability_variation","title":"plot_basin_stability_variation","text":"<pre><code>plot_basin_stability_variation(\n    interval: Literal[\"linear\", \"log\"] = \"linear\",\n    show: bool = True,\n)\n</code></pre> <p>Plot all basin stability values against parameter variation in a single plot.</p> <p>Parameters:</p> Name Type Description Default <code>interval</code> <code>Literal['linear', 'log']</code> <p>Indicates whether the x-axis should use a linear or logarithmic scale. Options:  - 'linear': Default linear scale. - 'log': Logarithmic scale, e.g., when using <code>2 * np.logspace(...)</code>.</p> <code>'linear'</code> <code>show</code> <code>bool</code> <p>Whether to display the plot. If False, returns the figure without showing.</p> <code>True</code> <p>Returns:</p> Type Description <p>The matplotlib Figure object.</p>"},{"location":"api/plotters/#pybasin.matplotlib_study_plotter.MatplotlibStudyPlotter.plot_bifurcation_diagram","title":"plot_bifurcation_diagram","text":"<pre><code>plot_bifurcation_diagram(dof: list[int], show: bool = True)\n</code></pre> <p>Plot bifurcation diagram showing attractor locations over parameter variation.</p> <p>For each parameter value, the method extracts the bifurcation amplitudes (i.e. solution.bifurcation_amplitudes), selects the desired DOFs, applies k-means clustering and then plots the cluster centers as a function of the parameter.</p> <p>Unbounded trajectories are automatically filtered out before clustering, as bifurcation amplitudes are only computed for bounded trajectories.</p> <p>Parameters:</p> Name Type Description Default <code>dof</code> <code>list[int]</code> <p>List of indices of the state variables (DOFs) to plot.</p> required <code>show</code> <code>bool</code> <p>Whether to display the plot. If False, returns the figure without showing.</p> <code>True</code> <p>Returns:</p> Type Description <p>The matplotlib Figure object.</p>"},{"location":"api/predictors/","title":"Predictors","text":""},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor","title":"pybasin.predictors.base.LabelPredictor","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for label prediction algorithms.</p> <p>This class provides a common interface for both supervised classifiers and unsupervised clusterers used in basin stability analysis.</p>"},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor.predict_labels","title":"predict_labels  <code>abstractmethod</code>","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels for the given features.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array to predict labels for.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of predicted labels.</p>"},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor.needs_feature_names","title":"needs_feature_names","text":"<pre><code>needs_feature_names() -&gt; bool\n</code></pre> <p>Check if this predictor requires feature names to be set before prediction.</p> <p>Override this method and return True if your predictor needs to parse feature names (e.g., to identify specific features like 'variance' or 'amplitude').</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if set_feature_names() must be called before predict_labels().</p>"},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor.set_feature_names","title":"set_feature_names","text":"<pre><code>set_feature_names(feature_names: list[str]) -&gt; None\n</code></pre> <p>Set feature names for predictors that require them.</p> <p>Called automatically by BasinStabilityEstimator if needs_feature_names() returns True. Override this method to parse and store feature name indices.</p> <p>Parameters:</p> Name Type Description Default <code>feature_names</code> <code>list[str]</code> <p>List of feature names matching the feature array columns.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If called on a predictor that doesn't need feature names.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClustererPredictor","title":"pybasin.predictors.base.ClustererPredictor","text":"<p>               Bases: <code>LabelPredictor</code></p> <p>Base class for unsupervised clustering algorithms.</p> <p>Unsupervised learning: Discovers patterns and groups in data without requiring labeled examples. Use when attractors/basins are unknown and need to be discovered.</p> <p>Unlike ClassifierPredictor, this class does not require template initial conditions or ODE parameters, as unsupervised methods work directly on features without needing labeled training data.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor","title":"pybasin.predictors.base.ClassifierPredictor","text":"<p>               Bases: <code>LabelPredictor</code></p> <p>Base class for supervised classifiers that require labeled template data.</p> <p>Supervised learning: Requires example trajectories with known labels to learn the mapping from features to basin/attractor labels. Use when attractors are known.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor-attributes","title":"Attributes","text":""},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.has_dedicated_solver","title":"has_dedicated_solver  <code>property</code>","text":"<pre><code>has_dedicated_solver: bool\n</code></pre> <p>Check if the classifier has its own dedicated solver for template integration.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.__init__","title":"__init__","text":"<pre><code>__init__(\n    template_y0: list[list[float]],\n    labels: list[str],\n    ode_params: Mapping[str, Any],\n    solver: SolverProtocol | None = None,\n)\n</code></pre> <p>Initialize the supervised classifier.</p> <p>Parameters:</p> Name Type Description Default <code>template_y0</code> <code>list[list[float]]</code> <p>Template initial conditions as a list of lists (e.g., [[0.5, 0.0], [2.7, 0.0]]). Will be converted to tensor with appropriate device during integration.</p> required <code>labels</code> <code>list[str]</code> <p>Ground truth labels for template conditions.</p> required <code>ode_params</code> <code>Mapping[str, Any]</code> <p>ODE parameters mapping (dict or TypedDict with numeric values).</p> required <code>solver</code> <code>SolverProtocol | None</code> <p>Optional solver for template integration. If provided, this solver will be used instead of the main solver (useful for CPU-based template integration when templates are few).</p> <code>None</code>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.integrate_templates","title":"integrate_templates","text":"<pre><code>integrate_templates(\n    solver: SolverProtocol | None,\n    ode_system: ODESystemProtocol,\n) -&gt; None\n</code></pre> <p>Integrate ODE for template initial conditions (without feature extraction).</p> <p>This method should be called before fit_with_features() to allow the main feature extraction to fit the scaler first.</p> <p>By default, if no dedicated solver was provided at init, this method will automatically create a CPU variant of the passed solver. This is because CPU is typically faster than GPU for small batch sizes (like templates).</p> <p>Parameters:</p> Name Type Description Default <code>solver</code> <code>SolverProtocol | None</code> <p>Fallback solver if no solver was provided at init. Can be None if a solver was provided during classifier initialization.</p> required <code>ode_system</code> <code>ODESystemProtocol</code> <p>ODE system to integrate (ODESystem or JaxODESystem).</p> required"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.fit_with_features","title":"fit_with_features","text":"<pre><code>fit_with_features(\n    feature_extractor: FeatureExtractor,\n    feature_selector: Any | None = None,\n) -&gt; None\n</code></pre> <p>Fit the classifier using pre-integrated template solutions.</p> <p>Must call integrate_templates() first to populate self.solution.</p> <p>Parameters:</p> Name Type Description Default <code>feature_extractor</code> <code>FeatureExtractor</code> <p>Feature extractor to transform trajectories.</p> required <code>feature_selector</code> <code>Any | None</code> <p>Optional feature selector (already fitted on main data). If provided, applies the same filtering to template features.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If filtering removes all template features.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.fit","title":"fit","text":"<pre><code>fit(\n    solver: SolverProtocol,\n    ode_system: ODESystemProtocol,\n    feature_extractor: FeatureExtractor,\n) -&gt; None\n</code></pre> <p>Fit the classifier using template initial conditions.</p> <p>WARNING: This method extracts features from templates FIRST, which means the scaler will be fitted on template data (often just 2 samples). For better normalization, use integrate_templates() + fit_with_features() to allow the main data to fit the scaler first.</p> <p>Parameters:</p> Name Type Description Default <code>solver</code> <code>SolverProtocol</code> <p>Solver to integrate the ODE system (Solver or JaxSolver).</p> required <code>ode_system</code> <code>ODESystemProtocol</code> <p>ODE system to integrate (ODESystem or JaxODESystem).</p> required <code>feature_extractor</code> <code>FeatureExtractor</code> <p>Feature extractor to transform trajectories.</p> required"},{"location":"api/predictors/#pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer","title":"pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer","text":"<p>               Bases: <code>ClustererPredictor</code></p> <p>HDBSCAN clustering for basin stability analysis with optional auto-tuning and noise assignment (unsupervised learning).</p>"},{"location":"api/predictors/#pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer.__init__","title":"__init__","text":"<pre><code>__init__(\n    clusterer: Any = None,\n    assign_noise: bool = False,\n    k_neighbors: int = 5,\n    auto_tune: bool = False,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize HDBSCAN clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>clusterer</code> <code>Any</code> <p>HDBSCAN instance, or None to create default.</p> <code>None</code> <code>assign_noise</code> <code>bool</code> <p>Whether to assign noise points to nearest clusters using KNN.</p> <code>False</code> <code>k_neighbors</code> <code>int</code> <p>Number of neighbors for KNN noise assignment.</p> <code>5</code> <code>auto_tune</code> <code>bool</code> <p>Whether to automatically tune min_cluster_size using silhouette score.</p> <code>False</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for HDBSCAN if clusterer is None. Common: min_cluster_size=50, min_samples=10</p> <code>{}</code>"},{"location":"api/predictors/#pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels using HDBSCAN clustering with optional noise assignment.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array to cluster.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Cluster labels.</p>"},{"location":"api/predictors/#pybasin.predictors.dbscan_clusterer.DBSCANClusterer","title":"pybasin.predictors.dbscan_clusterer.DBSCANClusterer","text":"<p>               Bases: <code>ClustererPredictor</code></p> <p>DBSCAN clustering for basin stability analysis (unsupervised learning).</p>"},{"location":"api/predictors/#pybasin.predictors.dbscan_clusterer.DBSCANClusterer-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.dbscan_clusterer.DBSCANClusterer.__init__","title":"__init__","text":"<pre><code>__init__(clusterer: DBSCAN | None = None, **kwargs: Any)\n</code></pre> <p>Initialize DBSCAN clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>clusterer</code> <code>DBSCAN | None</code> <p>DBSCAN instance, or None to create default.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for DBSCAN if clusterer is None.</p> <code>{}</code>"},{"location":"api/predictors/#pybasin.predictors.dbscan_clusterer.DBSCANClusterer.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels using DBSCAN clustering.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array to cluster.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Cluster labels.</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer","title":"pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer","text":"<p>               Bases: <code>ClustererPredictor</code></p> <p>Two-stage hierarchical clustering for dynamical systems.</p> <p>This clusterer uses physics-based heuristics to classify trajectories into attractor types (Stage 1) and then sub-classifies within each type (Stage 2).</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer--stage-1-attractor-type-classification","title":"Stage 1: Attractor Type Classification","text":"<p>Fixed Point (FP) Detection:     Heuristic: variance &lt; fp_variance_threshold</p> <pre><code>A trajectory is classified as converging to a fixed point if the variance\nof its steady-state values is extremely low. The threshold should be set\nbased on the expected numerical precision of your integration.\n\nIMPORTANT: If features are normalized/scaled (e.g., StandardScaler), the\nvariance values will be transformed. For normalized features with unit\nvariance, use a threshold relative to 1.0 (e.g., 1e-4). For unnormalized\nfeatures, use absolute thresholds based on your system's scale.\n</code></pre> <p>Limit Cycle (LC) Detection:     Heuristic: (periodicity_strength &gt; lc_periodicity_threshold AND                variance &lt; chaos_variance_threshold) OR has_drift</p> <pre><code>A trajectory is classified as a limit cycle if:\n1. It shows strong periodic behavior (high autocorrelation periodicity)\n   AND has bounded variance (not chaotic), OR\n2. It shows monotonic drift (rotating solutions like pendulum rotations)\n\nThe periodicity_strength comes from autocorrelation analysis and ranges\nfrom 0 (no periodicity) to 1 (perfect periodicity). Values above 0.5\ntypically indicate clear periodic behavior.\n</code></pre> <p>Chaos Detection:     Heuristic: NOT FP AND NOT LC (default fallback)</p> <pre><code>Trajectories that don't meet FP or LC criteria are classified as chaotic.\nHigh variance combined with low periodicity strength indicates chaos.\n</code></pre>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer--stage-2-sub-classification","title":"Stage 2: Sub-classification","text":"<p>Within each attractor type, trajectories are further clustered: - FP: Clustered by steady-state location (mean values) - LC: Hierarchically clustered by period number, then amplitude/mean - Chaos: Clustered by spatial mean location</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer--required-features","title":"Required Features","text":"<p>Feature names must follow the convention: state_X__feature_name</p> <p>Required base features:     - variance: Steady-state variance (FP detection)     - amplitude: Peak-to-peak amplitude (LC sub-classification)     - mean: Steady-state mean (FP/chaos sub-classification)     - linear_trend__attr_slope: Linear drift rate (rotating LC detection)     - autocorrelation_periodicity__output_strength: Periodicity measure [0-1]     - autocorrelation_periodicity__output_period: Detected period     - spectral_frequency_ratio: Ratio for period-n detection</p> <p>Note: This clusterer requires feature names to be set via set_feature_names() before calling predict_labels(). The BasinStabilityEstimator handles this automatically during the estimation process.</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer.__init__","title":"__init__","text":"<pre><code>__init__(\n    drift_threshold: float = 0.1,\n    tiers: list[str] | None = None,\n    fp_variance_threshold: float = 1e-06,\n    fp_sub_classifier: LabelPredictor | None = None,\n    lc_periodicity_threshold: float = 0.5,\n    lc_sub_classifier: LabelPredictor | None = None,\n    chaos_variance_threshold: float = 5.0,\n    chaos_sub_classifier: LabelPredictor | None = None,\n)\n</code></pre> <p>Initialize the dynamical system clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>drift_threshold</code> <code>float</code> <p>Minimum |slope| to consider a dimension as drifting. Drifting dimensions (e.g., pendulum angle during rotation) are excluded from variance/mean calculations for FP and chaos sub-classification to avoid spurious splits. Also used to detect rotating limit cycles. Units: [state_units / time_units]. Default: 0.1.</p> <code>0.1</code> <code>tiers</code> <code>list[str] | None</code> <p>List of attractor types to detect, in priority order. First matching tier wins. Options: \"FP\", \"LC\", \"chaos\". Default: [\"FP\", \"LC\", \"chaos\"].</p> <code>None</code> <code>fp_variance_threshold</code> <code>float</code> <p>Maximum variance to classify as fixed point. For unnormalized features, set based on expected steady-state fluctuations (e.g., 1e-6 for well-converged integrations). For normalized features (unit variance), use relative threshold (e.g., 1e-4 meaning 0.01% of typical variance). Default: 1e-6.</p> <code>1e-06</code> <code>fp_sub_classifier</code> <code>LabelPredictor | None</code> <p>Custom sub-classifier for fixed points. Input: mean values per non-drifting dimension. Default: HDBSCAN with min_cluster_size=50.</p> <code>None</code> <code>lc_periodicity_threshold</code> <code>float</code> <p>Minimum periodicity strength [0-1] to classify as limit cycle. The periodicity strength measures how well the autocorrelation matches periodic behavior (0.0 = no periodic pattern, 0.3-0.5 = weak/noisy, 0.5-0.8 = clear periodic, 0.8-1.0 = strong/clean limit cycle). Default: 0.5.</p> <code>0.5</code> <code>lc_sub_classifier</code> <code>LabelPredictor | None</code> <p>Custom sub-classifier for limit cycles. Input: [freq_ratio, amplitude, mean] features. Default: Hierarchical period-based clustering.</p> <code>None</code> <code>chaos_variance_threshold</code> <code>float</code> <p>Maximum variance for limit cycle. Trajectories with variance above this AND low periodicity are classified as chaotic. Set based on expected LC amplitude range. For normalized features, typical LC variance is ~0.5-2.0. Default: 5.0.</p> <code>5.0</code> <code>chaos_sub_classifier</code> <code>LabelPredictor | None</code> <p>Custom sub-classifier for chaotic attractors. Input: mean values per dimension. Default: HDBSCAN with auto_tune=True.</p> <code>None</code>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer.needs_feature_names","title":"needs_feature_names","text":"<pre><code>needs_feature_names() -&gt; bool\n</code></pre> <p>This clusterer requires feature names to parse physics-based features.</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer.set_feature_names","title":"set_feature_names","text":"<pre><code>set_feature_names(feature_names: list[str]) -&gt; None\n</code></pre> <p>Set feature names and build feature indices.</p> <p>Parameters:</p> Name Type Description Default <code>feature_names</code> <code>list[str]</code> <p>List of feature names matching the feature array columns.</p> required"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels using two-stage hierarchical clustering.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array of shape (n_samples, n_features).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of predicted labels with format \"TYPE_subcluster\".</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If set_feature_names() was not called before prediction.</p>"},{"location":"api/predictors/#pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer","title":"pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer","text":"<p>               Bases: <code>ClustererPredictor</code></p> <p>Meta-clusterer for separately labeling unbounded trajectories.</p> <p>This meta-clusterer wraps another ClustererPredictor and handles unbounded trajectories separately. Unbounded trajectories are identified using a detector function and assigned a special label, while bounded trajectories are processed using the wrapped clusterer.</p> <p>This is particularly useful in basin stability calculations where some trajectories may diverge to infinity (e.g., in the Lorenz system). By excluding unbounded trajectories from clustering, the wrapped clusterer can focus on discovering patterns in bounded basins without contamination from divergent trajectories.</p> <p>Example usage:</p> <pre><code>from pybasin.predictors.unboundedness_clusterer import UnboundednessClusterer\nfrom pybasin.predictors.hdbscan_clusterer import HDBSCANClusterer\nimport numpy as np\n\n# Create features with some unbounded samples\nfeatures = np.random.randn(100, 10)\nfeatures[0, :] = np.inf  # Unbounded sample\nfeatures[1, :] = 1e10  # Unbounded sample\n\n# Wrap HDBSCAN with unboundedness handling\nbase_clusterer = HDBSCANClusterer(min_cluster_size=5)\nclusterer = UnboundednessClusterer(base_clusterer)\nlabels = clusterer.predict_labels(features)\nprint(f\"Unbounded samples: {np.sum(labels == 'unbounded')}\")\n</code></pre> <p>Notes:</p> <ul> <li>Only bounded samples are passed to the wrapped clusterer for clustering</li> <li>The unbounded label is automatically tracked and returned for unbounded samples</li> <li>If all samples are unbounded, all labels will be the unbounded label</li> <li>This prevents unbounded trajectories from distorting cluster centroids and boundaries</li> </ul> <p>Attributes:</p> Name Type Description <code>clusterer</code> <p>The wrapped clusterer instance.</p> <code>unbounded_detector</code> <p>Function used to detect unbounded trajectories.</p> <code>unbounded_label</code> <p>Label assigned to unbounded trajectories.</p>"},{"location":"api/predictors/#pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer.__init__","title":"__init__","text":"<pre><code>__init__(\n    clusterer: ClustererPredictor,\n    unbounded_detector: Callable[[ndarray], ndarray]\n    | None = None,\n    unbounded_label: int | str = \"unbounded\",\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize the unboundedness meta-clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>clusterer</code> <code>ClustererPredictor</code> <p>Base clusterer to use for bounded trajectories.</p> required <code>unbounded_detector</code> <code>Callable[[ndarray], ndarray] | None</code> <p>Function to detect unbounded trajectories.</p> <code>None</code> <code>unbounded_label</code> <code>int | str</code> <p>Label to assign to unbounded trajectories.</p> <code>'unbounded'</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments passed to ClustererPredictor base (unused).</p> <code>{}</code>"},{"location":"api/predictors/#pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels for features, separating unbounded trajectories.</p> <p>Unbounded trajectories are detected and labeled separately, while bounded trajectories are clustered using the wrapped clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array of shape (n_samples, n_features).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of predicted labels with unbounded trajectories labeled separately.</p>"},{"location":"api/predictors/#pybasin.predictors.knn_classifier.KNNClassifier","title":"pybasin.predictors.knn_classifier.KNNClassifier","text":"<p>               Bases: <code>ClassifierPredictor</code></p> <p>K-Nearest Neighbors classifier for basin stability analysis (supervised learning).</p>"},{"location":"api/predictors/#pybasin.predictors.knn_classifier.KNNClassifier-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.knn_classifier.KNNClassifier.__init__","title":"__init__","text":"<pre><code>__init__(\n    classifier: KNeighborsClassifier | None,\n    template_y0: list[list[float]],\n    labels: list[str],\n    ode_params: Mapping[str, Any],\n    solver: SolverProtocol | None = None,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize KNN classifier.</p> <p>Parameters:</p> Name Type Description Default <code>classifier</code> <code>KNeighborsClassifier | None</code> <p>KNeighborsClassifier instance, or None to create default.</p> required <code>template_y0</code> <code>list[list[float]]</code> <p>Template initial conditions as a list of lists.</p> required <code>labels</code> <code>list[str]</code> <p>Ground truth labels.</p> required <code>ode_params</code> <code>Mapping[str, Any]</code> <p>ODE parameters.</p> required <code>solver</code> <code>SolverProtocol | None</code> <p>Optional solver for template integration.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for KNeighborsClassifier if classifier is None.</p> <code>{}</code>"},{"location":"api/predictors/#pybasin.predictors.knn_classifier.KNNClassifier.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels using the fitted KNN classifier.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array to classify.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Predicted labels.</p>"},{"location":"api/samplers/","title":"Samplers","text":""},{"location":"api/samplers/#pybasin.sampler.Sampler","title":"pybasin.sampler.Sampler","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for sampling initial conditions using PyTorch.</p>"},{"location":"api/samplers/#pybasin.sampler.Sampler-functions","title":"Functions","text":""},{"location":"api/samplers/#pybasin.sampler.Sampler.__init__","title":"__init__","text":"<pre><code>__init__(\n    min_limits: list[float],\n    max_limits: list[float],\n    device: str | None = None,\n)\n</code></pre> <p>Initialize the sampler.</p> <p>Parameters:</p> Name Type Description Default <code>min_limits</code> <code>list[float]</code> <p>List of minimum values for each state.</p> required <code>max_limits</code> <code>list[float]</code> <p>List of maximum values for each state.</p> required <code>device</code> <code>str | None</code> <p>Device to use ('cuda', 'cpu', or None for auto-detect).</p> <code>None</code>"},{"location":"api/samplers/#pybasin.sampler.Sampler.sample","title":"sample  <code>abstractmethod</code>","text":"<pre><code>sample(n: int) -&gt; torch.Tensor\n</code></pre> <p>Generate n samples for the initial conditions.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of samples.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Sampled initial conditions as a tensor of shape (n, state_dim).</p>"},{"location":"api/samplers/#pybasin.sampler.UniformRandomSampler","title":"pybasin.sampler.UniformRandomSampler","text":"<p>               Bases: <code>Sampler</code></p> <p>Generates random samples using a uniform distribution within the specified range.</p>"},{"location":"api/samplers/#pybasin.sampler.GridSampler","title":"pybasin.sampler.GridSampler","text":"<p>               Bases: <code>Sampler</code></p> <p>Generates evenly spaced samples in a grid pattern within the specified range.</p> <p>Handles fixed dimensions (where min == max) by only distributing grid points along varying dimensions. For example, with limits [-10, 10], [-20, 20], [0, 0] and n=20000, the grid uses n^(1/2) \u2248 142 points per varying dimension (x, y) and a single point for the fixed dimension (z), yielding 142 x 142 x 1 = 20164 unique samples instead of 28 x 28 x 28 = 21952 with many duplicates.</p>"},{"location":"api/samplers/#pybasin.sampler.GaussianSampler","title":"pybasin.sampler.GaussianSampler","text":"<p>               Bases: <code>Sampler</code></p> <p>Generates samples using a Gaussian distribution around the midpoint.</p>"},{"location":"api/solution/","title":"Solution","text":""},{"location":"api/solution/#pybasin.solution.Solution","title":"pybasin.solution.Solution","text":"<p>Solution: Represents the time integration result for a single initial condition.</p> <p>This class stores:</p> <ul> <li>The initial condition used for integration.</li> <li>The time series result from integration.</li> <li>Features extracted from the trajectory.</li> <li>Optional labels/classification for each trajectory.</li> <li>Optional model parameters that were used in the integration.</li> <li>Optional bifurcation amplitudes extracted from the trajectory.</li> </ul> <p>Attributes:</p> Name Type Description <code>initial_condition</code> <code>Tensor</code> <p>The initial condition used for integration (shape: B, S).</p> <code>time</code> <code>Tensor</code> <p>Time points of the solution (shape: N).</p> <code>y</code> <code>Tensor</code> <p>State values over time (shape: N, B, S).</p> <code>features</code> <code>Tensor | None</code> <p>Filtered features used for classification.</p> <code>extracted_features</code> <code>Tensor | None</code> <p>Original extracted features before filtering.</p> <code>extracted_feature_names</code> <code>list[str] | None</code> <p>Names of extracted features.</p> <code>filtered_feature_names</code> <code>list[str] | None</code> <p>Names of filtered features.</p> <code>labels</code> <code>ndarray | None</code> <p>Labels assigned to each solution in the batch.</p> <code>model_params</code> <code>dict[str, Any] | None</code> <p>Parameters of the ODE model.</p> <code>bifurcation_amplitudes</code> <code>Tensor | None</code> <p>Maximum absolute values along time dimension.</p>"},{"location":"api/solution/#pybasin.solution.Solution-functions","title":"Functions","text":""},{"location":"api/solution/#pybasin.solution.Solution.__init__","title":"__init__","text":"<pre><code>__init__(\n    initial_condition: Tensor,\n    time: Tensor,\n    y: Tensor,\n    features: Tensor | None = None,\n    labels: ndarray | None = None,\n    model_params: dict[str, float] | None = None,\n)\n</code></pre> <p>Initialize the Solution object.</p> <p>Parameters:</p> Name Type Description Default <code>initial_condition</code> <code>Tensor</code> <p>shape: (B, S) =&gt; B batches, S state variables</p> required <code>time</code> <code>Tensor</code> <p>shape: (N,) =&gt; N time points</p> required <code>y</code> <code>Tensor</code> <p>shape: (N, B, S) =&gt; N time points, B batches, S state variables</p> required <code>features</code> <code>Tensor | None</code> <p>Optional features describing the trajectory.</p> <code>None</code> <code>labels</code> <code>ndarray | None</code> <p>Optional classification labels for the solutions.</p> <code>None</code> <code>model_params</code> <code>dict[str, float] | None</code> <p>Optional dictionary of model parameters used in the simulation.</p> <code>None</code>"},{"location":"api/solution/#pybasin.solution.Solution.set_labels","title":"set_labels","text":"<pre><code>set_labels(labels: ndarray)\n</code></pre> <p>Assign a label to this solution.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>ndarray</code> <p>The label to assign from the classification results.</p> required"},{"location":"api/solution/#pybasin.solution.Solution.set_extracted_features","title":"set_extracted_features","text":"<pre><code>set_extracted_features(features: Tensor, names: list[str])\n</code></pre> <p>Store extracted features before filtering.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>Tensor</code> <p>Extracted feature tensor.</p> required <code>names</code> <code>list[str]</code> <p>List of feature names.</p> required"},{"location":"api/solution/#pybasin.solution.Solution.set_features","title":"set_features","text":"<pre><code>set_features(\n    features: Tensor, names: list[str] | None = None\n)\n</code></pre> <p>Store features extracted from the trajectory.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>Tensor</code> <p>A feature vector describing the solution (typically filtered).</p> required <code>names</code> <code>list[str] | None</code> <p>Optional list of feature names (for filtered features).</p> <code>None</code>"},{"location":"api/solution/#pybasin.solution.Solution.get_summary","title":"get_summary","text":"<pre><code>get_summary() -&gt; dict[str, Any]\n</code></pre> <p>Return a summary of the solution.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with key information about the solution.</p>"},{"location":"api/solvers/","title":"Solvers","text":""},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver","title":"pybasin.solvers.jax_solver.JaxSolver","text":"<p>High-performance ODE solver using JAX and Diffrax for native JAX ODE systems.</p> <p>This solver is optimized for JaxODESystem instances and provides the fastest integration performance by avoiding any PyTorch callbacks. It uses JIT compilation and vmap for efficient batch processing.</p> <p>The interface is compatible with other solvers - it accepts PyTorch tensors and returns PyTorch tensors, but internally uses JAX for maximum performance.</p> <p>See also: Diffrax documentation</p> <p>Citation:</p> <pre><code>@phdthesis{kidger2021on,\n    title={{O}n {N}eural {D}ifferential {E}quations},\n    author={Patrick Kidger},\n    year={2021},\n    school={University of Oxford},\n}\n</code></pre> <p>Example usage:</p> <pre><code>from pybasin.jax_ode_system import JaxODESystem\nfrom pybasin.solvers import JaxSolver\nimport torch\n\nclass MyODE(JaxODESystem):\n    def ode(self, t, y):\n        return -y  # Simple decay\n    def get_str(self):\n        return \"decay\"\n\nsolver = JaxSolver(time_span=(0, 10), n_steps=100)\ny0 = torch.tensor([[1.0, 2.0]])  # batch=1, dims=2\nt, y = solver.integrate(MyODE({}), y0)\n</code></pre>"},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver-functions","title":"Functions","text":""},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver.__init__","title":"__init__","text":"<pre><code>__init__(\n    time_span: tuple[float, float] = (0, 1000),\n    n_steps: int | None = 1000,\n    device: str | None = None,\n    solver: Any | None = None,\n    rtol: float = 1e-08,\n    atol: float = 1e-06,\n    max_steps: int = 16**5,\n    use_cache: bool = True,\n    event_fn: Callable[[Any, Array, Any], Array]\n    | None = None,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize JaxSolver.</p> <p>Parameters:</p> Name Type Description Default <code>time_span</code> <code>tuple[float, float]</code> <p>Tuple (t_start, t_end) defining the integration interval. Defaults to (0, 1000).</p> <code>(0, 1000)</code> <code>n_steps</code> <code>int | None</code> <p>Number of evaluation points. Defaults to 1000.</p> <code>1000</code> <code>device</code> <code>str | None</code> <p>Device to use ('cuda', 'gpu', 'cpu', or None for auto-detect).</p> <code>None</code> <code>solver</code> <code>Any | None</code> <p>Diffrax solver instance (e.g., Dopri5(), Tsit5()). Defaults to Dopri5().</p> <code>None</code> <code>rtol</code> <code>float</code> <p>Relative tolerance for adaptive stepping. Defaults to 1e-8.</p> <code>1e-08</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for adaptive stepping. Defaults to 1e-6.</p> <code>1e-06</code> <code>max_steps</code> <code>int</code> <p>Maximum number of steps for the integrator.</p> <code>16 ** 5</code> <code>use_cache</code> <code>bool</code> <p>Whether to use caching for integration results. Defaults to True.</p> <code>True</code> <code>event_fn</code> <code>Callable[[Any, Array, Any], Array] | None</code> <p>Optional event function for early termination. Should return positive when integration should continue, negative/zero to stop. Signature: (t, y, args) -&gt; scalar Array.</p> <code>None</code>"},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver.with_device","title":"with_device","text":"<pre><code>with_device(device: str) -&gt; JaxSolver\n</code></pre> <p>Create a copy of this solver configured for a different device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>str</code> <p>Target device ('cpu', 'cuda', 'gpu').</p> required <p>Returns:</p> Type Description <code>JaxSolver</code> <p>New JaxSolver instance with the same configuration but different device.</p>"},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver.integrate","title":"integrate","text":"<pre><code>integrate(\n    ode_system: ODESystemProtocol, y0: Tensor\n) -&gt; tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Solve the ODE system and return the evaluation time points and solution.</p> <p>Parameters:</p> Name Type Description Default <code>ode_system</code> <code>ODESystemProtocol</code> <p>An instance of JaxODESystem.</p> required <code>y0</code> <code>Tensor</code> <p>Initial conditions as PyTorch tensor with shape (batch, n_dims).</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>Tuple (t_eval, y_values) as PyTorch tensors where y_values has shape (n_steps, batch, n_dims).</p>"},{"location":"api/solvers/#pybasin.solver.TorchDiffEqSolver","title":"pybasin.solver.TorchDiffEqSolver","text":"<p>               Bases: <code>Solver</code></p> <p>Differentiable ODE solver with full GPU support and O(1)-memory backpropagation.</p> <p>Uses the adjoint method for memory-efficient gradient computation through ODE solutions. Supports adaptive-step (dopri5, dopri8, bosh3) and fixed-step (euler, rk4) methods.</p> <p>See also: torchdiffeq GitHub</p> <p>Citation:</p> <pre><code>@misc{torchdiffeq,\n    author={Chen, Ricky T. Q.},\n    title={torchdiffeq},\n    year={2018},\n    url={https://github.com/rtqichen/torchdiffeq},\n}\n</code></pre>"},{"location":"api/solvers/#pybasin.solver.TorchDiffEqSolver-functions","title":"Functions","text":""},{"location":"api/solvers/#pybasin.solver.TorchDiffEqSolver.__init__","title":"__init__","text":"<pre><code>__init__(\n    time_span: tuple[float, float],\n    fs: float | None = None,\n    n_steps: int | None = None,\n    device: str | None = None,\n    method: str = \"dopri5\",\n    rtol: float = 1e-08,\n    atol: float = 1e-06,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize TorchDiffEqSolver.</p> <p>Parameters:</p> Name Type Description Default <code>time_span</code> <code>tuple[float, float]</code> <p>Tuple (t_start, t_end) defining the integration interval.</p> required <code>fs</code> <code>float | None</code> <p>Sampling frequency (Hz). DEPRECATED: use n_steps instead.</p> <code>None</code> <code>n_steps</code> <code>int | None</code> <p>Number of evaluation points. If None, defaults to 500.</p> <code>None</code> <code>device</code> <code>str | None</code> <p>Device to use ('cuda', 'cpu', or None for auto-detect).</p> <code>None</code> <code>method</code> <code>str</code> <p>Integration method from tordiffeq.odeint.</p> <code>'dopri5'</code> <code>rtol</code> <code>float</code> <p>Relative tolerance for adaptive stepping.</p> <code>1e-08</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for adaptive stepping.</p> <code>1e-06</code>"},{"location":"api/solvers/#pybasin.solver.TorchDiffEqSolver.with_device","title":"with_device","text":"<pre><code>with_device(device: str) -&gt; TorchDiffEqSolver\n</code></pre> <p>Create a copy of this solver configured for a different device.</p>"},{"location":"api/solvers/#pybasin.solver.TorchOdeSolver","title":"pybasin.solver.TorchOdeSolver","text":"<p>               Bases: <code>Solver</code></p> <p>Parallel ODE solver with independent step sizes per batch element.</p> <p>Compatible with PyTorch's JIT compiler for performance optimization. Unlike other solvers, torchode can take different step sizes for each sample in a batch, avoiding performance traps for problems of varying stiffness.</p> <p>See also: torchode documentation</p> <p>Citation:</p> <pre><code>@inproceedings{lienen2022torchode,\n    title = {torchode: A Parallel {ODE} Solver for PyTorch},\n    author = {Marten Lienen and Stephan G{\"u}nnemann},\n    booktitle = {The Symbiosis of Deep Learning and Differential Equations II, NeurIPS},\n    year = {2022},\n    url = {https://openreview.net/forum?id=uiKVKTiUYB0}\n}\n</code></pre>"},{"location":"api/solvers/#pybasin.solver.TorchOdeSolver-functions","title":"Functions","text":""},{"location":"api/solvers/#pybasin.solver.TorchOdeSolver.__init__","title":"__init__","text":"<pre><code>__init__(\n    time_span: tuple[float, float],\n    fs: float | None = None,\n    n_steps: int | None = None,\n    device: str | None = None,\n    method: str = \"dopri5\",\n    rtol: float = 1e-08,\n    atol: float = 1e-06,\n    use_jit: bool = False,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize TorchOdeSolver.</p> <p>Parameters:</p> Name Type Description Default <code>time_span</code> <code>tuple[float, float]</code> <p>Tuple (t_start, t_end) defining the integration interval.</p> required <code>fs</code> <code>float | None</code> <p>Sampling frequency (Hz). DEPRECATED: use n_steps instead.</p> <code>None</code> <code>n_steps</code> <code>int | None</code> <p>Number of evaluation points. If None, defaults to 500.</p> <code>None</code> <code>device</code> <code>str | None</code> <p>Device to use ('cuda', 'cpu', or None for auto-detect).</p> <code>None</code> <code>method</code> <code>str</code> <p>Integration method ('dopri5', 'tsit5', 'euler', 'heun').</p> <code>'dopri5'</code> <code>rtol</code> <code>float</code> <p>Relative tolerance for adaptive stepping.</p> <code>1e-08</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for adaptive stepping.</p> <code>1e-06</code> <code>use_jit</code> <code>bool</code> <p>Whether to use JIT compilation (can improve performance).</p> <code>False</code>"},{"location":"api/solvers/#pybasin.solver.TorchOdeSolver.with_device","title":"with_device","text":"<pre><code>with_device(device: str) -&gt; TorchOdeSolver\n</code></pre> <p>Create a copy of this solver configured for a different device.</p>"},{"location":"api/solvers/#pybasin.solver.SklearnParallelSolver","title":"pybasin.solver.SklearnParallelSolver","text":"<p>               Bases: <code>Solver</code></p> <p>ODE solver using sklearn's parallel processing with scipy's solve_ivp.</p> <p>Uses multiprocessing (loky backend) to solve multiple initial conditions in parallel. Each worker solves one trajectory at a time using scipy's solve_ivp.</p> <p>See also: scipy.integrate.solve_ivp</p>"},{"location":"api/solvers/#pybasin.solver.SklearnParallelSolver-functions","title":"Functions","text":""},{"location":"api/solvers/#pybasin.solver.SklearnParallelSolver.__init__","title":"__init__","text":"<pre><code>__init__(\n    time_span: tuple[float, float],\n    fs: float,\n    device: str | None = None,\n    n_jobs: int = -1,\n    batch_size: int | None = None,\n    method: str = \"RK45\",\n    rtol: float = 1e-06,\n    atol: float = 1e-08,\n    max_step: float | None = None,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize SklearnParallelSolver.</p> <p>Parameters:</p> Name Type Description Default <code>time_span</code> <code>tuple[float, float]</code> <p>Integration interval (t_start, t_end).</p> required <code>fs</code> <code>float</code> <p>Sampling frequency (Hz).</p> required <code>device</code> <code>str | None</code> <p>Device to use (only 'cpu' supported).</p> <code>None</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs (-1 for all CPUs).</p> <code>-1</code> <code>batch_size</code> <code>int | None</code> <p>Unused, kept for API compatibility.</p> <code>None</code> <code>method</code> <code>str</code> <p>Integration method ('RK45', 'RK23', 'DOP853', 'Radau', 'BDF', 'LSODA', etc).</p> <code>'RK45'</code> <code>rtol</code> <code>float</code> <p>Relative tolerance for the solver.</p> <code>1e-06</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for the solver.</p> <code>1e-08</code> <code>max_step</code> <code>float | None</code> <p>Maximum step size for the solver.</p> <code>None</code>"},{"location":"api/solvers/#pybasin.solver.SklearnParallelSolver.with_device","title":"with_device","text":"<pre><code>with_device(device: str) -&gt; SklearnParallelSolver\n</code></pre> <p>Create a copy of this solver configured for a different device.</p> <p>Note: SklearnParallelSolver only supports CPU, so this always returns a CPU solver.</p>"},{"location":"benchmarks/basin-stability-estimator/","title":"Basin Stability Estimator","text":""},{"location":"benchmarks/basin-stability-estimator/#interactive-flame-graph","title":"Interactive Flame Graph","text":"<p>View the profiling results in speedscope:</p> <p>Open in speedscope</p>"},{"location":"benchmarks/basin-stability-estimator/#example-run","title":"Example Run","text":"<p>The pendulum case study with 10,000 initial conditions using pyBasin defaults:</p> <pre><code>BASIN STABILITY ESTIMATION COMPLETE\nTotal time: 17.3210s\nTiming Breakdown:\n  1. Sampling:             0.0629s  (  0.4%)\n  2. Integration:         12.1686s  ( 70.3%)\n  3. Solution/Amps:        0.0571s  (  0.3%)\n  4. Features:             0.4379s  (  2.5%)\n  5. Filtering:            0.0047s  (  0.0%)\n  6. Classification:       4.5817s  ( 26.5%)\n  7. BS Computation:       0.0073s  (  0.0%)\n</code></pre>"},{"location":"benchmarks/basin-stability-estimator/#expensive-steps","title":"Expensive Steps","text":"<p>The three most computationally expensive steps are:</p> <ol> <li> <p>ODE Integration (~70%) \u2014 Solving the differential equations for all initial conditions. Uses JAX/Diffrax by default with GPU acceleration.</p> </li> <li> <p>Classification (~26%) \u2014 HDBSCAN clustering with auto-tuning enabled, followed by KMeans to assign noise points to the nearest cluster.</p> </li> <li> <p>Feature Extraction (~2.5%) \u2014 Extracts time series features from trajectories. The default <code>TorchFeatureExtractor</code> uses these statistical features: <code>median</code>, <code>mean</code>, <code>standard_deviation</code>, <code>variance</code>, <code>root_mean_square</code>, <code>maximum</code>, <code>absolute_maximum</code>, <code>minimum</code>, <code>delta</code>, <code>log_delta</code>.</p> </li> </ol> <p>Feature Complexity</p> <p>More complex features (e.g., entropy, autocorrelation, frequency domain) can significantly increase extraction time. The default minimal set is chosen for speed while maintaining classification accuracy.</p>"},{"location":"benchmarks/basin-stability-estimator/#profiling-setup","title":"Profiling Setup","text":"<p>The profile was generated using Austin, a frame stack sampler for CPython.</p> <p>The pendulum case study is run using pyBasin defaults\u2014only the ODE system and area of interest (sampler bounds) are defined. All other components (solver, feature extractor, predictor) use their default configurations.</p> <p>To generate a new profile:</p> <pre><code>./scripts/generate_profiling.sh\n</code></pre> <p>This runs the pendulum case study and outputs <code>profile.speedscope.json</code> for visualization in speedscope.</p>"},{"location":"benchmarks/end-to-end/","title":"End-to-End Performance","text":"<p>This benchmark compares the full basin stability estimation pipeline across MATLAB and Python implementations.</p>"},{"location":"benchmarks/end-to-end/#methodology","title":"Methodology","text":"<p>All implementations use the same:</p> <ul> <li>ODE system: Damped driven pendulum</li> <li>Parameters: <code>\u03b1=0.1</code>, <code>T=0.5</code>, <code>K=1.0</code></li> <li>Integration: <code>t_span=(0, 1000)</code>, <code>rtol=1e-8</code>, <code>atol=1e-6</code></li> <li>Sample sizes: 100 to 100,000 initial conditions</li> </ul>"},{"location":"benchmarks/end-to-end/#implementations-compared","title":"Implementations Compared","text":"Implementation Platform Parallelization MATLAB bSTAB-M CPU MATLAB <code>parfor</code> pyBasin + JAX CPU Vectorized (<code>vmap</code>) pyBasin + JAX CUDA GPU Vectorized (<code>vmap</code>)"},{"location":"benchmarks/end-to-end/#results","title":"Results","text":""},{"location":"benchmarks/end-to-end/#performance-comparison","title":"Performance Comparison","text":"N MATLAB (s) Python CPU (s) Python CUDA (s) CPU vs MATLAB GPU vs MATLAB 100 0.76 1.30 12.86 0.6x 0.1x 200 1.02 1.50 12.87 0.7x 0.1x 500 1.90 1.62 12.98 1.2x 0.1x 1,000 3.27 2.00 12.05 1.6x 0.3x 2,000 6.29 2.72 12.32 2.3x 0.5x 5,000 15.90 5.73 12.82 2.8x 1.2x 10,000 31.01 10.52 12.64 2.9x 2.5x 20,000 62.73 20.94 12.27 3.0x 5.1x 50,000 153.04 30.07 12.40 5.1x 12.3x 100,000 309.07 62.94 12.57 4.9x 24.6x"},{"location":"benchmarks/end-to-end/#scaling-analysis","title":"Scaling Analysis","text":"Implementation Scaling Exponent \u03b1 R\u00b2 MATLAB O(N) 0.90 \u00b1 0.06 0.992 Python CPU O(N^0.59) 0.59 \u00b1 0.10 0.942 Python CUDA O(1) -0.00 \u00b1 0.01 0.168"},{"location":"benchmarks/end-to-end/#comparison-plot","title":"Comparison Plot","text":""},{"location":"benchmarks/end-to-end/#scaling-plot-log-log","title":"Scaling Plot (Log-Log)","text":""},{"location":"benchmarks/end-to-end/#key-findings","title":"Key Findings","text":"<ol> <li>Python CPU becomes 3-5\u00d7 faster than MATLAB for N &gt; 5,000</li> <li>Python CUDA achieves near-constant time (~12s) regardless of N due to GPU parallelization</li> <li>At N=100,000: GPU is ~25\u00d7 faster than MATLAB (as long as data fits in GPU memory)</li> </ol>"},{"location":"benchmarks/end-to-end/#hardware","title":"Hardware","text":"<p>Benchmarks run on:</p> <ul> <li>CPU: Intel Core Ultra 9 275HX</li> <li>GPU: NVIDIA GeForce RTX 5070 Ti Laptop GPU (12 GB VRAM)</li> </ul>"},{"location":"benchmarks/feature-extraction/","title":"Feature Extraction Benchmarks","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"benchmarks/feature-extraction/#implementations-compared","title":"Implementations Compared","text":"<ul> <li>tsfresh (reference, CPU)</li> <li>TorchFeatureExtractor (CPU parallel)</li> <li>TorchFeatureExtractor (CUDA GPU)</li> </ul>"},{"location":"benchmarks/feature-extraction/#results","title":"Results","text":"Backend Mode Device 10k batches time tsfresh parallel cpu 34,465 ms PyTorch parallel cpu 1,734 ms PyTorch sequential cpu 3,464 ms PyTorch gpu cuda 7,702 ms"},{"location":"benchmarks/feature-extraction/#key-finding","title":"Key Finding","text":"<p>PyTorch CPU parallel is ~20x faster than tsfresh.</p>"},{"location":"benchmarks/feature-extraction/#feature-accuracy","title":"Feature Accuracy","text":"<p>All features validated against tsfresh reference values.</p>"},{"location":"benchmarks/overview/","title":"Benchmarks Overview","text":"<p>This section documents pyBasin's performance characteristics and compares it against the original MATLAB implementation (bSTAB-M).</p>"},{"location":"benchmarks/overview/#test-hardware","title":"Test Hardware","text":"<ul> <li>CPU: Intel Core Ultra 9 275HX</li> <li>GPU: NVIDIA GeForce RTX 5070 Ti Laptop GPU (12 GB VRAM)</li> </ul>"},{"location":"benchmarks/overview/#key-findings","title":"Key Findings","text":"<ul> <li>GPU delivers massive speedups at scale: At N=100k samples, pyBasin on GPU (Diffrax) is ~25\u00d7 faster than MATLAB for end-to-end basin stability estimation (12s vs 309s)</li> <li>Near-constant GPU time: JAX/Diffrax on CUDA maintains ~11-12s integration time regardless of sample size, enabling large-scale studies without linear time scaling</li> <li>CPU competitive for smaller workloads: pyBasin CPU (Diffrax) is ~1.2\u00d7 faster than MATLAB at N=5k and scales to 3-5\u00d7 faster at N&gt;5k</li> <li>GPU overhead at small N: For sample sizes below ~10k, CPU solvers outperform GPU due to data transfer and kernel launch overhead</li> <li>JAX/Diffrax is the recommended solver: Best performance on both CPU and GPU, plus unique support for per-trajectory event-based termination (critical for unbounded systems)</li> <li>Integration dominates runtime: ODE integration accounts for ~70% of total estimation time, classification ~26%, and feature extraction ~2.5%. Solver selection has the most impact on performance.</li> </ul>"},{"location":"benchmarks/overview/#benchmark-pages","title":"Benchmark Pages","text":""},{"location":"benchmarks/overview/#basin-stability-estimator","title":"Basin Stability Estimator","text":"<p>Detailed breakdown of the full estimation pipeline showing how time is distributed across each step (sampling, integration, feature extraction, classification). Includes an interactive flame graph for profiling analysis.</p>"},{"location":"benchmarks/overview/#end-to-end-performance","title":"End-to-End Performance","text":"<p>Compares the complete basin stability estimation workflow between pyBasin and MATLAB bSTAB-M across different sample sizes. Demonstrates pyBasin's scalability advantage, especially on GPU.</p>"},{"location":"benchmarks/overview/#solver-comparison","title":"Solver Comparison","text":"<p>Evaluates different ODE solver backends (JAX/Diffrax, PyTorch/torchdiffeq, SciPy) across CPU and GPU. Shows how JAX achieves near-constant integration time on GPU regardless of sample size.</p>"},{"location":"benchmarks/overview/#feature-extraction","title":"Feature Extraction","text":"<p>Compares feature extraction performance between pyBasin's PyTorch-based implementation and tsfresh. Analyzes the trade-offs between feature complexity and extraction speed.</p>"},{"location":"benchmarks/solvers/","title":"Solver Comparison","text":"<p>This benchmark compares ODE solver performance across different Python backends and MATLAB.</p>"},{"location":"benchmarks/solvers/#test-configuration","title":"Test Configuration","text":"<ul> <li>ODE: Driven damped pendulum</li> <li>t_span: (0, 1000)</li> <li>Tolerances: rtol=1e-8, atol=1e-6</li> <li>Sample sizes: 5,000 / 10,000 / 100,000 initial conditions</li> </ul>"},{"location":"benchmarks/solvers/#solvers-tested","title":"Solvers Tested","text":"Solver Backend Devices Method MATLAB ode45 MATLAB CPU Dormand-Prince 5(4) JAX/Diffrax JAX CPU, CUDA Dormand-Prince 5(4) torchdiffeq PyTorch CPU, CUDA Dormand-Prince 5(4) torchode PyTorch CUDA Dormand-Prince 5(4) <p>TorchOde Performance Issues</p> <p>TorchOde was excluded from CPU benchmarks due to severe performance issues observed in previous runs. Additionally, it performs very poorly at larger N values (e.g., ~1133s at N=100k vs ~11s for JAX/Diffrax), indicating it is not properly optimized for GPU batch processing in this use case.</p>"},{"location":"benchmarks/solvers/#results-by-sample-size","title":"Results by Sample Size","text":""},{"location":"benchmarks/solvers/#n-5000","title":"N = 5,000","text":"Solver Device Time (s) Std Dev vs MATLAB JAX/Diffrax CPU 4.87 \u00b10.06 1.20x MATLAB ode45 CPU 5.83 \u00b10.72 1.00x torchdiffeq CPU 7.86 \u00b11.42 0.74x JAX/Diffrax CUDA 11.56 \u00b10.44 0.50x torchode CUDA 30.51 \u00b11.13 0.19x torchdiffeq CUDA 31.82 \u00b10.79 0.18x"},{"location":"benchmarks/solvers/#n-10000","title":"N = 10,000","text":"Solver Device Time (s) Std Dev vs MATLAB torchdiffeq CPU 9.61 \u00b10.33 1.21x JAX/Diffrax CPU 9.68 \u00b10.17 1.20x JAX/Diffrax CUDA 11.45 \u00b10.36 1.02x MATLAB ode45 CPU 11.64 \u00b10.40 1.00x torchdiffeq CUDA 31.77 \u00b10.48 0.37x torchode CUDA 31.96 \u00b10.32 0.36x"},{"location":"benchmarks/solvers/#n-100000","title":"N = 100,000","text":"Solver Device Time (s) Std Dev vs MATLAB JAX/Diffrax CUDA 11.46 \u00b10.10 8.92x torchdiffeq CUDA 28.63 \u00b10.24 3.57x torchdiffeq CPU 32.58 \u00b11.10 3.14x JAX/Diffrax CPU 63.66 \u00b12.70 1.61x MATLAB ode45 CPU 102.26 \u00b11.59 1.00x torchode CUDA 1132.87 \u00b10.45 0.09x"},{"location":"benchmarks/solvers/#comparison-plots","title":"Comparison Plots","text":""},{"location":"benchmarks/solvers/#n-5000_1","title":"N = 5,000","text":""},{"location":"benchmarks/solvers/#n-10000_1","title":"N = 10,000","text":""},{"location":"benchmarks/solvers/#n-100000_1","title":"N = 100,000","text":"<p>Note: torchode (CUDA) time is divided by 4 in the N=100,000 plot to improve readability.</p>"},{"location":"benchmarks/solvers/#key-findings","title":"Key Findings","text":"<ol> <li>JAX/Diffrax (CPU) is the fastest option for small to medium N (5k-10k samples)</li> <li>JAX/Diffrax (CUDA) achieves near-constant time (~11.5s) regardless of N, making it 8.9x faster than MATLAB at N=100k</li> <li>torchdiffeq scales reasonably well on both CPU and CUDA</li> <li>GPU acceleration only provides significant benefit at large sample sizes (N \u2265 100k)</li> <li>At small N, GPU overhead makes CPU solvers faster</li> </ol>"},{"location":"benchmarks/solvers/#recommendations","title":"Recommendations","text":"<p>JAX/Diffrax should be the default solver for pyBasin. When a GPU is available, it delivers unmatched performance with near-constant integration time regardless of sample size\u2014making it the clear choice for any workload.</p> <p>Additionally, JAX/Diffrax is the only solver that supports event-based termination with individual trajectory stopping. This is critical for systems with unbounded trajectories (e.g., Lorenz \"broken butterfly\"), where some initial conditions diverge to infinity. With JAX events, each trajectory stops independently when it exceeds a threshold, while bounded trajectories continue integrating. Other solvers either stop all trajectories simultaneously or require workarounds like zero masking. See the Handling Unbounded Trajectories guide for details.</p> <p>For CPU-only systems, the choice depends on scale. At smaller sample sizes (N \u2264 10k), JAX/Diffrax on CPU is the fastest option. However, at larger scales (N = 100k), torchdiffeq on CPU offers a meaningful ~2x improvement over JAX/Diffrax CPU (32s vs 64s). While this difference is negligible for single runs, it becomes significant for parameter studies that require evaluating many ODE configurations. A study testing 50 parameter combinations at N=100k would save roughly 26 minutes by using torchdiffeq instead of JAX/Diffrax on CPU\u2014though JAX/Diffrax on GPU would complete the same workload in just 10 minutes.</p>"},{"location":"benchmarks/solvers/#hardware","title":"Hardware","text":"<p>Benchmarks run on:</p> <ul> <li>CPU: Intel Core Ultra 9 275HX</li> <li>GPU: NVIDIA GeForce RTX 5070 Ti Laptop GPU (12 GB VRAM)</li> </ul>"},{"location":"case-studies/duffing/","title":"Duffing Oscillator","text":""},{"location":"case-studies/duffing/#system-description","title":"System Description","text":"<p>Duffing oscillator with cubic nonlinearity:</p> \\[\\ddot{x} + \\delta \\dot{x} + \\alpha x + \\beta x^3 = \\gamma \\cos(\\omega t)\\]"},{"location":"case-studies/duffing/#attractors","title":"Attractors","text":"<ul> <li>y1-y5: Various n-cycle attractors (period-n oscillations)</li> </ul>"},{"location":"case-studies/duffing/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/duffing/#setup","title":"Setup","text":"<pre><code>def setup_duffing_oscillator_system() -&gt; SetupProperties:\n    n = 10000\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up Duffing oscillator system on device: {device}\")\n\n    params: DuffingParams = {\"delta\": 0.08, \"k3\": 1, \"A\": 0.2}\n    ode_system = DuffingJaxODE(params)\n\n    sampler = UniformRandomSampler(min_limits=[-1, -0.5], max_limits=[1, 1], device=device)\n\n    solver = JaxSolver(\n        time_span=(0, 1000),\n        n_steps=50000,\n        device=device,\n        rtol=1e-8,\n        atol=1e-6,\n        use_cache=True,\n    )\n\n    feature_extractor = TorchFeatureExtractor(\n        time_steady=900.0,\n        normalize=False,\n        features=None,\n        features_per_state={\n            0: {\"maximum\": None, \"standard_deviation\": None},\n        },\n    )\n\n    classifier_initial_conditions = [\n        [-0.21, 0.02],\n        [1.05, 0.77],\n        [-0.67, 0.02],\n        [-0.46, 0.30],\n        [-0.43, 0.12],\n    ]\n\n    classifier_labels = [\n        \"y1\",\n        \"y2\",\n        \"y3\",\n        \"y4\",\n        \"y5\",\n    ]\n\n    knn = KNeighborsClassifier(n_neighbors=1)\n\n    knn_cluster = KNNClassifier(\n        classifier=knn,\n        template_y0=classifier_initial_conditions,\n        labels=classifier_labels,\n        ode_params=params,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": knn_cluster,\n    }\n</code></pre>"},{"location":"case-studies/duffing/#main-estimation","title":"Main Estimation","text":"<p>File Not Found</p> <p>Could not find file: <code>case_studies/duffing_oscillator/main_duffing_case1.py</code></p>"},{"location":"case-studies/duffing/#case-1-baseline-results-supervised","title":"Case 1: Baseline Results (Supervised)","text":""},{"location":"case-studies/duffing/#comparison-with-matlab-bstab","title":"Comparison with MATLAB bSTAB","text":"<p>Overall Classification Quality:</p> <ul> <li>Macro F1-score: 0.9980</li> <li>Matthews Correlation Coefficient: 0.9977</li> </ul> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 y1 0.2023 \u00b1 0.0040 0.2027 \u00b1 0.0040 0.9965 y2 0.4950 \u00b1 0.0050 0.4950 \u00b1 0.0050 1.0000 y3 0.0288 \u00b1 0.0017 0.0288 \u00b1 0.0017 1.0000 y4 0.0257 \u00b1 0.0016 0.0257 \u00b1 0.0016 0.9961 y5 0.2482 \u00b1 0.0043 0.2478 \u00b1 0.0043 0.9972"},{"location":"case-studies/duffing/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/duffing/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/duffing/#state-space","title":"State Space","text":""},{"location":"case-studies/duffing/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/duffing/#case-2-unsupervised-clustering-with-template-relabeling","title":"Case 2: Unsupervised Clustering with Template Relabeling","text":"<p>This case demonstrates unsupervised attractor discovery using DBSCAN clustering, followed by relabeling using KNN template matching to assign meaningful attractor names.</p>"},{"location":"case-studies/duffing/#comparison-with-matlab-bstab_1","title":"Comparison with MATLAB bSTAB","text":"<p>Cluster Quality Metrics:</p> <ul> <li>Clusters found: 5 (expected: 5)</li> <li>Overall agreement: 100.0%</li> <li>Adjusted Rand Index: 1.0000</li> <li>Macro F1-score: 0.9980</li> <li>Matthews Correlation Coefficient: 0.9977</li> </ul> Attractor DBSCAN Purity pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 y1 0 100.0% 0.2023 \u00b1 0.0040 0.2027 \u00b1 0.0040 0.9965 y2 1 100.0% 0.4950 \u00b1 0.0050 0.4950 \u00b1 0.0050 1.0000 y3 4 100.0% 0.0288 \u00b1 0.0017 0.0288 \u00b1 0.0017 1.0000 y4 2 100.0% 0.0257 \u00b1 0.0016 0.0257 \u00b1 0.0016 0.9961 y5 3 100.0% 0.2482 \u00b1 0.0043 0.2478 \u00b1 0.0043 0.9972"},{"location":"case-studies/duffing/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/duffing/#basin-stability_1","title":"Basin Stability","text":""},{"location":"case-studies/duffing/#state-space_1","title":"State Space","text":""},{"location":"case-studies/duffing/#feature-space_1","title":"Feature Space","text":""},{"location":"case-studies/friction/","title":"Friction Oscillator","text":""},{"location":"case-studies/friction/#system-description","title":"System Description","text":"<p>Mass-spring-damper with friction:</p> \\[m\\ddot{x} + c\\dot{x} + kx = F_{friction}(v_{belt} - \\dot{x})\\]"},{"location":"case-studies/friction/#attractors","title":"Attractors","text":"<ul> <li>FP: Fixed point (stick state)</li> <li>LC: Limit cycle (stick-slip oscillation)</li> </ul>"},{"location":"case-studies/friction/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/friction/#setup","title":"Setup","text":"<pre><code>def setup_friction_system() -&gt; SetupProperties:\n    n = 5000\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up friction system on device: {device}\")\n\n    params: FrictionParams = {\n        \"v_d\": 1.5,  # Driving velocity\n        \"xi\": 0.05,  # Damping ratio\n        \"musd\": 2.0,  # Ratio static to dynamic friction coefficient\n        \"mud\": 0.5,  # Dynamic coefficient of friction\n        \"muv\": 0.0,  # Linear strengthening parameter\n        \"v0\": 0.5,  # Reference velocity for exponential decay\n    }\n\n    ode_system = FrictionJaxODE(params)\n\n    sampler = UniformRandomSampler(\n        min_limits=[-2.0, 0.0],\n        max_limits=[2.0, 2.0],\n        device=device,\n    )\n\n    solver = JaxSolver(\n        time_span=(0, 500),\n        n_steps=500,\n        device=device,\n        rtol=1e-8,\n        atol=1e-6,\n        use_cache=False,\n    )\n\n    feature_extractor = FrictionFeatureExtractor(time_steady=400)\n\n    classifier_initial_conditions = [\n        [0.1, 0.1],\n        [2.0, 2.0],\n    ]\n\n    classifier_labels = [\"FP\", \"LC\"]\n\n    knn = KNeighborsClassifier(n_neighbors=1)\n\n    knn_cluster = KNNClassifier(\n        classifier=knn,\n        template_y0=classifier_initial_conditions,\n        labels=classifier_labels,\n        ode_params=params,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": knn_cluster,\n    }\n</code></pre>"},{"location":"case-studies/friction/#main-estimation","title":"Main Estimation","text":"<pre><code>def main():\n    props = setup_friction_system()\n\n    bse = BasinStabilityEstimator(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=props.get(\"solver\"),\n        feature_extractor=props.get(\"feature_extractor\"),\n        predictor=props.get(\"cluster_classifier\"),\n        save_to=\"results_friction\",\n        feature_selector=None,\n    )\n\n    bse.estimate_bs()\n\n    return bse\n</code></pre>"},{"location":"case-studies/friction/#case-1-baseline-results","title":"Case 1: Baseline Results","text":""},{"location":"case-studies/friction/#comparison-with-matlab-bstab","title":"Comparison with MATLAB bSTAB","text":"<p>Overall Classification Quality:</p> <ul> <li>Macro F1-score: 1.0000</li> <li>Matthews Correlation Coefficient: 1.0000</li> </ul> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.3040 \u00b1 0.0065 0.3040 \u00b1 0.0065 1.0000 LC 0.6960 \u00b1 0.0065 0.6960 \u00b1 0.0065 1.0000"},{"location":"case-studies/friction/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/friction/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/friction/#state-space","title":"State Space","text":""},{"location":"case-studies/friction/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/friction/#case-2-v_d-parameter-sweep","title":"Case 2: v_d Parameter Sweep","text":""},{"location":"case-studies/friction/#comparison-with-matlab-bstab_1","title":"Comparison with MATLAB bSTAB","text":""},{"location":"case-studies/friction/#parameter-08000","title":"Parameter = 0.8000","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 LC 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-08750","title":"Parameter = 0.8750","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 LC 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-09500","title":"Parameter = 0.9500","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 LC 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-10250","title":"Parameter = 1.0250","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 LC 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-11000","title":"Parameter = 1.1000","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 LC 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-11750","title":"Parameter = 1.1750","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.0132 \u00b1 0.0016 0.0132 \u00b1 0.0016 1.0000 LC 0.9868 \u00b1 0.0016 0.9868 \u00b1 0.0016 1.0000"},{"location":"case-studies/friction/#parameter-12500","title":"Parameter = 1.2500","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.0800 \u00b1 0.0038 0.0800 \u00b1 0.0038 1.0000 LC 0.9200 \u00b1 0.0038 0.9200 \u00b1 0.0038 1.0000"},{"location":"case-studies/friction/#parameter-13250","title":"Parameter = 1.3250","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.1478 \u00b1 0.0050 0.1478 \u00b1 0.0050 1.0000 LC 0.8522 \u00b1 0.0050 0.8522 \u00b1 0.0050 1.0000"},{"location":"case-studies/friction/#parameter-14000","title":"Parameter = 1.4000","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.2130 \u00b1 0.0058 0.2130 \u00b1 0.0058 1.0000 LC 0.7870 \u00b1 0.0058 0.7870 \u00b1 0.0058 1.0000"},{"location":"case-studies/friction/#parameter-14750","title":"Parameter = 1.4750","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.2776 \u00b1 0.0063 0.2776 \u00b1 0.0063 1.0000 LC 0.7224 \u00b1 0.0063 0.7224 \u00b1 0.0063 1.0000"},{"location":"case-studies/friction/#parameter-15500","title":"Parameter = 1.5500","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.3544 \u00b1 0.0068 0.3544 \u00b1 0.0068 1.0000 LC 0.6456 \u00b1 0.0068 0.6456 \u00b1 0.0068 1.0000"},{"location":"case-studies/friction/#parameter-16250","title":"Parameter = 1.6250","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.4202 \u00b1 0.0070 0.4202 \u00b1 0.0070 1.0000 LC 0.5798 \u00b1 0.0070 0.5798 \u00b1 0.0070 1.0000"},{"location":"case-studies/friction/#parameter-17000","title":"Parameter = 1.7000","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.4922 \u00b1 0.0071 0.4922 \u00b1 0.0071 1.0000 LC 0.5078 \u00b1 0.0071 0.5078 \u00b1 0.0071 1.0000"},{"location":"case-studies/friction/#parameter-17750","title":"Parameter = 1.7750","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.5678 \u00b1 0.0070 0.5678 \u00b1 0.0070 1.0000 LC 0.4322 \u00b1 0.0070 0.4322 \u00b1 0.0070 1.0000"},{"location":"case-studies/friction/#parameter-18500","title":"Parameter = 1.8500","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-19250","title":"Parameter = 1.9250","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-20000","title":"Parameter = 2.0000","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-20750","title":"Parameter = 2.0750","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-21500","title":"Parameter = 2.1500","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#parameter-22250","title":"Parameter = 2.2250","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/friction/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/friction/#basin-stability-variation","title":"Basin Stability Variation","text":""},{"location":"case-studies/friction/#bifurcation-diagram","title":"Bifurcation Diagram","text":""},{"location":"case-studies/lorenz/","title":"Lorenz System","text":""},{"location":"case-studies/lorenz/#system-description","title":"System Description","text":"<p>Lorenz \"broken butterfly\" attractor:</p> \\[ \\begin{aligned} \\dot{x} &amp;= \\sigma(y - x) \\\\ \\dot{y} &amp;= rx - y - xz \\\\ \\dot{z} &amp;= xy - bz \\end{aligned} \\]"},{"location":"case-studies/lorenz/#attractors","title":"Attractors","text":"<ul> <li>chaos y_1: Positive x wing (butterfly1)</li> <li>chaos y_2: Negative x wing (butterfly2)</li> <li>unbounded: Trajectories that escape to infinity</li> </ul>"},{"location":"case-studies/lorenz/#key-feature","title":"Key Feature","text":"<p>Demonstrates unboundedness detection with <code>event_fn</code>.</p>"},{"location":"case-studies/lorenz/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/lorenz/#setup","title":"Setup","text":"<pre><code>def setup_lorenz_system() -&gt; SetupProperties:\n    n = 20_000\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up Lorenz system on device: {device}\")\n\n    params: LorenzParams = {\"sigma\": 0.12, \"r\": 0.0, \"b\": -0.6}\n\n    ode_system = LorenzJaxODE(params)\n\n    sampler = UniformRandomSampler(\n        min_limits=[-10.0, -20.0, 0.0], max_limits=[10.0, 20.0, 0.0], device=device\n    )\n\n    solver = JaxSolver(\n        time_span=(0, 1000),\n        n_steps=4000,\n        device=device,\n        rtol=1e-8,\n        atol=1e-6,\n        use_cache=True,\n        event_fn=lorenz_stop_event,\n    )\n\n    feature_extractor = JaxFeatureExtractor(\n        time_steady=900.0,\n        normalize=False,\n        features_per_state={\n            0: {\"mean\": None},\n            1: None,\n            2: None,\n        },\n    )\n\n    classifier_initial_conditions = [\n        [0.8, -3.0, 0.0],\n        [-0.8, 3.0, 0.0],\n        [10.0, 50.0, 0.0],\n    ]\n\n    classifier_labels = [\"chaos y_1\", \"chaos y_2\", \"unbounded\"]\n\n    knn = KNeighborsClassifier(n_neighbors=1)\n\n    knn_cluster = KNNClassifier(\n        classifier=knn,\n        template_y0=classifier_initial_conditions,\n        labels=classifier_labels,\n        ode_params=params,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": knn_cluster,\n    }\n</code></pre>"},{"location":"case-studies/lorenz/#main-estimation","title":"Main Estimation","text":"<pre><code>def main():\n    props = setup_lorenz_system()\n\n    bse = BasinStabilityEstimator(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=props.get(\"solver\"),\n        feature_extractor=props.get(\"feature_extractor\"),\n        predictor=props.get(\"cluster_classifier\"),\n        save_to=\"results_case1\",\n        # feature_selector=None,\n    )\n\n    basin_stability = bse.estimate_bs()\n    print(\"Basin Stability:\", basin_stability)\n\n    # bse.save()\n\n    return bse\n</code></pre>"},{"location":"case-studies/lorenz/#case-1-baseline-results","title":"Case 1: Baseline Results","text":""},{"location":"case-studies/lorenz/#comparison-with-matlab-bstab","title":"Comparison with MATLAB bSTAB","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.0894 \u00b1 0.0020 0.0894 \u00b1 0.0020 +0.0000 \u00b10.0056 \u2713 chaos y_2 0.0875 \u00b1 0.0020 0.0874 \u00b1 0.0020 +0.0000 \u00b10.0055 \u2713 unbounded 0.8231 \u00b1 0.0027 0.8232 \u00b1 0.0027 -0.0000 \u00b10.0075 \u2713"},{"location":"case-studies/lorenz/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/lorenz/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/lorenz/#state-space","title":"State Space","text":""},{"location":"case-studies/lorenz/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/lorenz/#case-2-sigma-parameter-sweep","title":"Case 2: Sigma Parameter Sweep","text":""},{"location":"case-studies/lorenz/#comparison-with-matlab-bstab_1","title":"Comparison with MATLAB bSTAB","text":""},{"location":"case-studies/lorenz/#parameter-01200","title":"Parameter = 0.1200","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.0844 \u00b1 0.0020 0.0843 \u00b1 0.0020 +0.0001 \u00b10.0054 \u2713 chaos y_2 0.0862 \u00b1 0.0020 0.0859 \u00b1 0.0020 +0.0003 \u00b10.0055 \u2713 unbounded 0.8294 \u00b1 0.0027 0.8298 \u00b1 0.0027 -0.0004 \u00b10.0074 \u2713"},{"location":"case-studies/lorenz/#parameter-01225","title":"Parameter = 0.1225","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1019 \u00b1 0.0021 0.1019 \u00b1 0.0021 +0.0000 \u00b10.0059 \u2713 chaos y_2 0.1047 \u00b1 0.0022 0.1047 \u00b1 0.0022 +0.0000 \u00b10.0060 \u2713 unbounded 0.7933 \u00b1 0.0029 0.7933 \u00b1 0.0029 +0.0000 \u00b10.0079 \u2713"},{"location":"case-studies/lorenz/#parameter-01250","title":"Parameter = 0.1250","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1122 \u00b1 0.0022 0.1122 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1139 \u00b1 0.0022 0.1139 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 unbounded 0.7740 \u00b1 0.0030 0.7740 \u00b1 0.0030 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01275","title":"Parameter = 0.1275","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1140 \u00b1 0.0022 0.1140 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1163 \u00b1 0.0023 0.1163 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 unbounded 0.7697 \u00b1 0.0030 0.7697 \u00b1 0.0030 +0.0000 \u00b10.0083 \u2713"},{"location":"case-studies/lorenz/#parameter-01300","title":"Parameter = 0.1300","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1148 \u00b1 0.0023 0.1148 \u00b1 0.0023 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1138 \u00b1 0.0022 0.1138 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 unbounded 0.7714 \u00b1 0.0030 0.7714 \u00b1 0.0030 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01325","title":"Parameter = 0.1325","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1080 \u00b1 0.0022 0.1080 \u00b1 0.0022 +0.0000 \u00b10.0061 \u2713 chaos y_2 0.1127 \u00b1 0.0022 0.1127 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 unbounded 0.7794 \u00b1 0.0029 0.7794 \u00b1 0.0029 +0.0000 \u00b10.0081 \u2713"},{"location":"case-studies/lorenz/#parameter-01350","title":"Parameter = 0.1350","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1105 \u00b1 0.0022 0.1105 \u00b1 0.0022 +0.0000 \u00b10.0061 \u2713 chaos y_2 0.1106 \u00b1 0.0022 0.1106 \u00b1 0.0022 +0.0000 \u00b10.0061 \u2713 unbounded 0.7789 \u00b1 0.0029 0.7789 \u00b1 0.0029 +0.0000 \u00b10.0081 \u2713"},{"location":"case-studies/lorenz/#parameter-01375","title":"Parameter = 0.1375","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1118 \u00b1 0.0022 0.1118 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1126 \u00b1 0.0022 0.1126 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 unbounded 0.7756 \u00b1 0.0029 0.7756 \u00b1 0.0029 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01400","title":"Parameter = 0.1400","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1123 \u00b1 0.0022 0.1123 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1103 \u00b1 0.0022 0.1103 \u00b1 0.0022 +0.0000 \u00b10.0061 \u2713 unbounded 0.7775 \u00b1 0.0029 0.7775 \u00b1 0.0029 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01425","title":"Parameter = 0.1425","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1119 \u00b1 0.0022 0.1119 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1092 \u00b1 0.0022 0.1092 \u00b1 0.0022 +0.0000 \u00b10.0061 \u2713 unbounded 0.7789 \u00b1 0.0029 0.7789 \u00b1 0.0029 -0.0000 \u00b10.0081 \u2713"},{"location":"case-studies/lorenz/#parameter-01450","title":"Parameter = 0.1450","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1143 \u00b1 0.0022 0.1143 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1093 \u00b1 0.0022 0.1093 \u00b1 0.0022 +0.0000 \u00b10.0061 \u2713 unbounded 0.7764 \u00b1 0.0029 0.7764 \u00b1 0.0029 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01475","title":"Parameter = 0.1475","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1134 \u00b1 0.0022 0.1134 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1122 \u00b1 0.0022 0.1122 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 unbounded 0.7743 \u00b1 0.0030 0.7743 \u00b1 0.0030 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01500","title":"Parameter = 0.1500","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1139 \u00b1 0.0022 0.1139 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1081 \u00b1 0.0022 0.1081 \u00b1 0.0022 +0.0000 \u00b10.0061 \u2713 unbounded 0.7780 \u00b1 0.0029 0.7780 \u00b1 0.0029 +0.0000 \u00b10.0081 \u2713"},{"location":"case-studies/lorenz/#parameter-01525","title":"Parameter = 0.1525","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1155 \u00b1 0.0023 0.1155 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 chaos y_2 0.1116 \u00b1 0.0022 0.1116 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 unbounded 0.7729 \u00b1 0.0030 0.7729 \u00b1 0.0030 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01550","title":"Parameter = 0.1550","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1112 \u00b1 0.0022 0.1112 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1163 \u00b1 0.0023 0.1163 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 unbounded 0.7724 \u00b1 0.0030 0.7724 \u00b1 0.0030 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01575","title":"Parameter = 0.1575","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1116 \u00b1 0.0022 0.1116 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1092 \u00b1 0.0022 0.1092 \u00b1 0.0022 +0.0000 \u00b10.0061 \u2713 unbounded 0.7792 \u00b1 0.0029 0.7792 \u00b1 0.0029 +0.0000 \u00b10.0081 \u2713"},{"location":"case-studies/lorenz/#parameter-01600","title":"Parameter = 0.1600","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1142 \u00b1 0.0022 0.1142 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1114 \u00b1 0.0022 0.1114 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 unbounded 0.7744 \u00b1 0.0030 0.7744 \u00b1 0.0030 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01625","title":"Parameter = 0.1625","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1131 \u00b1 0.0022 0.1131 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1157 \u00b1 0.0023 0.1157 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 unbounded 0.7712 \u00b1 0.0030 0.7712 \u00b1 0.0030 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01650","title":"Parameter = 0.1650","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1114 \u00b1 0.0022 0.1114 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1121 \u00b1 0.0022 0.1121 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 unbounded 0.7765 \u00b1 0.0029 0.7765 \u00b1 0.0029 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01675","title":"Parameter = 0.1675","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1123 \u00b1 0.0022 0.1123 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1193 \u00b1 0.0023 0.1194 \u00b1 0.0023 -0.0001 \u00b10.0064 \u2713 unbounded 0.7683 \u00b1 0.0030 0.7683 \u00b1 0.0030 +0.0000 \u00b10.0083 \u2713"},{"location":"case-studies/lorenz/#parameter-01700","title":"Parameter = 0.1700","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1136 \u00b1 0.0022 0.1136 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 chaos y_2 0.1182 \u00b1 0.0023 0.1182 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 unbounded 0.7682 \u00b1 0.0030 0.7682 \u00b1 0.0030 +0.0000 \u00b10.0083 \u2713"},{"location":"case-studies/lorenz/#parameter-01725","title":"Parameter = 0.1725","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1201 \u00b1 0.0023 0.1201 \u00b1 0.0023 +0.0000 \u00b10.0064 \u2713 chaos y_2 0.1171 \u00b1 0.0023 0.1171 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 unbounded 0.7629 \u00b1 0.0030 0.7629 \u00b1 0.0030 +0.0000 \u00b10.0083 \u2713"},{"location":"case-studies/lorenz/#parameter-01750","title":"Parameter = 0.1750","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1179 \u00b1 0.0023 0.1179 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 chaos y_2 0.1118 \u00b1 0.0022 0.1118 \u00b1 0.0022 +0.0000 \u00b10.0062 \u2713 unbounded 0.7702 \u00b1 0.0030 0.7702 \u00b1 0.0030 +0.0000 \u00b10.0082 \u2713"},{"location":"case-studies/lorenz/#parameter-01775","title":"Parameter = 0.1775","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1162 \u00b1 0.0023 0.1162 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 chaos y_2 0.1181 \u00b1 0.0023 0.1181 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 unbounded 0.7657 \u00b1 0.0030 0.7657 \u00b1 0.0030 +0.0000 \u00b10.0083 \u2713"},{"location":"case-studies/lorenz/#parameter-01800","title":"Parameter = 0.1800","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.1172 \u00b1 0.0023 0.1172 \u00b1 0.0023 +0.0000 \u00b10.0063 \u2713 chaos y_2 0.1220 \u00b1 0.0023 0.1220 \u00b1 0.0023 +0.0000 \u00b10.0064 \u2713 unbounded 0.7609 \u00b1 0.0030 0.7609 \u00b1 0.0030 +0.0000 \u00b10.0084 \u2713"},{"location":"case-studies/lorenz/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/lorenz/#basin-stability-variation","title":"Basin Stability Variation","text":""},{"location":"case-studies/lorenz/#bifurcation-diagram","title":"Bifurcation Diagram","text":""},{"location":"case-studies/lorenz/#case-3-solver-rtol-convergence-study","title":"Case 3: Solver rtol Convergence Study","text":"<p>This hyperparameter study demonstrates the effect of ODE solver relative tolerance on basin stability estimation. Coarse tolerances (rtol=1e-3) produce inaccurate results, while finer tolerances converge to consistent values.</p>"},{"location":"case-studies/lorenz/#comparison-with-matlab-bstab_2","title":"Comparison with MATLAB bSTAB","text":""},{"location":"case-studies/lorenz/#parameter-00010","title":"Parameter = 0.0010","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.0236 \u00b1 0.0011 0.0895 \u00b1 0.0020 -0.0659 \u00b10.0045 \u2717 chaos y_2 0.0211 \u00b1 0.0010 0.0858 \u00b1 0.0020 -0.0647 \u00b10.0044 \u2717 unbounded 0.9553 \u00b1 0.0015 0.8246 \u00b1 0.0027 +0.1307 \u00b10.0060 \u2717"},{"location":"case-studies/lorenz/#parameter-00001","title":"Parameter = 0.0001","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.0871 \u00b1 0.0020 0.0874 \u00b1 0.0020 -0.0004 \u00b10.0055 \u2713 chaos y_2 0.0859 \u00b1 0.0020 0.0862 \u00b1 0.0020 -0.0002 \u00b10.0055 \u2713 unbounded 0.8270 \u00b1 0.0027 0.8264 \u00b1 0.0027 +0.0006 \u00b10.0074 \u2713"},{"location":"case-studies/lorenz/#parameter-00000","title":"Parameter = 0.0000","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.0871 \u00b1 0.0020 0.0871 \u00b1 0.0020 +0.0000 \u00b10.0055 \u2713 chaos y_2 0.0855 \u00b1 0.0020 0.0850 \u00b1 0.0020 +0.0005 \u00b10.0055 \u2713 unbounded 0.8274 \u00b1 0.0027 0.8279 \u00b1 0.0027 -0.0005 \u00b10.0074 \u2713"},{"location":"case-studies/lorenz/#parameter-00000_1","title":"Parameter = 0.0000","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.0871 \u00b1 0.0020 0.0872 \u00b1 0.0020 -0.0001 \u00b10.0055 \u2713 chaos y_2 0.0887 \u00b1 0.0020 0.0887 \u00b1 0.0020 +0.0000 \u00b10.0056 \u2713 unbounded 0.8242 \u00b1 0.0027 0.8242 \u00b1 0.0027 +0.0000 \u00b10.0075 \u2713"},{"location":"case-studies/lorenz/#parameter-00000_2","title":"Parameter = 0.0000","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.0860 \u00b1 0.0020 0.0862 \u00b1 0.0020 -0.0002 \u00b10.0055 \u2713 chaos y_2 0.0882 \u00b1 0.0020 0.0882 \u00b1 0.0020 -0.0000 \u00b10.0056 \u2713 unbounded 0.8258 \u00b1 0.0027 0.8256 \u00b1 0.0027 +0.0002 \u00b10.0074 \u2713"},{"location":"case-studies/lorenz/#parameter-00000_3","title":"Parameter = 0.0000","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status chaos y_1 0.0876 \u00b1 0.0020 0.0874 \u00b1 0.0020 +0.0002 \u00b10.0055 \u2713 chaos y_2 0.0872 \u00b1 0.0020 0.0871 \u00b1 0.0020 +0.0001 \u00b10.0055 \u2713 unbounded 0.8252 \u00b1 0.0027 0.8255 \u00b1 0.0027 -0.0003 \u00b10.0074 \u2713"},{"location":"case-studies/lorenz/#visualizations_2","title":"Visualizations","text":""},{"location":"case-studies/lorenz/#basin-stability-variation_1","title":"Basin Stability Variation","text":""},{"location":"case-studies/lorenz/#bifurcation-diagram_1","title":"Bifurcation Diagram","text":""},{"location":"case-studies/overview/","title":"Case Studies Overview","text":"<p>Documented here are the case studies that validate pyBasin against its original MATLAB counterpart, bSTAB. Each study targets a specific dynamical system and compares the two implementations on identical initial conditions.</p>"},{"location":"case-studies/overview/#classification-quality-metrics","title":"Classification Quality Metrics","text":"<p>To assess whether pyBasin reproduces the MATLAB bSTAB results, we compare predicted attractor labels from pyBasin with ground truth labels produced by bSTAB. Both tools classify trajectories into discrete attractor categories (e.g., \"FP\", \"LC\", \"chaos\"), which makes it possible to apply standard classification metrics directly.</p>"},{"location":"case-studies/overview/#methodology","title":"Methodology","text":"<p>Given that attractor labels from two independent implementations are compared, we treat the problem as a classification task and evaluate agreement using established metrics.</p> <p>Concretely, each test case proceeds as follows:</p> <ol> <li>Load the exact initial conditions exported from MATLAB ground truth CSV files</li> <li>Classify those initial conditions with pyBasin</li> <li>Match the resulting labels against the MATLAB ground truth</li> <li>Evaluate the classification metrics described below</li> </ol>"},{"location":"case-studies/overview/#metrics-used","title":"Metrics Used","text":""},{"location":"case-studies/overview/#1-f1-score-per-class","title":"1. F1-Score (Per Class)","text":"<p>Per-class classification quality is measured by the F1-score:</p> \\[F1 = \\frac{2 \\cdot TP}{2 \\cdot TP + FP + FN}\\] <p>where TP = true positives, FP = false positives, FN = false negatives for that class.</p> <p>Range: [0, 1], where 1.0 = perfect classification for that class</p>"},{"location":"case-studies/overview/#2-macro-f1-score-overall","title":"2. Macro F1-Score (Overall)","text":"<p>Averaging the per-class F1-scores yields the macro F1-score, which captures overall classification quality without weighting by class frequency:</p> \\[\\text{Macro F1} = \\frac{1}{K} \\sum_{k=1}^{K} F1_k\\] <p>where \\(K\\) is the number of classes (attractor types).</p> <p>Range: [0, 1], where 1.0 = perfect classification across all classes</p>"},{"location":"case-studies/overview/#3-matthews-correlation-coefficient-mcc","title":"3. Matthews Correlation Coefficient (MCC)","text":"<p>As a global measure of prediction\u2013ground truth correlation, we also report the Matthews correlation coefficient.</p> <p>For binary classification:</p> \\[\\text{MCC} = \\frac{TP \\cdot TN - FP \\cdot FN}{\\sqrt{(TP + FP)(TP + FN)(TN + FP)(TN + FN)}}\\] <p>For multiclass classification, scikit-learn implements a generalization based on the confusion matrix \\(C\\):</p> \\[\\text{MCC} = \\frac{c \\cdot s - \\sum_k p_k \\cdot t_k}{\\sqrt{(s^2 - \\sum_k p_k^2)(s^2 - \\sum_k t_k^2)}}\\] <p>where:</p> <ul> <li>\\(t_k = \\sum_i^K C_{ik}\\) \u2014 the number of times class \\(k\\) truly occurred</li> <li>\\(p_k = \\sum_i^K C_{ki}\\) \u2014 the number of times class \\(k\\) was predicted</li> <li>\\(c = \\sum_k^K C_{kk}\\) \u2014 the total number of samples correctly predicted</li> <li>\\(s = \\sum_i^K \\sum_j^K C_{ij}\\) \u2014 the total number of samples</li> </ul> <p>Range: [-1, 1], where:</p> <ul> <li>+1 = perfect prediction</li> <li>0 = random prediction</li> <li>-1 = complete disagreement</li> </ul> <p>Because basin stability problems often feature one dominant attractor, MCC is well-suited here; it remains informative even under class imbalance.</p>"},{"location":"case-studies/overview/#quality-thresholds","title":"Quality Thresholds","text":"Metric Excellent Good Acceptable Poor F1 \u2265 0.95 \u2265 0.90 \u2265 0.80 &lt; 0.80 Macro F1 \u2265 0.95 \u2265 0.90 \u2265 0.80 &lt; 0.80 MCC \u2265 0.90 \u2265 0.80 \u2265 0.70 &lt; 0.70 <p>Scores in the Excellent or Good range confirm that pyBasin faithfully reproduces the MATLAB behaviour. Acceptable scores point to minor discrepancies\u2014often numerical precision or boundary-case effects. Poor scores warrant further investigation.</p>"},{"location":"case-studies/overview/#reading-comparison-tables","title":"Reading Comparison Tables","text":"<p>Each case study contains a comparison table with the following columns:</p> <ul> <li>Attractor: The attractor type (e.g., \"FP\", \"LC\", \"chaos\")</li> <li>pyBasin BS +/- SE: Basin stability and standard error from the Python implementation</li> <li>bSTAB BS +/- SE: Corresponding values from the MATLAB reference</li> <li>F1: Per-class F1-score</li> </ul> <p>Above each table, a summary line reports the macro F1-score and the MCC for that comparison.</p>"},{"location":"case-studies/overview/#purpose","title":"Purpose","text":"<p>These case studies fulfil several roles at once. First, they provide a systematic validation path: comparing pyBasin results against MATLAB bSTAB on the same initial conditions establishes correctness. Beyond validation, they double as usage examples for different classes of dynamical systems. They also produce the figures and numerical tables needed for documentation. Finally, they serve as performance benchmarks.</p>"},{"location":"case-studies/overview/#available-case-studies","title":"Available Case Studies","text":""},{"location":"case-studies/overview/#duffing-oscillator","title":"Duffing Oscillator","text":"<p>A periodically forced Duffing oscillator that exhibits multistability with five coexisting limit cycle attractors.</p> <p>Key Features:</p> <ul> <li>Five coexisting limit cycle attractors</li> <li>Supervised vs. unsupervised classification comparison</li> <li>Feature extraction based on maximum amplitude and standard deviation</li> </ul> <p>Reference: Thomson, J. M. T., &amp; Stewart, H. B. (2002). Nonlinear dynamics and chaos (2nd ed.). Wiley. (See p. 9, Fig. 1.9)</p> <p>Files: <code>case_studies/duffing_oscillator/</code></p>"},{"location":"case-studies/overview/#lorenz-system","title":"Lorenz System","text":"<p>A modified Lorenz system in which two chaotic attractors coexist alongside unbounded trajectories.</p> <p>Key Features:</p> <ul> <li>Two coexisting chaotic attractors and unbounded solutions</li> <li>Parameter sweep over \u03c3</li> <li>Sample size (N) convergence study</li> <li>Sensitivity analysis of integrator tolerances (rtol/atol)</li> </ul> <p>Reference: Li, C., &amp; Sprott, J. C. (2014). Multistability in the Lorenz system: A broken butterfly. International Journal of Bifurcation and Chaos, 24(10), Article 1450131. https://doi.org/10.1142/S0218127414501314</p> <p>Files: <code>case_studies/lorenz/</code></p>"},{"location":"case-studies/overview/#pendulum","title":"Pendulum","text":"<p>A periodically forced pendulum, studied under several different forcing parameter configurations.</p> <p>Key Features:</p> <ul> <li>Multiple parameter cases</li> <li>Fixed point and limit cycle attractors</li> <li>Supervised classification</li> </ul> <p>Reference: Menck, P., Heitzig, J., Marwan, N., &amp; Kurths, J. (2013). How basin stability complements the linear-stability paradigm. Nature Physics, 9, 89\u201392. https://doi.org/10.1038/nphys2516</p> <p>Files: <code>case_studies/pendulum/</code></p>"},{"location":"case-studies/overview/#friction-system","title":"Friction System","text":"<p>A mechanical oscillator subject to dry friction, resulting in non-smooth dynamics and coexisting fixed point and limit cycle attractors.</p> <p>Key Features:</p> <ul> <li>Fixed point and limit cycle attractors</li> <li>Non-smooth dynamics due to friction</li> <li>Parameter sweep over the driving velocity \\(v_d\\)</li> </ul> <p>Reference: Stender, M., Hoffmann, N., &amp; Papangelo, A. (2020). The basin stability of bi-stable friction-excited oscillators. Lubricants, 8(12), Article 105. https://doi.org/10.3390/lubricants8120105</p> <p>Files: <code>case_studies/friction/</code></p>"},{"location":"case-studies/overview/#rossler-network","title":"R\u00f6ssler Network","text":"<p>A network of coupled R\u00f6ssler oscillators, used to study synchronization and its basin stability.</p> <p>Key Features:</p> <ul> <li>Coupled oscillator dynamics</li> <li>Synchronization analysis</li> <li>Network-level basin stability estimation</li> </ul> <p>Reference: Menck, P., Heitzig, J., Marwan, N., &amp; Kurths, J. (2013). How basin stability complements the linear-stability paradigm. Nature Physics, 9, 89\u201392. https://doi.org/10.1038/nphys2516</p> <p>Files: <code>case_studies/rossler/</code></p>"},{"location":"case-studies/overview/#running-case-studies","title":"Running Case Studies","text":"<p>From the project root, individual case studies can be executed as follows:</p> <pre><code># Navigate to project root\ncd /path/to/pyBasinWorkspace\n\n# Run a specific case study\nuv run python -m case_studies.duffing_oscillator.main_supervised\nuv run python -m case_studies.lorenz.main_lorenz\nuv run python -m case_studies.pendulum.main_case1\n</code></pre>"},{"location":"case-studies/overview/#integration-tests","title":"Integration Tests","text":"<p>Each case study has a corresponding integration test that automatically checks correctness:</p> <pre><code># Run all integration tests\nuv run pytest tests/integration/\n\n# Run specific case study test\nuv run pytest tests/integration/test_duffing.py\n</code></pre>"},{"location":"case-studies/overview/#generated-artifacts","title":"Generated Artifacts","text":"<p>Outputs are written to two locations:</p> <ul> <li>Figures: <code>docs/assets/</code> \u2014 plots and visualisations</li> <li>Results: <code>artifacts/results/</code> \u2014 numerical data (JSON, CSV)</li> </ul> <p>Passing the <code>--generate-artifacts</code> flag to the test runner regenerates these outputs:</p> <pre><code># Generate artifacts for all case studies\nuv run pytest tests/integration/ --generate-artifacts\n\n# Generate artifacts for a specific case study\nuv run pytest tests/integration/test_duffing.py --generate-artifacts\n</code></pre>"},{"location":"case-studies/overview/#contributing-new-case-studies","title":"Contributing New Case Studies","text":"<p>Adding a new case study involves the following steps:</p> <ol> <li>Create a directory under <code>case_studies/</code></li> <li>Implement the ODE system and feature extractor</li> <li>Write a main script that runs the analysis</li> <li>Add a matching integration test</li> <li>Document the study in this section</li> </ol> <p>See the Contributing Guide for further details.</p>"},{"location":"case-studies/pendulum/","title":"Pendulum","text":""},{"location":"case-studies/pendulum/#system-description","title":"System Description","text":"<p>Driven damped pendulum:</p> \\[\\ddot{\\theta} + \\gamma \\dot{\\theta} + \\sin(\\theta) = A \\cos(\\omega t)\\]"},{"location":"case-studies/pendulum/#attractors","title":"Attractors","text":"<ul> <li>Fixed Point (FP): Pendulum settles to equilibrium</li> <li>Limit Cycle (LC): Periodic oscillation</li> </ul>"},{"location":"case-studies/pendulum/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/pendulum/#setup","title":"Setup","text":"<pre><code>def setup_pendulum_system() -&gt; SetupProperties:\n    n = 10000\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up pendulum system on device: {device}\")\n\n    params: PendulumParams = {\"alpha\": 0.1, \"T\": 0.5, \"K\": 1.0}\n\n    ode_system = PendulumJaxODE(params)\n\n    sampler = UniformRandomSampler(\n        min_limits=[-np.pi + np.arcsin(params[\"T\"] / params[\"K\"]), -10.0],\n        max_limits=[np.pi + np.arcsin(params[\"T\"] / params[\"K\"]), 10.0],\n        device=device,\n    )\n\n    solver = JaxSolver(\n        time_span=(0, 1000),\n        n_steps=1000,\n        device=device,\n        rtol=1e-8,\n        atol=1e-6,\n        use_cache=True,\n    )\n\n    feature_extractor = JaxFeatureExtractor(\n        time_steady=950.0,\n        features=None,\n        features_per_state={\n            1: {\"log_delta\": None},\n        },\n        normalize=False,\n    )\n\n    template_y0 = [\n        [0.5, 0.0],\n        [2.7, 0.0],\n    ]\n    classifier_labels = [\"FP\", \"LC\"]\n\n    knn = KNeighborsClassifier(n_neighbors=1)\n\n    knn_cluster = KNNClassifier(\n        classifier=knn,\n        template_y0=template_y0,\n        labels=classifier_labels,\n        ode_params=params,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": knn_cluster,\n    }\n</code></pre>"},{"location":"case-studies/pendulum/#main-estimation","title":"Main Estimation","text":"<pre><code>def main():\n    props = setup_pendulum_system()\n\n    bse = BasinStabilityEstimator(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=props.get(\"solver\"),\n        feature_extractor=props.get(\"feature_extractor\"),\n        predictor=props.get(\"cluster_classifier\"),\n        save_to=\"results_case1\",\n        feature_selector=None,\n    )\n\n    bse.estimate_bs()\n\n    return bse\n</code></pre>"},{"location":"case-studies/pendulum/#case-1-baseline-results","title":"Case 1: Baseline Results","text":""},{"location":"case-studies/pendulum/#comparison-with-matlab-bstab","title":"Comparison with MATLAB bSTAB","text":"<p>Overall Classification Quality:</p> <ul> <li>Macro F1-score: 1.0000</li> <li>Matthews Correlation Coefficient: 1.0000</li> </ul> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.1520 \u00b1 0.0036 0.1520 \u00b1 0.0036 1.0000 LC 0.8480 \u00b1 0.0036 0.8480 \u00b1 0.0036 1.0000"},{"location":"case-studies/pendulum/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/pendulum/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/pendulum/#state-space","title":"State Space","text":""},{"location":"case-studies/pendulum/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/pendulum/#case-2-parameter-sweep","title":"Case 2: Parameter Sweep","text":""},{"location":"case-studies/pendulum/#comparison-with-matlab-bstab_1","title":"Comparison with MATLAB bSTAB","text":""},{"location":"case-studies/pendulum/#parameter-00100","title":"Parameter = 0.0100","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/pendulum/#parameter-00600","title":"Parameter = 0.0600","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/pendulum/#parameter-01100","title":"Parameter = 0.1100","text":"<p>Macro F1: 1.0000 | MCC: 0.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 1.0000"},{"location":"case-studies/pendulum/#parameter-01600","title":"Parameter = 0.1600","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.4830 \u00b1 0.0050 0.4830 \u00b1 0.0050 1.0000 LC 0.5170 \u00b1 0.0050 0.5170 \u00b1 0.0050 1.0000"},{"location":"case-studies/pendulum/#parameter-02100","title":"Parameter = 0.2100","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.3967 \u00b1 0.0049 0.3967 \u00b1 0.0049 1.0000 LC 0.6033 \u00b1 0.0049 0.6033 \u00b1 0.0049 1.0000"},{"location":"case-studies/pendulum/#parameter-02600","title":"Parameter = 0.2600","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.3268 \u00b1 0.0047 0.3268 \u00b1 0.0047 1.0000 LC 0.6732 \u00b1 0.0047 0.6732 \u00b1 0.0047 1.0000"},{"location":"case-studies/pendulum/#parameter-03100","title":"Parameter = 0.3100","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.2756 \u00b1 0.0045 0.2756 \u00b1 0.0045 1.0000 LC 0.7244 \u00b1 0.0045 0.7244 \u00b1 0.0045 1.0000"},{"location":"case-studies/pendulum/#parameter-03600","title":"Parameter = 0.3600","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.2380 \u00b1 0.0043 0.2380 \u00b1 0.0043 1.0000 LC 0.7620 \u00b1 0.0043 0.7620 \u00b1 0.0043 1.0000"},{"location":"case-studies/pendulum/#parameter-04100","title":"Parameter = 0.4100","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.2065 \u00b1 0.0040 0.2065 \u00b1 0.0040 1.0000 LC 0.7935 \u00b1 0.0040 0.7935 \u00b1 0.0040 1.0000"},{"location":"case-studies/pendulum/#parameter-04600","title":"Parameter = 0.4600","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.1703 \u00b1 0.0038 0.1703 \u00b1 0.0038 1.0000 LC 0.8297 \u00b1 0.0038 0.8297 \u00b1 0.0038 1.0000"},{"location":"case-studies/pendulum/#parameter-05100","title":"Parameter = 0.5100","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.1470 \u00b1 0.0035 0.1470 \u00b1 0.0035 1.0000 LC 0.8530 \u00b1 0.0035 0.8530 \u00b1 0.0035 1.0000"},{"location":"case-studies/pendulum/#parameter-05600","title":"Parameter = 0.5600","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.1279 \u00b1 0.0033 0.1279 \u00b1 0.0033 1.0000 LC 0.8721 \u00b1 0.0033 0.8721 \u00b1 0.0033 1.0000"},{"location":"case-studies/pendulum/#parameter-06100","title":"Parameter = 0.6100","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.1034 \u00b1 0.0030 0.1034 \u00b1 0.0030 1.0000 LC 0.8966 \u00b1 0.0030 0.8966 \u00b1 0.0030 1.0000"},{"location":"case-studies/pendulum/#parameter-06600","title":"Parameter = 0.6600","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.0839 \u00b1 0.0028 0.0839 \u00b1 0.0028 1.0000 LC 0.9161 \u00b1 0.0028 0.9161 \u00b1 0.0028 1.0000"},{"location":"case-studies/pendulum/#parameter-07100","title":"Parameter = 0.7100","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.0653 \u00b1 0.0025 0.0653 \u00b1 0.0025 1.0000 LC 0.9347 \u00b1 0.0025 0.9347 \u00b1 0.0025 1.0000"},{"location":"case-studies/pendulum/#parameter-07600","title":"Parameter = 0.7600","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.0545 \u00b1 0.0023 0.0545 \u00b1 0.0023 1.0000 LC 0.9455 \u00b1 0.0023 0.9455 \u00b1 0.0023 1.0000"},{"location":"case-studies/pendulum/#parameter-08100","title":"Parameter = 0.8100","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.0391 \u00b1 0.0019 0.0391 \u00b1 0.0019 1.0000 LC 0.9609 \u00b1 0.0019 0.9609 \u00b1 0.0019 1.0000"},{"location":"case-studies/pendulum/#parameter-08600","title":"Parameter = 0.8600","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.0244 \u00b1 0.0015 0.0244 \u00b1 0.0015 1.0000 LC 0.9756 \u00b1 0.0015 0.9756 \u00b1 0.0015 1.0000"},{"location":"case-studies/pendulum/#parameter-09100","title":"Parameter = 0.9100","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.0172 \u00b1 0.0013 0.0172 \u00b1 0.0013 1.0000 LC 0.9828 \u00b1 0.0013 0.9828 \u00b1 0.0013 1.0000"},{"location":"case-studies/pendulum/#parameter-09600","title":"Parameter = 0.9600","text":"<p>Macro F1: 1.0000 | MCC: 1.0000</p> Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE F1 FP 0.0071 \u00b1 0.0008 0.0071 \u00b1 0.0008 1.0000 LC 0.9929 \u00b1 0.0008 0.9929 \u00b1 0.0008 1.0000"},{"location":"case-studies/pendulum/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/pendulum/#basin-stability-variation","title":"Basin Stability Variation","text":""},{"location":"case-studies/pendulum/#bifurcation-diagram","title":"Bifurcation Diagram","text":""},{"location":"case-studies/rossler-network/","title":"R\u00f6ssler Network","text":""},{"location":"case-studies/rossler-network/#system-description","title":"System Description","text":"<p>Network of 100 coupled R\u00f6ssler oscillators studying synchronization dynamics:</p> \\[ \\begin{aligned} \\dot{x}_i &amp;= -y_i - z_i + K \\sum_{j \\in \\mathcal{N}_i} (x_j - x_i) \\\\ \\dot{y}_i &amp;= x_i + ay_i \\\\ \\dot{z}_i &amp;= b + z_i(x_i - c) \\end{aligned} \\] <p>where \\(i = 1, \\ldots, 100\\) and \\(\\mathcal{N}_i\\) denotes the neighbors of node \\(i\\) in the network.</p> <p>Parameters:</p> <ul> <li>\\(a = 0.2\\), \\(b = 0.2\\), \\(c = 7.0\\) (R\u00f6ssler system parameters)</li> <li>\\(K\\) = coupling strength (varied from 0.119 to 0.317)</li> <li>Network topology: Scale-free network with 100 nodes</li> </ul>"},{"location":"case-studies/rossler-network/#attractors","title":"Attractors","text":"<p>The system exhibits three types of behavior:</p> <ul> <li>Synchronized: All oscillators converge to a common trajectory</li> <li>Desynchronized: Oscillators remain coupled but do not synchronize</li> <li>Unbounded: Some trajectories diverge to infinity</li> </ul> <p>Basin stability is computed for non-unbounded states (synchronized + desynchronized).</p>"},{"location":"case-studies/rossler-network/#key-features","title":"Key Features","text":"<p>This case study uses custom feature extraction and classification:</p> <ul> <li><code>SynchronizationFeatureExtractor</code>: Computes maximum pairwise deviation across all node pairs</li> <li><code>SynchronizationClassifier</code>: Classifies based on synchronization threshold</li> </ul>"},{"location":"case-studies/rossler-network/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/rossler-network/#setup","title":"Setup","text":"<pre><code>def setup_rossler_network_system() -&gt; SetupProperties:\n    \"\"\"Setup the R\u00f6ssler network system for basin stability estimation.\n\n    Uses coupling strength K=0.218 (expected S_B \u2248 0.496 from paper).\n\n    :return: Configuration dictionary for BasinStabilityEstimator.\n    \"\"\"\n    k = 0.218\n    n = 500\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up R\u00f6ssler network system on device: {device}\")\n    print(f\"  N = {N_NODES} nodes, k = {k}\")\n\n    params: RosslerNetworkParams = {\n        \"a\": 0.2,\n        \"b\": 0.2,\n        \"c\": 7.0,\n        \"K\": k,\n        \"edges_i\": EDGES_I,\n        \"edges_j\": EDGES_J,\n        \"N\": N_NODES,\n    }\n\n    ode_system = RosslerNetworkJaxODE(params)\n\n    min_limits = (\n        [-15.0] * N_NODES  # x_i in [-15, 15]\n        + [-15.0] * N_NODES  # y_i in [-15, 15]\n        + [-5.0] * N_NODES  # z_i in [-5, 35]\n    )\n    max_limits = (\n        [15.0] * N_NODES  # x_i\n        + [15.0] * N_NODES  # y_i\n        + [35.0] * N_NODES  # z_i\n    )\n\n    sampler = UniformRandomSampler(\n        min_limits=min_limits,\n        max_limits=max_limits,\n        device=device,\n    )\n\n    solver = JaxSolver(\n        time_span=(0, 1000),\n        n_steps=1000,\n        device=device,\n        rtol=1e-3,\n        atol=1e-6,\n        use_cache=True,\n        event_fn=rossler_stop_event,\n    )\n\n    feature_extractor = SynchronizationFeatureExtractor(\n        n_nodes=N_NODES,\n        time_steady=950,\n        device=device,\n    )\n\n    sync_classifier = SynchronizationClassifier(\n        epsilon=1.5,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": sync_classifier,\n    }\n</code></pre>"},{"location":"case-studies/rossler-network/#single-k-value","title":"Single K Value","text":"<pre><code>def main() -&gt; BasinStabilityEstimator:\n    \"\"\"Run basin stability estimation for R\u00f6ssler network.\n\n    Uses coupling strength K=0.218 (expected S_B \u2248 0.496 from paper).\n\n    :return: Basin stability estimator with results.\n    \"\"\"\n    props = setup_rossler_network_system()\n\n    bse = BasinStabilityEstimator(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=props.get(\"solver\"),\n        feature_extractor=props.get(\"feature_extractor\"),\n        predictor=props.get(\"cluster_classifier\"),\n        save_to=\"results\",\n        feature_selector=None,\n        detect_unbounded=False,\n    )\n\n    bse.estimate_bs()\n\n    return bse\n</code></pre>"},{"location":"case-studies/rossler-network/#k-parameter-sweep","title":"K Parameter Sweep","text":"<pre><code>def main() -&gt; BasinStabilityStudy:\n    \"\"\"Run adaptive parameter study for R\u00f6ssler network coupling strength.\n\n    Sweeps through K values from paper to analyze basin stability variation.\n\n    :return: Adaptive basin stability estimator with results.\n    \"\"\"\n    props = setup_rossler_network_system()\n\n    study_params = SweepStudyParams(\n        name='ode_system.params[\"K\"]',\n        values=K_VALUES_FROM_PAPER.tolist(),\n    )\n\n    solver = props.get(\"solver\")\n    feature_extractor = props.get(\"feature_extractor\")\n    cluster_classifier = props.get(\"cluster_classifier\")\n    assert solver is not None\n    assert feature_extractor is not None\n    assert cluster_classifier is not None\n\n    bse = BasinStabilityStudy(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=solver,\n        feature_extractor=feature_extractor,\n        cluster_classifier=cluster_classifier,\n        study_params=study_params,\n        save_to=\"results_k_study\",\n    )\n\n    bse.estimate_as_bs()\n\n    return bse\n</code></pre>"},{"location":"case-studies/rossler-network/#baseline-results-k0218","title":"Baseline Results (K=0.218)","text":""},{"location":"case-studies/rossler-network/#comparison-with-paper-results","title":"Comparison with Paper Results","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.4840 \u00b1 0.0223 0.4960 \u00b1 0.0224 -0.0120 \u00b10.0620 \u2713 unbounded 0.5160 \u00b1 0.0223 0.5040 \u00b1 0.0224 +0.0120 \u00b10.0620 \u2713"},{"location":"case-studies/rossler-network/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/rossler-network/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/rossler-network/#state-space","title":"State Space","text":""},{"location":"case-studies/rossler-network/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/rossler-network/#k-parameter-sweep_1","title":"K Parameter Sweep","text":""},{"location":"case-studies/rossler-network/#comparison-with-paper-results_1","title":"Comparison with Paper Results","text":""},{"location":"case-studies/rossler-network/#parameter-01190","title":"Parameter = 0.1190","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.0780 \u00b1 0.0120 0.2260 \u00b1 0.0187 -0.1480 \u00b10.0435 \u2717 unbounded 0.7980 \u00b1 0.0180 0.7740 \u00b1 0.0187 +0.0240 \u00b10.0508 \u2713"},{"location":"case-studies/rossler-network/#parameter-01390","title":"Parameter = 0.1390","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.2220 \u00b1 0.0186 0.2740 \u00b1 0.0199 -0.0520 \u00b10.0534 \u2713 unbounded 0.7520 \u00b1 0.0193 0.7260 \u00b1 0.0199 +0.0260 \u00b10.0544 \u2713"},{"location":"case-studies/rossler-network/#parameter-01590","title":"Parameter = 0.1590","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.3020 \u00b1 0.0205 0.3300 \u00b1 0.0210 -0.0280 \u00b10.0576 \u2713 unbounded 0.6920 \u00b1 0.0206 0.6700 \u00b1 0.0210 +0.0220 \u00b10.0578 \u2713"},{"location":"case-studies/rossler-network/#parameter-01790","title":"Parameter = 0.1790","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.3600 \u00b1 0.0215 0.3460 \u00b1 0.0213 +0.0140 \u00b10.0592 \u2713 unbounded 0.6380 \u00b1 0.0215 0.6540 \u00b1 0.0213 -0.0160 \u00b10.0593 \u2713"},{"location":"case-studies/rossler-network/#parameter-01980","title":"Parameter = 0.1980","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.4200 \u00b1 0.0221 0.4720 \u00b1 0.0223 -0.0520 \u00b10.0615 \u2713 unbounded 0.5800 \u00b1 0.0221 0.5280 \u00b1 0.0223 +0.0520 \u00b10.0615 \u2713"},{"location":"case-studies/rossler-network/#parameter-02180","title":"Parameter = 0.2180","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.4840 \u00b1 0.0223 0.4960 \u00b1 0.0224 -0.0120 \u00b10.0620 \u2713 unbounded 0.5160 \u00b1 0.0223 0.5040 \u00b1 0.0224 +0.0120 \u00b10.0620 \u2713"},{"location":"case-studies/rossler-network/#parameter-02380","title":"Parameter = 0.2380","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.5500 \u00b1 0.0222 0.5940 \u00b1 0.0220 -0.0440 \u00b10.0613 \u2713 unbounded 0.4500 \u00b1 0.0222 0.4060 \u00b1 0.0220 +0.0440 \u00b10.0613 \u2713"},{"location":"case-studies/rossler-network/#parameter-02580","title":"Parameter = 0.2580","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.6080 \u00b1 0.0218 0.6280 \u00b1 0.0216 -0.0200 \u00b10.0602 \u2713 unbounded 0.3920 \u00b1 0.0218 0.3720 \u00b1 0.0216 +0.0200 \u00b10.0602 \u2713"},{"location":"case-studies/rossler-network/#parameter-02780","title":"Parameter = 0.2780","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.6560 \u00b1 0.0212 0.6560 \u00b1 0.0212 +0.0000 \u00b10.0589 \u2713 unbounded 0.3440 \u00b1 0.0212 0.3440 \u00b1 0.0212 +0.0000 \u00b10.0589 \u2713"},{"location":"case-studies/rossler-network/#parameter-02970","title":"Parameter = 0.2970","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.7120 \u00b1 0.0203 0.6940 \u00b1 0.0206 +0.0180 \u00b10.0566 \u2713 unbounded 0.2880 \u00b1 0.0203 0.3060 \u00b1 0.0206 -0.0180 \u00b10.0566 \u2713"},{"location":"case-studies/rossler-network/#parameter-03170","title":"Parameter = 0.3170","text":"Attractor pyBasin BS \u00b1 SE Paper BS \u00b1 SE Difference 95% CI Status synchronized 0.6780 \u00b1 0.0209 0.6900 \u00b1 0.0207 -0.0120 \u00b10.0576 \u2713 unbounded 0.2840 \u00b1 0.0202 0.3100 \u00b1 0.0207 -0.0260 \u00b10.0566 \u2713"},{"location":"case-studies/rossler-network/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/rossler-network/#basin-stability-variation","title":"Basin Stability Variation","text":""},{"location":"case-studies/rossler-network/#references","title":"References","text":"<p>Menck, P. J., Heitzig, J., Marwan, N., &amp; Kurths, J. (2013). How basin stability complements the linear-stability paradigm. Nature Physics, 9(2), 89-92.</p>"},{"location":"development/contributing/","title":"Contributing","text":"<p>TODO</p> <p>This section is under development.</p>"},{"location":"development/contributing/#adding-a-new-case-study","title":"Adding a New Case Study","text":"<p>To add a new case study:</p> <ol> <li>Create a new directory under <code>case_studies/</code></li> <li>Implement the ODE system and feature extractor</li> <li>Create a main script that runs the analysis</li> <li>Add corresponding integration test</li> <li>Document in the case studies section</li> </ol>"},{"location":"development/contributing/#development-guidelines","title":"Development Guidelines","text":"<p>More information coming soon.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>pip or uv package manager</li> </ul>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<p>Once published, you'll be able to install pyBasin using pip:</p> <pre><code>pip install pybasin\n</code></pre>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":""},{"location":"getting-started/installation/#using-uv-recommended","title":"Using UV (Recommended)","text":"<pre><code># Clone the repository\ngit clone https://github.com/adrianwix/pyBasin.git\ncd pyBasinWorkspace\n\n# Install with UV\nuv add -e .\n\n# Or install with all optional dependencies\nuv add -e \".[all]\"\n</code></pre>"},{"location":"getting-started/installation/#using-pip","title":"Using pip","text":"<pre><code># Clone the repository\ngit clone https://github.com/adrianwix/pyBasin.git\ncd pyBasinWorkspace\n\n# Install in editable mode\npip install -e .\n\n# Or install with all optional dependencies\npip install -e \".[all]\"\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"getting-started/installation/#development-tools","title":"Development Tools","text":"<p>Install testing and linting tools:</p> <pre><code>uv add -e \".[dev]\"\n</code></pre> <p>Includes:</p> <ul> <li>pytest</li> <li>pytest-cov</li> <li>mypy</li> <li>ruff</li> <li>black</li> </ul>"},{"location":"getting-started/installation/#documentation","title":"Documentation","text":"<p>Install documentation building tools:</p> <pre><code>uv add -e \".[docs]\"\n</code></pre> <p>Includes:</p> <ul> <li>mkdocs-material</li> <li>mkdocstrings</li> <li>mkdocs-jupyter</li> </ul>"},{"location":"getting-started/installation/#case-studies","title":"Case Studies","text":"<p>Install additional dependencies for running case studies:</p> <pre><code>uv add -e \".[case-studies]\"\n</code></pre> <p>Includes:</p> <ul> <li>jupyter</li> <li>openpyxl</li> <li>notebook</li> </ul>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>Verify your installation:</p> <pre><code>import pybasin\nprint(pybasin.__version__)\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Check out the Quick Start guide</li> <li>Explore the API Reference</li> <li>Run the Case Studies</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide will help you get started with pyBasin in just a few minutes.</p>"},{"location":"getting-started/quickstart/#basic-example","title":"Basic Example","text":"<p>Here's a simple example of estimating basin stability for a 2D dynamical system:</p> <pre><code>import numpy as np\nfrom pybasin import BasinStabilityEstimator, ODESystem\n\n# Step 1: Define your dynamical system\nclass SimpleSystem(ODESystem):\n    \"\"\"A simple 2D system with two stable fixed points.\"\"\"\n\n    def dynamics(self, t, state):\n        \"\"\"Define the differential equations.\"\"\"\n        x, y = state\n        dx = x * (1 - x**2 - y**2)\n        dy = y * (1 - x**2 - y**2)\n        return np.array([dx, dy])\n\n    def classify_attractor(self, solution):\n        \"\"\"Classify which attractor the solution reached.\"\"\"\n        final_state = solution.y[:, -1]\n        x_final, y_final = final_state\n\n        # Classify based on final position\n        if x_final &gt; 0:\n            return 0  # Right attractor\n        else:\n            return 1  # Left attractor\n\n# Step 2: Create the estimator\nsystem = SimpleSystem()\nestimator = BasinStabilityEstimator(\n    system=system,\n    t_span=(0, 50),  # Integration time\n    n_samples=1000   # Number of initial conditions\n)\n\n# Step 3: Define the sampling region\nbounds = [(-2, 2), (-2, 2)]  # [x_min, x_max], [y_min, y_max]\n\n# Step 4: Estimate basin stability\nresults = estimator.estimate(bounds)\n\n# Step 5: Analyze results\nprint(f\"Basin Stability (Attractor 0): {results.basin_stability[0]:.3f}\")\nprint(f\"Basin Stability (Attractor 1): {results.basin_stability[1]:.3f}\")\nprint(f\"Total samples: {results.n_samples}\")\nprint(f\"Attractor distribution: {results.attractor_counts}\")\n\n# Step 6: Visualize\nresults.plot_basin_2d()\n</code></pre>"},{"location":"getting-started/quickstart/#using-adaptive-sampling","title":"Using Adaptive Sampling","text":"<p>For more efficient sampling, use the adaptive sampling estimator:</p> <pre><code>from pybasin import BasinStabilityStudy\n\n# Create adaptive sampling estimator\nas_estimator = BasinStabilityStudy(\n    system=system,\n    initial_samples=100,\n    max_samples=1000,\n    uncertainty_threshold=0.1\n)\n\n# Estimate with adaptive sampling\nas_results = as_estimator.estimate(bounds)\n\nprint(f\"Samples used: {as_results.n_samples}\")\nprint(f\"Convergence achieved: {as_results.converged}\")\n</code></pre>"},{"location":"getting-started/quickstart/#custom-feature-extraction","title":"Custom Feature Extraction","text":"<p>You can define custom features for better classification:</p> <pre><code>from pybasin import FeatureExtractor\n\nclass MyFeatureExtractor(FeatureExtractor):\n    \"\"\"Extract custom features from solutions.\"\"\"\n\n    def extract(self, solution):\n        \"\"\"Extract features from the solution.\"\"\"\n        t = solution.t\n        y = solution.y\n\n        features = {\n            'final_x': y[0, -1],\n            'final_y': y[1, -1],\n            'max_distance': np.max(np.sqrt(y[0]**2 + y[1]**2)),\n            'period': self._estimate_period(t, y),\n        }\n        return features\n\n    def _estimate_period(self, t, y):\n        \"\"\"Estimate the period of oscillation.\"\"\"\n        # Your period estimation logic here\n        return 0.0\n\n# Use custom feature extractor\nestimator = BasinStabilityEstimator(\n    system=system,\n    feature_extractor=MyFeatureExtractor()\n)\n</code></pre>"},{"location":"getting-started/quickstart/#working-with-high-dimensional-systems","title":"Working with High-Dimensional Systems","text":"<p>For systems with more than 2 dimensions:</p> <pre><code>class LorenzSystem(ODESystem):\n    \"\"\"The Lorenz system.\"\"\"\n\n    def __init__(self, sigma=10, rho=28, beta=8/3):\n        self.sigma = sigma\n        self.rho = rho\n        self.beta = beta\n\n    def dynamics(self, t, state):\n        x, y, z = state\n        dx = self.sigma * (y - x)\n        dy = x * (self.rho - z) - y\n        dz = x * y - self.beta * z\n        return np.array([dx, dy, dz])\n\n    def classify_attractor(self, solution):\n        # Classification logic for Lorenz attractors\n        final_state = solution.y[:, -1]\n        if final_state[2] &gt; 20:\n            return 0\n        return 1\n\n# Sample in 3D space\nlorenz = LorenzSystem()\nestimator = BasinStabilityEstimator(lorenz)\nbounds = [(-20, 20), (-30, 30), (0, 50)]\nresults = estimator.estimate(bounds)\n</code></pre>"},{"location":"getting-started/quickstart/#saving-and-loading-results","title":"Saving and Loading Results","text":"<pre><code># Save results\nresults.save('my_results.json')\n\n# Load results\nfrom pybasin import BasinStabilityResult\nloaded_results = BasinStabilityResult.load('my_results.json')\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the API Reference</li> <li>Check out the Case Studies for real-world examples</li> </ul>"},{"location":"guides/custom-feature-extractor/","title":"Creating Custom Feature Extractors","text":"<p>Feature extractors transform ODE solution trajectories into feature vectors used for basin of attraction classification. This guide shows how to create your own.</p>"},{"location":"guides/custom-feature-extractor/#basic-implementation","title":"Basic Implementation","text":"<p>To create a custom feature extractor, subclass <code>FeatureExtractor</code> and implement the <code>extract_features</code> method:</p> <pre><code>import torch\nfrom pybasin.feature_extractors.feature_extractor import FeatureExtractor\nfrom pybasin.solution import Solution\n\n\nclass AmplitudeFeatureExtractor(FeatureExtractor):\n    def extract_features(self, solution: Solution) -&gt; torch.Tensor:\n        # Filter out transient behavior\n        y_filtered: torch.Tensor = self.filter_time(solution)\n\n        # Compute features - here we extract max amplitude per state\n        # y_filtered shape: (n_times, n_samples, n_states)\n        max_amplitude: torch.Tensor = torch.max(torch.abs(y_filtered), dim=0).values\n\n        # Set _num_features for automatic feature naming\n        self._num_features = max_amplitude.shape[1]\n\n        # Return shape: (n_samples, n_features)\n        return max_amplitude\n</code></pre>"},{"location":"guides/custom-feature-extractor/#key-points","title":"Key Points","text":"<ol> <li>Use <code>filter_time</code>: Call <code>self.filter_time(solution)</code> to remove transient dynamics based on <code>time_steady</code></li> <li>Return a tensor: The return type must be <code>torch.Tensor</code> with shape <code>(n_samples, n_features)</code></li> <li>Set <code>_num_features</code>: Assign <code>self._num_features</code> to enable automatic feature naming</li> <li>Do NOT modify the Solution object: The <code>extract_features</code> method should be pure - read from the solution, compute features, and return them. Never assign to <code>solution.features</code>, <code>solution.extracted_features</code>, or any other solution attributes.</li> </ol>"},{"location":"guides/custom-feature-extractor/#using-the-extractor","title":"Using the Extractor","text":"<pre><code>extractor = AmplitudeFeatureExtractor(time_steady=100.0)\nfeatures = extractor.extract_features(solution)\n\n# Feature names are automatically generated\nprint(extractor.feature_names)  # ['amplitude_1', 'amplitude_2', ...]\n</code></pre>"},{"location":"guides/custom-feature-extractor/#custom-feature-names","title":"Custom Feature Names","text":"<p>By default, feature names are generated automatically from the class name:</p> <ul> <li><code>AmplitudeFeatureExtractor</code> \u2192 <code>amplitude_1</code>, <code>amplitude_2</code>, ...</li> <li><code>SynchronizationFeatureExtractor</code> \u2192 <code>synchronization_1</code>, <code>synchronization_2</code>, ...</li> </ul>"},{"location":"guides/custom-feature-extractor/#overriding-feature-names","title":"Overriding Feature Names","text":"<p>To use custom, meaningful names, set <code>_feature_names</code> in <code>__init__</code>:</p> <pre><code>class SynchronizationFeatureExtractor(FeatureExtractor):\n    def __init__(\n        self,\n        n_nodes: int,\n        time_steady: float = 1000.0,\n    ):\n        super().__init__(time_steady=time_steady)\n        self.n_nodes = n_nodes\n        # Define custom feature names\n        self._feature_names = [\n            \"max_deviation_x\",\n            \"max_deviation_y\",\n            \"max_deviation_z\",\n            \"max_deviation_all\",\n        ]\n\n    def extract_features(self, solution: Solution) -&gt; torch.Tensor:\n        y_filtered: torch.Tensor = self.filter_time(solution)\n        # ... compute features ...\n        return features  # shape: (n_samples, 4)\n</code></pre> <p>When <code>_feature_names</code> is set, it takes precedence over automatic name generation.</p>"},{"location":"guides/custom-feature-extractor/#complete-example","title":"Complete Example","text":"<pre><code>import torch\nfrom pybasin.feature_extractors.feature_extractor import FeatureExtractor\nfrom pybasin.solution import Solution\n\n\nclass MeanAndStdFeatureExtractor(FeatureExtractor):\n    \"\"\"Extract mean and standard deviation of each state variable.\"\"\"\n\n    def __init__(self, n_states: int, time_steady: float = 0.0):\n        super().__init__(time_steady=time_steady)\n        self.n_states = n_states\n        # Custom names: mean_0, std_0, mean_1, std_1, ...\n        self._feature_names = []\n        for i in range(n_states):\n            self._feature_names.extend([f\"mean_{i}\", f\"std_{i}\"])\n\n    def extract_features(self, solution: Solution) -&gt; torch.Tensor:\n        y_filtered: torch.Tensor = self.filter_time(solution)\n        # y_filtered: (n_times, n_samples, n_states)\n\n        mean_vals: torch.Tensor = y_filtered.mean(dim=0)  # (n_samples, n_states)\n        std_vals: torch.Tensor = y_filtered.std(dim=0)    # (n_samples, n_states)\n\n        # Interleave: [mean_0, std_0, mean_1, std_1, ...]\n        features: torch.Tensor = torch.stack(\n            [mean_vals, std_vals], dim=2\n        ).reshape(mean_vals.shape[0], -1)\n\n        return features\n</code></pre>"},{"location":"guides/torchode-solver/","title":"TorchOdeSolver - Alternative ODE Solver","text":"<p>This document explains the <code>TorchOdeSolver</code> implementation, an alternative to <code>TorchDiffEqSolver</code>.</p>"},{"location":"guides/torchode-solver/#overview","title":"Overview","text":"<p><code>TorchOdeSolver</code> is a PyTorch-based ODE solver that uses the torchode library. It provides:</p> <ul> <li>JIT Compilation: Optional PyTorch JIT compilation for better performance</li> <li>Batch Parallelization: Efficient parallel solving across batches</li> <li>Multiple Methods: Various integration methods (dopri5, tsit5, euler, etc.)</li> <li>GPU Support: Full CUDA support like TorchDiffEqSolver</li> </ul>"},{"location":"guides/torchode-solver/#performance-comparison","title":"Performance Comparison","text":"<p>\u26a0\ufe0f Important: In the current implementation, TorchDiffEqSolver is faster than TorchOdeSolver for single-trajectory integration:</p> <ul> <li>TorchDiffEqSolver: ~76 seconds for 10,000 samples (pendulum case study)</li> <li>TorchOdeSolver: ~119 seconds for 10,000 samples (pendulum case study)</li> </ul> <p>This is because:</p> <ol> <li>The current architecture integrates one trajectory at a time (batch_size=1)</li> <li>torchode's batch parallelization doesn't help with batch_size=1</li> <li>torchdiffeq is more optimized for single-trajectory integration</li> </ol> <p>When TorchOdeSolver would be faster:</p> <ul> <li>When integrating multiple trajectories in parallel (requires code restructuring)</li> <li>When using JIT compilation with repeated solves of the same system</li> <li>For problems where variable step sizes per trajectory are needed</li> </ul>"},{"location":"guides/torchode-solver/#installation","title":"Installation","text":"<p>To use <code>TorchOdeSolver</code>, you need to install the <code>torchode</code> package:</p> <pre><code># Using pip\npip install torchode\n\n# Using uv\nuv add torchode\n\n# Or install with the optional solvers dependency\npip install -e \".[solvers]\"\n</code></pre>"},{"location":"guides/torchode-solver/#comparison-torchdiffeqsolver-vs-torchodesolver","title":"Comparison: TorchDiffEqSolver vs TorchOdeSolver","text":""},{"location":"guides/torchode-solver/#torchdiffeqsolver-torchdiffeq","title":"TorchDiffEqSolver (torchdiffeq)","text":"<ul> <li>Default Solver: dopri5 (Dormand-Prince 5(4))</li> <li>Similar to: MATLAB's ode45</li> <li>Pros:</li> <li>Well-established, widely used</li> <li>Adjoint method for memory-efficient backpropagation</li> <li>Simple API</li> <li>Cons:</li> <li>No batch parallelization</li> <li>No JIT compilation support</li> </ul>"},{"location":"guides/torchode-solver/#torchodesolver-torchode","title":"TorchOdeSolver (torchode)","text":"<ul> <li>Default Solver: dopri5 (Dormand-Prince 5(4))</li> <li>Pros:</li> <li>JIT compilation support for performance</li> <li>Batch parallelization (different step sizes per sample)</li> <li>Modern PyTorch integration</li> <li>Multiple solver methods</li> <li>Cons:</li> <li>Newer library, less widespread adoption</li> <li>More complex API</li> </ul>"},{"location":"guides/torchode-solver/#available-methods","title":"Available Methods","text":""},{"location":"guides/torchode-solver/#adaptive-step-methods","title":"Adaptive-Step Methods","text":"<ul> <li><code>dopri5</code> (default): Dormand-Prince 5(4) - similar to MATLAB's ode45</li> <li><code>tsit5</code>: Tsitouras 5(4) - often more efficient than dopri5</li> </ul>"},{"location":"guides/torchode-solver/#fixed-step-methods","title":"Fixed-Step Methods","text":"<ul> <li><code>euler</code>: Explicit Euler (1st order)</li> <li><code>midpoint</code>: Explicit midpoint (2nd order)</li> <li><code>heun</code>: Heun's method (2nd order)</li> </ul>"},{"location":"guides/torchode-solver/#usage-example","title":"Usage Example","text":""},{"location":"guides/torchode-solver/#basic-usage","title":"Basic Usage","text":"<pre><code>from pybasin.solver import TorchOdeSolver\n\n# Create solver with default settings (dopri5)\nsolver = TorchOdeSolver(\n    time_span=(0, 1000),\n    fs=25,\n    device=\"cuda\"\n)\n</code></pre>"},{"location":"guides/torchode-solver/#with-custom-settings","title":"With Custom Settings","text":"<pre><code>solver = TorchOdeSolver(\n    time_span=(0, 1000),\n    fs=25,\n    device=\"cuda\",\n    method=\"tsit5\",      # Use Tsitouras method\n    rtol=1e-8,           # Relative tolerance\n    atol=1e-6,           # Absolute tolerance\n    use_jit=True         # Enable JIT compilation\n)\n</code></pre>"},{"location":"guides/torchode-solver/#complete-example","title":"Complete Example","text":"<p>See <code>case_studies/pendulum/main_pendulum_case1_torchode.py</code> for a complete working example.</p> <pre><code>from case_studies.pendulum.setup_pendulum_system_torchode import (\n    setup_pendulum_system_torchode,\n)\nfrom pybasin.basin_stability_estimator import BasinStabilityEstimator\n\n# Setup system with TorchOdeSolver\nprops = setup_pendulum_system_torchode()\n\n# Create estimator\nbse = BasinStabilityEstimator(\n    n=props[\"n\"],\n    ode_system=props[\"ode_system\"],\n    sampler=props[\"sampler\"],\n    solver=props[\"solver\"],  # Using TorchOdeSolver\n    feature_extractor=props[\"feature_extractor\"],\n    cluster_classifier=props[\"cluster_classifier\"],\n)\n\n# Estimate basin stability\nbasin_stability = bse.estimate_bs()\n</code></pre>"},{"location":"guides/torchode-solver/#running-the-test-case-study","title":"Running the Test Case Study","text":"<p>To test the TorchOdeSolver implementation:</p> <pre><code># First, install torchode\nuv add torchode\n\n# Run the pendulum case study with TorchOdeSolver\npython case_studies/pendulum/main_pendulum_case1_torchode.py\n</code></pre>"},{"location":"guides/torchode-solver/#performance-tips","title":"Performance Tips","text":"<ol> <li>Enable JIT Compilation: Set <code>use_jit=True</code> for repeated solves with the same system</li> </ol> <pre><code>solver = TorchOdeSolver(time_span=(0, 1000), fs=25, use_jit=True)\n</code></pre> <ol> <li> <p>Choose the Right Method:</p> </li> <li> <p>For general problems: <code>dopri5</code> (default)</p> </li> <li>For better efficiency: <code>tsit5</code></li> <li> <p>For simple/fast problems: <code>euler</code> or <code>midpoint</code> (fixed step)</p> </li> <li> <p>Adjust Tolerances:</p> </li> <li> <p>Tighter tolerances (smaller rtol/atol) = more accurate but slower</p> </li> <li> <p>Looser tolerances = faster but less accurate</p> </li> <li> <p>GPU Acceleration: Always specify <code>device=\"cuda\"</code> if available</p> </li> </ol>"},{"location":"guides/torchode-solver/#implementation-details","title":"Implementation Details","text":"<p>The <code>TorchOdeSolver</code> class:</p> <ul> <li>Inherits from the abstract <code>Solver</code> base class</li> <li>Implements the <code>_integrate()</code> method</li> <li>Handles batch dimension conversion (torchode expects batched inputs)</li> <li>Supports caching like TorchDiffEqSolver</li> <li>Falls back gracefully if torchode is not installed</li> </ul>"},{"location":"guides/torchode-solver/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/torchode-solver/#import-error","title":"Import Error","text":"<pre><code>ImportError: torchode is not installed\n</code></pre> <p>Solution: Install torchode with <code>pip install torchode</code></p>"},{"location":"guides/torchode-solver/#unknown-method-error","title":"Unknown Method Error","text":"<pre><code>ValueError: Unknown method: xyz\n</code></pre> <p>Solution: Use one of the available methods: dopri5, tsit5, euler, midpoint, heun</p>"},{"location":"guides/torchode-solver/#integration-failed","title":"Integration Failed","text":"<pre><code>RuntimeError: torchode integration failed\n</code></pre> <p>Solution: Try adjusting tolerances or using a different method</p>"},{"location":"guides/torchode-solver/#references","title":"References","text":"<ul> <li>torchode GitHub</li> <li>torchode Documentation</li> <li>torchode Paper</li> <li>torchdiffeq GitHub (for comparison)</li> </ul>"},{"location":"guides/type-safety-generics/","title":"Type Safety and Generics in pyBasin","text":""},{"location":"guides/type-safety-generics/#overview","title":"Overview","text":"<p>pyBasin uses Python's generic type system to provide strong type safety for ODE parameters across the entire library. This guide explains how to use generics effectively when extending pyBasin with your own ODE systems.</p>"},{"location":"guides/type-safety-generics/#why-generics","title":"Why Generics?","text":"<p>The generic type system provides:</p> <ol> <li>Type Safety: Static type checkers (mypy, pyright) can verify parameter types at development time</li> <li>IDE Autocomplete: Your IDE will know exactly which parameters are available</li> <li>Self-Documentation: Types serve as documentation for what parameters an ODE system expects</li> <li>Refactoring Safety: Renaming or changing parameter types will show errors across your codebase</li> </ol>"},{"location":"guides/type-safety-generics/#how-to-define-a-new-ode-system","title":"How to Define a New ODE System","text":""},{"location":"guides/type-safety-generics/#step-1-define-your-parameter-type","title":"Step 1: Define Your Parameter Type","text":"<p>Use <code>TypedDict</code> to define the exact parameters your ODE system needs:</p> <pre><code>from typing import TypedDict\n\nclass MyODEParams(TypedDict):\n    \"\"\"Parameters for my ODE system.\"\"\"\n    alpha: float      # damping coefficient\n    beta: float       # forcing amplitude\n    omega: float      # forcing frequency\n    initial_mass: float  # initial mass\n</code></pre> <p>Benefits:</p> <ul> <li>Type checkers will enforce that all required keys are present</li> <li>IDE will autocomplete parameter names</li> <li>Docstrings on each field document what they mean</li> </ul>"},{"location":"guides/type-safety-generics/#step-2-create-your-ode-system","title":"Step 2: Create Your ODE System","text":"<p>Inherit from <code>ODESystem[YourParamsType]</code>:</p> <pre><code>from pybasin.ode_system import ODESystem\nimport torch\n\nclass MyODE(ODESystem[MyODEParams]):\n    def __init__(self, params: MyODEParams):\n        super().__init__(params)\n        # self.params is now typed as MyODEParams!\n\n    def ode(self, t: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n        # Type checker knows these keys exist\n        alpha = self.params[\"alpha\"]\n        beta = self.params[\"beta\"]\n        omega = self.params[\"omega\"]\n\n        # ... your ODE logic here ...\n        dy_dt = -alpha * y + beta * torch.sin(omega * t)\n        return dy_dt\n\n    def get_str(self) -&gt; str:\n        return f\"My ODE with \u03b1={self.params['alpha']}\"\n</code></pre>"},{"location":"guides/type-safety-generics/#step-3-use-type-safe-parameters-everywhere","title":"Step 3: Use Type-Safe Parameters Everywhere","text":"<p>When creating classifiers or other components, you can pass your typed parameters:</p> <pre><code>from pybasin.predictors.knn_classifier import KNNClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Create your parameters with full type safety\nparams: MyODEParams = {\n    \"alpha\": 0.1,\n    \"beta\": 1.0,\n    \"omega\": 2.0,\n    \"initial_mass\": 1.5,\n}\n\n# Type checker ensures params matches MyODEParams\node_system = MyODE(params)\n\n# Pass the parameters to the classifier\nknn_classifier = KNNClassifier(\n    classifier=KNeighborsClassifier(n_neighbors=3),\n    template_y0=[[0.0, 1.0], [1.0, 0.0]],\n    labels=[\"stable\", \"unstable\"],\n    ode_params=params,\n)\n</code></pre>"},{"location":"guides/type-safety-generics/#complete-example-pendulum-system","title":"Complete Example: Pendulum System","text":"<p>Here's the pendulum example showing full type safety:</p> <pre><code># 1. Define parameters\nfrom typing import TypedDict\n\nclass PendulumParams(TypedDict):\n    \"\"\"Parameters for the pendulum ODE system.\"\"\"\n    alpha: float  # damping coefficient\n    T: float      # external torque\n    K: float      # stiffness coefficient\n\n# 2. Create ODE system\nfrom pybasin.ode_system import ODESystem\nimport torch\n\nclass PendulumODE(ODESystem[PendulumParams]):\n    def __init__(self, params: PendulumParams):\n        super().__init__(params)\n\n    def ode(self, t: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n        # IDE autocompletes these parameter names!\n        alpha = self.params[\"alpha\"]\n        T = self.params[\"T\"]\n        K = self.params[\"K\"]\n\n        theta = y[..., 0]\n        theta_dot = y[..., 1]\n\n        dtheta_dt = theta_dot\n        dtheta_dot_dt = -alpha * theta_dot + T - K * torch.sin(theta)\n\n        return torch.stack([dtheta_dt, dtheta_dot_dt], dim=-1)\n\n    def get_str(self) -&gt; str:\n        return (\n            f\"Pendulum ODE:\\n\"\n            f\"  d\u03b8/dt = \u03c9\\n\"\n            f\"  d\u03c9/dt = -{self.params['alpha']}\u03c9 + \"\n            f\"{self.params['T']} - {self.params['K']}sin(\u03b8)\"\n        )\n\n# 3. Use with type safety\ndef setup_pendulum():\n    # Type checker verifies all required keys are present\n    params: PendulumParams = {\n        \"alpha\": 0.1,\n        \"T\": 0.5,\n        \"K\": 1.0,\n    }\n\n    # If you forget a parameter or misspell it, you'll get a type error!\n    # params: PendulumParams = {\"alpha\": 0.1}  # ERROR: Missing 'T' and 'K'\n\n    ode = PendulumODE(params)\n    return ode\n</code></pre>"},{"location":"guides/type-safety-generics/#comparison-with-typescript","title":"Comparison with TypeScript","text":"<p>If you're familiar with TypeScript, here's how the concepts map:</p>"},{"location":"guides/type-safety-generics/#typescript","title":"TypeScript:","text":"<pre><code>interface PendulumParams {\n  alpha: number;\n  T: number;\n  K: number;\n}\n\nclass PendulumODE extends ODESystem&lt;PendulumParams&gt; {\n  constructor(params: PendulumParams) {\n    super(params);\n    // this.params is typed as PendulumParams\n  }\n}\n</code></pre>"},{"location":"guides/type-safety-generics/#python-pybasin","title":"Python (pyBasin):","text":"<pre><code>class PendulumParams(TypedDict):\n    alpha: float\n    T: float\n    K: float\n\nclass PendulumODE(ODESystem[PendulumParams]):\n    def __init__(self, params: PendulumParams):\n        super().__init__(params)\n        # self.params is typed as PendulumParams\n</code></pre> <p>The main difference is that Python uses <code>TypedDict</code> instead of <code>interface</code>, and square brackets <code>[]</code> for generics instead of angle brackets <code>&lt;&gt;</code>.</p>"},{"location":"guides/type-safety-generics/#type-checking","title":"Type Checking","text":"<p>To verify your types are correct, run:</p> <pre><code># With pyright (recommended for VS Code)\nuv run pyright\n\n# Or with mypy\nuv run mypy src/\n</code></pre>"},{"location":"guides/type-safety-generics/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/type-safety-generics/#optional-parameters","title":"Optional Parameters","text":"<pre><code>from typing import TypedDict, NotRequired\n\nclass OptionalParams(TypedDict):\n    alpha: float                    # Required\n    beta: NotRequired[float]        # Optional (Python 3.11+)\n</code></pre>"},{"location":"guides/type-safety-generics/#multiple-parameter-types","title":"Multiple Parameter Types","text":"<p>If you need to support multiple parameter configurations:</p> <pre><code>from typing import Union\n\nParamVariant1 = TypedDict(\"ParamVariant1\", {\"a\": float, \"b\": float})\nParamVariant2 = TypedDict(\"ParamVariant2\", {\"x\": float, \"y\": float})\n\nclass FlexibleODE(ODESystem[Union[ParamVariant1, ParamVariant2]]):\n    def ode(self, t, y):\n        if \"a\" in self.params:\n            # Handle variant 1\n            pass\n        else:\n            # Handle variant 2\n            pass\n</code></pre>"},{"location":"guides/type-safety-generics/#best-practices","title":"Best Practices","text":"<ol> <li>Always use TypedDict for parameters: Don't use plain <code>dict[str, float]</code></li> <li>Document your parameter fields: Add docstrings or comments to each field</li> <li>Be specific with types: Use <code>float</code>, <code>int</code>, <code>str</code> instead of <code>Any</code></li> <li>Run type checkers regularly: Integrate <code>pyright</code> or <code>mypy</code> into your workflow</li> <li>Keep parameters immutable: Don't modify <code>self.params</code> after initialization</li> </ol>"},{"location":"guides/type-safety-generics/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/type-safety-generics/#type-is-not-assignable-to-typevar","title":"\"Type is not assignable to TypeVar\"","text":"<p>If you see this error, make sure:</p> <ul> <li>Your parameter type is a <code>TypedDict</code> or plain <code>dict</code></li> <li>You're consistently using the same generic type throughout</li> </ul>"},{"location":"guides/type-safety-generics/#ide-not-showing-autocomplete","title":"IDE not showing autocomplete","text":"<ul> <li>Restart your Python language server</li> <li>Ensure your <code>TypedDict</code> is properly defined</li> <li>Check that you're using the latest version of your type checker</li> </ul>"},{"location":"guides/type-safety-generics/#further-reading","title":"Further Reading","text":"<ul> <li>Python TypedDict documentation</li> <li>PEP 589 \u2013 TypedDict</li> <li>Pyright documentation</li> </ul>"},{"location":"guides/unbounded-trajectories/","title":"Handling Unbounded Trajectories","text":""},{"location":"guides/unbounded-trajectories/#overview","title":"Overview","text":"<p>When computing basin stability, some initial conditions may lead to unbounded trajectories that diverge to infinity. These trajectories need special handling to:</p> <ol> <li>Stop integration early to save computation time</li> <li>Classify correctly as a distinct attractor state</li> <li>Avoid numerical overflow in the solver</li> </ol> <p>This guide explains the recommended approaches for handling unbounded trajectories in pyBasin.</p> <p>Quick Recommendation</p> <p>Use JaxSolver with event functions for the best performance and flexibility when dealing with unbounded trajectories.</p>"},{"location":"guides/unbounded-trajectories/#understanding-the-problem","title":"Understanding the Problem","text":"<p>In dynamical systems like the Lorenz system, some regions of the state space lead to trajectories that grow without bound:</p> <pre><code># Example: Lorenz \"broken butterfly\" system\nparams = {\"sigma\": 0.12, \"r\": 0.0, \"b\": -0.6}\n\n# Some initial conditions lead to bounded attractors:\nic_butterfly1 = [0.8, -3.0, 0.0]   # \u2192 bounded attractor\nic_butterfly2 = [-0.8, 3.0, 0.0]   # \u2192 bounded attractor\n\n# Others lead to unbounded trajectories:\nic_unbounded = [10.0, 50.0, 0.0]   # \u2192 |y| \u2192 \u221e\n</code></pre> <p>Without proper handling, unbounded trajectories will:</p> <ul> <li>Waste computation time integrating to large values</li> <li>Risk numerical overflow errors</li> <li>Contaminate basin stability estimates</li> </ul>"},{"location":"guides/unbounded-trajectories/#recommended-approach-jaxsolver-with-event-functions","title":"Recommended Approach: JaxSolver with Event Functions","text":"<p>The recommended solution is to use <code>JaxSolver</code> with an event function that stops integration when trajectories exceed a threshold.</p>"},{"location":"guides/unbounded-trajectories/#why-jaxsolver","title":"Why JaxSolver?","text":"<p>JAX's <code>diffrax</code> library supports event-based termination where each trajectory in a batch can stop independently:</p> <ul> <li>\u2705 Individual termination: Each trajectory stops when it meets the condition</li> <li>\u2705 Efficient: Other trajectories continue integrating</li> <li>\u2705 Clean classification: Stopped trajectories are marked appropriately</li> </ul>"},{"location":"guides/unbounded-trajectories/#complete-example","title":"Complete Example","text":"<p>Here's a complete example from the Lorenz case study:</p> <pre><code>import torch\nfrom case_studies.lorenz.lorenz_jax_ode import LorenzJaxODE, LorenzParams\nfrom case_studies.lorenz.setup_lorenz_system import lorenz_stop_event\nfrom pybasin.basin_stability_estimator import BasinStabilityEstimator\nfrom pybasin.sampler import UniformRandomSampler\nfrom pybasin.solvers.jax_solver import JaxSolver\n\ndef main():\n    # Number of initial conditions to sample\n    n = 10_000\n\n    # Auto-detect device (use GPU if available)\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up Lorenz system on device: {device}\")\n\n    # Parameters for broken butterfly system\n    params: LorenzParams = {\"sigma\": 0.12, \"r\": 0.0, \"b\": -0.6}\n    ode_system = LorenzJaxODE(params)\n\n    # Sample uniformly in the region of interest\n    sampler = UniformRandomSampler(\n        min_limits=[-10.0, -20.0, 0.0],\n        max_limits=[10.0, 20.0, 0.0],\n        device=device\n    )\n\n    # JaxSolver with event function to stop unbounded trajectories\n    solver = JaxSolver(\n        device=device,\n        event_fn=lorenz_stop_event,  # \u2190 Key: event function\n    )\n\n    # Estimate basin stability\n    bse = BasinStabilityEstimator(\n        n=n,\n        ode_system=ode_system,\n        sampler=sampler,\n        solver=solver,\n        save_to=\"results_lorenz\",\n    )\n\n    basin_stability = bse.estimate_bs()\n    print(\"Basin Stability:\", basin_stability)\n\n    return bse\n\nif __name__ == \"__main__\":\n    bse = main()\n</code></pre>"},{"location":"guides/unbounded-trajectories/#defining-event-functions","title":"Defining Event Functions","text":"<p>The event function determines when to stop integration. Here's the <code>lorenz_stop_event</code> example:</p> <pre><code>import jax.numpy as jnp\nfrom diffrax import Event\n\ndef lorenz_stop_event(t, y, args):\n    \"\"\"\n    Stop integration when trajectory magnitude exceeds 200.\n\n    Args:\n        t: Current time\n        y: Current state [x, y, z]\n        args: Additional arguments (unused)\n\n    Returns:\n        Scalar value that triggers event when it crosses zero.\n        Negative = continue, positive = stop.\n    \"\"\"\n    # Compute maximum absolute value across all state components\n    max_magnitude = jnp.max(jnp.abs(y))\n\n    # Return (threshold - magnitude)\n    # When magnitude &gt; 200, this becomes negative \u2192 event triggers\n    return 200.0 - max_magnitude\n</code></pre> <p>Event Function Behavior</p> <p>The event triggers when the returned value crosses zero from positive to negative. Design your function accordingly:</p> <pre><code>- `threshold - magnitude`: triggers when magnitude exceeds threshold\n- `magnitude - threshold`: triggers when magnitude falls below threshold\n</code></pre>"},{"location":"guides/unbounded-trajectories/#benefits","title":"Benefits","text":"<p>\u2705 Performance: Only unbounded trajectories stop early \u2705 Accuracy: Bounded trajectories integrate to full completion \u2705 Simplicity: Clean, declarative API \u2705 Flexibility: Custom event functions for any stopping condition</p>"},{"location":"guides/unbounded-trajectories/#alternative-approach-zero-masking-with-torchdiffeq","title":"Alternative Approach: Zero Masking with TorchDiffEq","text":"<p>An alternative approach uses zero masking where derivatives are set to zero once a stopping condition is met. This \"freezes\" the solution at the threshold value.</p> <p>Performance Considerations</p> <p>This approach is slower than JaxSolver with events because:</p> <pre><code>- All trajectories integrate for the full time span (no early stopping)\n- The solver continues stepping even though derivatives are zero\n- Better suited for systems where most trajectories are bounded\n</code></pre>"},{"location":"guides/unbounded-trajectories/#how-zero-masking-works","title":"How Zero Masking Works","text":"<p>The ODE system returns zero derivatives when a trajectory exceeds the threshold:</p> <pre><code>import torch\nfrom pybasin.ode_system import ODESystem\n\nclass LorenzODE(ODESystem):\n    def ode(self, t: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Compute Lorenz dynamics with zero masking for unbounded trajectories.\n        \"\"\"\n        # Compute standard Lorenz dynamics\n        sigma = self.params[\"sigma\"]\n        r = self.params[\"r\"]\n        b = self.params[\"b\"]\n\n        x, y_coord, z = y[..., 0], y[..., 1], y[..., 2]\n\n        dx_dt = sigma * (y_coord - x)\n        dy_dt = r * x - x * z - y_coord\n        dz_dt = x * y_coord - b * z\n\n        dydt = torch.stack([dx_dt, dy_dt, dz_dt], dim=-1)\n\n        # Create mask: 1 if |y| &lt; 200, otherwise 0\n        mask = (torch.max(torch.abs(y), dim=-1)[0] &lt; 200).float().unsqueeze(-1)\n\n        # Return masked derivatives (zeros for unbounded trajectories)\n        return dydt * mask\n</code></pre>"},{"location":"guides/unbounded-trajectories/#key-points","title":"Key Points","text":"<ul> <li>Freezing behavior: When <code>|y| \u2265 200</code>, derivatives become zero, \"freezing\" the solution</li> <li>No early termination: Integration continues for the full time span</li> <li>Post-processing: Feature extraction must detect frozen trajectories by checking final magnitude</li> </ul>"},{"location":"guides/unbounded-trajectories/#using-with-torchdiffeqsolver","title":"Using with TorchDiffEqSolver","text":"<pre><code>from pybasin.solvers.torchdiffeq_solver import TorchDiffEqSolver\n\nsolver = TorchDiffEqSolver(\n    device=device,\n    t_span=(0.0, 1000.0),\n    method=\"dopri5\",\n    rtol=1e-8,\n    atol=1e-6,\n)\n\n# Use with LorenzODE that has zero masking\nbse = BasinStabilityEstimator(\n    n=n,\n    ode_system=LorenzODE(params),  # Has zero masking in ode()\n    sampler=sampler,\n    solver=solver,\n)\n</code></pre>"},{"location":"guides/unbounded-trajectories/#limitations-of-torchdiffeq-event-handling","title":"Limitations of TorchDiffEq Event Handling","text":"<p>TorchDiffEq Limitation</p> <p><code>torchdiffeq.odeint_event()</code> does not support individual trajectory termination. When the event condition is met for any trajectory in a batch, all integrations stop simultaneously.</p> <pre><code>This makes `odeint_event` unsuitable for basin stability estimation where different trajectories should stop at different times.\n</code></pre>"},{"location":"guides/unbounded-trajectories/#comparison","title":"Comparison","text":"Feature JaxSolver + Event TorchDiffEq + Zero Mask Individual termination \u2705 Yes \u274c No (zero masking workaround) Performance \u2705 Fast (early stopping) \u26a0\ufe0f Slower (full integration) Setup complexity \ud83d\udfe2 Simple (event function) \ud83d\udfe2 Simple (mask in ODE) GPU support \u2705 Yes \u2705 Yes Batch processing \u2705 Efficient \u26a0\ufe0f Less efficient Best for Most use cases Systems with few unbounded trajectories"},{"location":"guides/unbounded-trajectories/#best-practices","title":"Best Practices","text":""},{"location":"guides/unbounded-trajectories/#1-choose-the-right-threshold","title":"1. Choose the Right Threshold","text":"<p>Set your stopping threshold based on your system's dynamics:</p> <pre><code># Too low: May incorrectly classify bounded trajectories\nthreshold = 10.0  # \u274c May catch transient behavior\n\n# Good: Well above bounded attractor magnitudes\nthreshold = 200.0  # \u2705 Clear separation\n\n# Check your attractors first:\n# - Bounded attractors: |y| &lt; 50\n# - Set threshold at 4\u00d7 max bounded value\n</code></pre>"},{"location":"guides/unbounded-trajectories/#2-verify-event-triggering","title":"2. Verify Event Triggering","text":"<p>Test your event function with known unbounded initial conditions:</p> <pre><code>def test_event_function():\n    \"\"\"Verify event triggers for unbounded IC.\"\"\"\n    unbounded_ic = torch.tensor([10.0, 50.0, 0.0])\n\n    solution = solver.solve(\n        ode_system=ode_system,\n        initial_conditions=unbounded_ic,\n    )\n\n    # Check if integration stopped early\n    assert solution.t[-1] &lt; t_final, \"Event should trigger before t_final\"\n    assert torch.max(torch.abs(solution.y[-1])) &gt;= threshold\n</code></pre>"},{"location":"guides/unbounded-trajectories/#3-handle-classification-correctly","title":"3. Handle Classification Correctly","text":"<p>Ensure your feature extractor identifies unbounded trajectories:</p> <pre><code>def extract_features(solution):\n    \"\"\"Extract features, handling unbounded trajectories.\"\"\"\n    max_magnitude = torch.max(torch.abs(solution.y), dim=0)[0]\n\n    if max_magnitude &gt;= 200.0:\n        # Unbounded trajectory\n        return torch.tensor([0.0, 0.0])  # Special marker\n    else:\n        # Bounded trajectory - extract features from attractor\n        tail = solution.y[-100:]  # Last 100 points\n        mean_x = torch.mean(tail[:, 0])\n\n        if mean_x &gt; 0:\n            return torch.tensor([1.0, 0.0])  # Attractor 1\n        else:\n            return torch.tensor([0.0, 1.0])  # Attractor 2\n</code></pre>"},{"location":"guides/unbounded-trajectories/#summary","title":"Summary","text":"<ul> <li>Recommended: Use <code>JaxSolver</code> with event functions for efficient, individual trajectory termination</li> <li>Alternative: Use zero masking with <code>TorchDiffEqSolver</code> if you need PyTorch-only solution</li> <li>Avoid: Using <code>odeint_event()</code> for basin stability (stops all trajectories simultaneously)</li> <li>Test: Always verify your event function or masking logic with known unbounded cases</li> </ul> <p>For more examples, see the Lorenz case study.</p>"},{"location":"user-guide/adaptive-studies/","title":"Adaptive Parameter Studies","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/adaptive-studies/#use-case","title":"Use Case","text":"<p>Study how basin stability changes with a system parameter using <code>BasinStabilityStudy</code>.</p>"},{"location":"user-guide/adaptive-studies/#the-basinstabilitystudy-class","title":"The <code>BasinStabilityStudy</code> Class","text":"<p>Runs BSE multiple times for different parameter values, returning parameter values, BS values, and full results per run.</p>"},{"location":"user-guide/adaptive-studies/#example-pendulum-damping-study","title":"Example: Pendulum Damping Study","text":"<pre><code>import numpy as np\nfrom pybasin.basin_stability_study import BasinStabilityStudy\nfrom pybasin.study_params import SweepStudyParams\n\nstudy_params = SweepStudyParams(\n    name='ode_system.params[\"gamma\"]',\n    values=np.linspace(0.1, 0.5, 10),\n)\n\nas_bse = BasinStabilityStudy(\n    n=10_000,\n    ode_system=pendulum_ode,\n    sampler=sampler,\n    solver=solver,\n    feature_extractor=feature_extractor,\n    cluster_classifier=predictor,\n    study_params=study_params,\n)\nlabels, bs_vals, results = as_bse.estimate_as_bs()\n</code></pre>"},{"location":"user-guide/adaptive-studies/#visualization-with-asplotter","title":"Visualization with <code>ASPlotter</code>","text":"<p>Use the <code>ASPlotter</code> class to create parameter vs BS bifurcation diagrams.</p>"},{"location":"user-guide/bse-overview/","title":"Basin Stability Estimator Overview","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/bse-overview/#what-is-basin-stability","title":"What is Basin Stability?","text":"<p>Basin stability is a nonlinear measure of stability that quantifies the probability that a system returns to a given attractor when perturbed with random initial conditions.</p>"},{"location":"user-guide/bse-overview/#the-basinstabilityestimator-class","title":"The <code>BasinStabilityEstimator</code> Class","text":"<p>The <code>BasinStabilityEstimator</code> is the core class for computing basin stability values.</p>"},{"location":"user-guide/bse-overview/#constructor-parameters","title":"Constructor Parameters","text":"Parameter Type Default Description <code>ode_system</code> <code>ODESystemProtocol</code> Required The dynamical system <code>sampler</code> <code>Sampler</code> Required Initial condition generator <code>n</code> <code>int</code> <code>10_000</code> Number of samples <code>solver</code> <code>SolverProtocol</code> Auto-detect ODE integrator <code>feature_extractor</code> <code>FeatureExtractor</code> <code>TorchFeatureExtractor</code> Feature computation <code>predictor</code> <code>LabelPredictor</code> <code>HDBSCANClusterer</code> Classification method <code>feature_selector</code> <code>BaseEstimator</code> <code>DefaultFeatureSelector</code> Feature filtering <code>detect_unbounded</code> <code>bool</code> <code>True</code> Stop diverging trajectories <code>save_to</code> <code>str</code> <code>None</code> Output directory"},{"location":"user-guide/bse-overview/#default-flow","title":"Default Flow","text":"<pre><code>Sample ICs \u2192 Integrate ODEs \u2192 Detect Unbounded \u2192 Extract Features\n\u2192 Filter Features \u2192 Cluster/Classify \u2192 Compute BS Values\n</code></pre>"},{"location":"user-guide/bse-overview/#automatic-solver-selection","title":"Automatic Solver Selection","text":"<ul> <li>If <code>ode_system</code> is <code>JaxODESystem</code> \u2192 uses <code>JaxSolver</code></li> <li>If <code>ode_system</code> is <code>ODESystem</code> \u2192 uses <code>TorchDiffEqSolver</code></li> </ul>"},{"location":"user-guide/bse-overview/#unboundedness-detection","title":"Unboundedness Detection","text":"<p>Only active when <code>detect_unbounded=True</code> AND solver is <code>JaxSolver</code> with <code>event_fn</code>.</p> <p>See Handling Unbounded Trajectories for details.</p>"},{"location":"user-guide/bse-overview/#output-attributes","title":"Output Attributes","text":"<ul> <li><code>bse.bs_vals</code>: Dict of basin stability values per class</li> <li><code>bse.y0</code>: Initial conditions tensor</li> <li><code>bse.solution</code>: Solution object with trajectories, features, labels</li> </ul>"},{"location":"user-guide/feature-extractors/","title":"Feature Extractors","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/feature-extractors/#overview","title":"Overview","text":"<p>Feature extractors compute time-series characteristics from trajectories that distinguish different attractor types.</p>"},{"location":"user-guide/feature-extractors/#base-class","title":"Base Class","text":"<p>All extractors inherit from <code>FeatureExtractor</code> and implement:</p> <ul> <li>Method: <code>extract_features(solution: Solution) -&gt; torch.Tensor</code></li> <li>Property: <code>feature_names</code></li> </ul>"},{"location":"user-guide/feature-extractors/#available-extractors","title":"Available Extractors","text":"Class Features GPU Speed Use Case <code>TorchFeatureExtractor</code> ~700 \u2705 Fast Default <code>JaxFeatureExtractor</code> ~50 \u2705 Fastest JAX-only workflows <code>TsFreshFeatureExtractor</code> ~700 \u274c Slow Reference/validation <code>NoldsFeatureExtractor</code> ~10 \u274c Slow Dynamical features only"},{"location":"user-guide/feature-extractors/#torchfeatureextractor-default","title":"TorchFeatureExtractor (Default)","text":"<pre><code>from pybasin.feature_extractors import TorchFeatureExtractor\n\nextractor = TorchFeatureExtractor(\n    fc_parameters=\"minimal\",  # or \"comprehensive\", custom dict\n    time_steady=800.0,  # Discard transient\n    device=\"cuda\",\n)\n</code></pre>"},{"location":"user-guide/feature-extractors/#creating-custom-feature-extractors","title":"Creating Custom Feature Extractors","text":"<p>See the Custom Feature Extractor guide.</p>"},{"location":"user-guide/feature-selectors/","title":"Feature Selectors","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/feature-selectors/#overview","title":"Overview","text":"<p>Feature selectors filter features before classification to remove constant, low-variance, or correlated features.</p>"},{"location":"user-guide/feature-selectors/#default-behavior","title":"Default Behavior","text":"<p><code>DefaultFeatureSelector</code> removes features with zero variance.</p>"},{"location":"user-guide/feature-selectors/#using-sklearn-transformers","title":"Using sklearn Transformers","text":"<pre><code>from sklearn.feature_selection import VarianceThreshold\n\nbse = BasinStabilityEstimator(\n    ...,\n    feature_selector=VarianceThreshold(threshold=0.01),\n)\n</code></pre>"},{"location":"user-guide/feature-selectors/#correlationselector","title":"CorrelationSelector","text":"<pre><code>from pybasin.feature_selector.correlation_selector import CorrelationSelector\n\nselector = CorrelationSelector(threshold=0.95)\n</code></pre>"},{"location":"user-guide/feature-selectors/#disabling-feature-selection","title":"Disabling Feature Selection","text":"<pre><code>bse = BasinStabilityEstimator(..., feature_selector=None)\n</code></pre>"},{"location":"user-guide/plotters/","title":"Plotters","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/plotters/#overview","title":"Overview","text":"<p>Plotters visualize basin stability results.</p>"},{"location":"user-guide/plotters/#available-plotters","title":"Available Plotters","text":"Class Type Use Case <code>MatplotlibPlotter</code> Static Publication figures, quick inspection <code>InteractivePlotter</code> Web app Exploration, presentations <code>ASPlotter</code> Static Parameter study bifurcation diagrams"},{"location":"user-guide/plotters/#matplotlibplotter","title":"MatplotlibPlotter","text":"<pre><code>from pybasin.plotters.matplotlib_plotter import MatplotlibPlotter\n\nplotter = MatplotlibPlotter(bse)\nplotter.plot_bse_results()      # 4-panel diagnostic plot\nplotter.plot_phase(x_var=0, y_var=1)  # Phase space\nplotter.plot_templates(plotted_var=0) # Template time series\n</code></pre>"},{"location":"user-guide/plotters/#interactiveplotter","title":"InteractivePlotter","text":"<pre><code>from pybasin.plotters.interactive_plotter import InteractivePlotter\n\nplotter = InteractivePlotter(\n    bse,\n    state_labels={0: \"\u03b8\", 1: \"\u03c9\"},\n)\nplotter.run(port=8050)  # Opens web browser\n</code></pre>"},{"location":"user-guide/plotters/#asplotter","title":"ASPlotter","text":"<p>Used for visualizing parameter study results from <code>BasinStabilityStudy</code>.</p>"},{"location":"user-guide/predictors/","title":"Predictors","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/predictors/#overview","title":"Overview","text":"<p>Predictors classify trajectories into attractor classes based on extracted features.</p>"},{"location":"user-guide/predictors/#predictor-types","title":"Predictor Types","text":"<ul> <li>Unsupervised (<code>ClustererPredictor</code>): Discovers attractor classes automatically</li> <li>Supervised (<code>ClassifierPredictor</code>): Uses known template trajectories</li> </ul>"},{"location":"user-guide/predictors/#available-predictors","title":"Available Predictors","text":"Class Type Description <code>HDBSCANClusterer</code> Unsupervised Default, density-based, auto-tunes parameters <code>DBSCANClusterer</code> Unsupervised Classic DBSCAN <code>DynamicalClusterer</code> Unsupervised Physics-based two-stage clustering <code>KNNClassifier</code> Supervised K-nearest neighbors with templates <code>UnboundednessClusterer</code> Hybrid Detects unbounded trajectories"},{"location":"user-guide/predictors/#hdbscanclusterer-default","title":"HDBSCANClusterer (Default)","text":"<pre><code>from pybasin.predictors.hdbscan_clusterer import HDBSCANClusterer\n\npredictor = HDBSCANClusterer(\n    auto_tune=True,      # Auto-select min_cluster_size\n    assign_noise=True,   # Assign noise points to nearest cluster\n    min_cluster_size=50, # If auto_tune=False\n)\n</code></pre>"},{"location":"user-guide/predictors/#knnclassifier-supervised","title":"KNNClassifier (Supervised)","text":"<pre><code>from pybasin.predictors.knn_classifier import KNNClassifier\n\npredictor = KNNClassifier(\n    template_y0=[[0.0, 0.0], [1.0, 0.0]],  # Template ICs\n    labels=[\"FP\", \"LC\"],\n    k=5,\n)\n</code></pre>"},{"location":"user-guide/samplers/","title":"Samplers","text":"<p>Samplers generate initial conditions for basin stability estimation. All samplers return PyTorch tensors (<code>float32</code>) and support GPU acceleration.</p> <p>Tensor Precision</p> <p>All samplers use <code>float32</code> precision for GPU efficiency (5-10x faster than <code>float64</code>). Samples are returned as <code>torch.Tensor</code> on the configured device.</p>"},{"location":"user-guide/samplers/#available-samplers","title":"Available Samplers","text":"Class Description Returns Exact N? Deterministic? <code>UniformRandomSampler</code> Uniform random in hypercube \u2713 With seed <code>GridSampler</code> Evenly spaced regular grid \u2717 (scales up) \u2713 <code>GaussianSampler</code> Gaussian around midpoint \u2713 \u2717 <code>CsvSampler</code> Load from CSV file \u2713 \u2713"},{"location":"user-guide/samplers/#common-parameters","title":"Common Parameters","text":"<p>All samplers share these constructor parameters:</p> Parameter Type Description <code>min_limits</code> <code>list[float]</code> Minimum value for each state dimension <code>max_limits</code> <code>list[float]</code> Maximum value for each state dimension <code>device</code> <code>str</code> or <code>None</code> <code>\"cuda\"</code>, <code>\"cpu\"</code>, or <code>None</code> for auto-detect"},{"location":"user-guide/samplers/#fixed-dimensions","title":"Fixed Dimensions","text":"<p>To fix a state variable to a constant value (e.g., initial velocity = 0), set the same value for both <code>min</code> and <code>max</code> in that dimension. All samplers handle this correctly:</p> <pre><code># 3D state space (x, y, z) with z fixed at 0\nsampler = UniformRandomSampler(\n    min_limits=[-10.0, -20.0, 0.0],\n    max_limits=[10.0, 20.0, 0.0],  # z is fixed at 0\n)\n</code></pre> <p>CsvSampler Exception</p> <p><code>CsvSampler</code> does not accept <code>min_limits</code>/<code>max_limits</code>\u2014bounds are computed from the CSV data.</p>"},{"location":"user-guide/samplers/#uniformrandomsampler","title":"UniformRandomSampler","text":"<p>Generates random samples uniformly distributed within the bounding hypercube.</p> <pre><code>from pybasin.sampler import UniformRandomSampler\nimport numpy as np\n\nsampler = UniformRandomSampler(\n    min_limits=[-np.pi, -2.0],\n    max_limits=[np.pi, 2.0],\n    device=\"cuda\",  # optional, auto-detects GPU\n)\n\n# Generate 10,000 samples (returns exactly 10,000)\nsamples = sampler.sample(n=10000)\n\n# Use a different seed for different random samples\nsamples = sampler.sample(n=10000, seed=42)\n\n# Disable seeding for non-reproducible randomness\nsamples = sampler.sample(n=10000, seed=None)\n</code></pre> <p>Default Seed</p> <p>The default seed is <code>299792458</code> (speed of light in m/s). This ensures reproducible results by default.</p>"},{"location":"user-guide/samplers/#gridsampler","title":"GridSampler","text":"<p>Generates evenly spaced samples in a regular grid pattern. Ideal for 2D visualizations and deterministic sampling.</p> <pre><code>from pybasin.sampler import GridSampler\nimport numpy as np\n\nsampler = GridSampler(\n    min_limits=[-np.pi, -2.0],\n    max_limits=[np.pi, 2.0],\n)\n\nsamples = sampler.sample(n=10000)  # Returns 10,000 samples (100\u00d7100 grid)\n</code></pre>"},{"location":"user-guide/samplers/#sample-count-scaling","title":"Sample Count Scaling","text":"<p>The grid sampler rounds up the requested sample count to form a complete grid. For a d-dimensional space, it computes:</p> \\[n_{\\text{per dim}} = \\lceil n^{1/d} \\rceil\\] <p>The actual number of samples returned is \\(n_{\\text{per dim}}^d\\).</p> <p>2D Examples:</p> Requested N Points per Dimension Actual Samples 50 \u230850^0.5\u2309 = 8 8\u00b2 = 64 100 \u2308100^0.5\u2309 = 10 10\u00b2 = 100 1,000 \u23081000^0.5\u2309 = 32 32\u00b2 = 1,024 20,000 \u230820000^0.5\u2309 = 142 142\u00b2 = 20,164"},{"location":"user-guide/samplers/#fixed-dimensions-and-sample-count","title":"Fixed Dimensions and Sample Count","text":"<p>When using fixed dimensions (see Fixed Dimensions), only the varying dimensions contribute to the grid calculation.</p> <p>Given \\(d\\) varying dimensions and requested \\(n\\) samples, the points per varying dimension is \\(\\lceil n^{1/d} \\rceil\\). Fixed dimensions always contribute exactly 1 point, so the total number of samples is:</p> \\[\\text{total} = \\underbrace{\\lceil n^{1/d} \\rceil \\times \\lceil n^{1/d} \\rceil \\times \\cdots}_{d \\text{ varying dims}} \\times \\underbrace{1 \\times 1 \\times \\cdots}_{\\text{fixed dims}} = (\\lceil n^{1/d} \\rceil)^d\\] <p>Example: 3D space with 1 fixed dimension and \\(n = 20000\\):</p> <ul> <li>\\(d = 2\\) varying dimensions \u2192 \\(20000^{1/2} = 141.42...\\), so \\(\\lceil 141.42 \\rceil = 142\\) points per dimension</li> <li>Total: \\(142 \\times 142 \\times 1 = 20164\\) samples</li> </ul>"},{"location":"user-guide/samplers/#gaussiansampler","title":"GaussianSampler","text":"<p>Generates samples from a Gaussian distribution centered at the midpoint of each dimension. Samples are clamped to stay within bounds.</p> <pre><code>from pybasin.sampler import GaussianSampler\n\nsampler = GaussianSampler(\n    min_limits=[-np.pi, -2.0],\n    max_limits=[np.pi, 2.0],\n    std_factor=0.2,  # \u03c3 = 20% of the range (default)\n)\n\nsamples = sampler.sample(n=10000)\n</code></pre> <p>The distribution parameters are computed as:</p> \\[\\mu_i = \\frac{\\text{min}_i + \\text{max}_i}{2}, \\quad \\sigma_i = \\text{std_factor} \\times (\\text{max}_i - \\text{min}_i)\\]"},{"location":"user-guide/samplers/#csvsampler","title":"CsvSampler","text":"<p>Loads pre-defined samples from a CSV file. Essential for reproducing results from MATLAB or other reference implementations.</p>"},{"location":"user-guide/samplers/#constructor-parameters","title":"Constructor Parameters","text":"Parameter Type Default Description <code>csv_path</code> <code>str</code> or <code>Path</code> Required Path to the CSV file containing samples <code>coordinate_columns</code> <code>list[str]</code> Required Column names to use as state coordinates <code>label_column</code> <code>str</code> or <code>None</code> <code>None</code> Column name for ground truth labels <code>device</code> <code>str</code> or <code>None</code> <code>None</code> <code>\"cuda\"</code>, <code>\"cpu\"</code>, or <code>None</code> for auto-detect <pre><code>from pybasin.sampler import CsvSampler\n\nsampler = CsvSampler(\n    csv_path=\"data/initial_conditions.csv\",\n    coordinate_columns=[\"x1\", \"x2\"],      # Column names for state variables\n    label_column=\"attractor\",             # Optional: ground truth labels\n    device=\"cuda\",                        # Optional: auto-detects GPU if None\n)\n\n# Get all samples from the file\nsamples = sampler.sample()\n\n# Or get the first n samples\nsamples = sampler.sample(n=1000)\n\n# Access ground truth labels (if provided)\nlabels = sampler.labels  # numpy array or None\n</code></pre> <p>Bounds Auto-Detection</p> <p>Unlike other samplers, <code>CsvSampler</code> does not require <code>min_limits</code> and <code>max_limits</code>. These are automatically computed from the data in the CSV file.</p>"},{"location":"user-guide/samplers/#exceptions","title":"Exceptions","text":"Exception Condition <code>FileNotFoundError</code> CSV file does not exist at the specified path <code>ValueError</code> Coordinate columns not found in CSV <code>ValueError</code> Label column not found in CSV (when specified) <code>ValueError</code> Requested <code>n</code> samples exceeds available data"},{"location":"user-guide/samplers/#properties","title":"Properties","text":"Property Type Description <code>labels</code> <code>np.ndarray</code> or <code>None</code> Ground truth labels from CSV <code>n_samples</code> <code>int</code> Total number of samples in the file"},{"location":"user-guide/samplers/#creating-custom-samplers","title":"Creating Custom Samplers","text":"<p>Inherit from <code>Sampler</code> and implement the <code>sample</code> method:</p> <pre><code>from pybasin.sampler import Sampler\nimport torch\n\nclass LatinHypercubeSampler(Sampler):\n    \"\"\"Latin Hypercube sampling for better space coverage.\"\"\"\n\n    display_name: str = \"Latin Hypercube Sampler\"\n\n    def __init__(\n        self,\n        min_limits: list[float],\n        max_limits: list[float],\n        device: str | None = None,\n    ):\n        super().__init__(min_limits, max_limits, device)\n\n    def sample(self, n: int) -&gt; torch.Tensor:\n        # Your implementation here\n        # Must return tensor of shape (n, self.state_dim)\n        ...\n</code></pre>"},{"location":"user-guide/samplers/#base-class-attributes","title":"Base Class Attributes","text":"<p>After calling <code>super().__init__()</code>, these attributes are available:</p> Attribute Type Description <code>device</code> <code>torch.device</code> Target device (<code>cuda:0</code> or <code>cpu</code>) <code>min_limits</code> <code>torch.Tensor</code> Minimum bounds as <code>float32</code> tensor on <code>device</code> <code>max_limits</code> <code>torch.Tensor</code> Maximum bounds as <code>float32</code> tensor on <code>device</code> <code>state_dim</code> <code>int</code> Number of state dimensions (length of limits)"},{"location":"user-guide/samplers/#requirements","title":"Requirements","text":"<ol> <li>Call <code>super().__init__()</code> with <code>min_limits</code>, <code>max_limits</code>, and <code>device</code></li> <li>Return a <code>torch.Tensor</code> of shape <code>(n, self.state_dim)</code></li> <li>Use <code>self.device</code> when creating tensors to ensure GPU compatibility</li> <li>Use <code>float32</code> dtype for consistency with the base class</li> </ol>"},{"location":"user-guide/solvers/","title":"Solvers","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/solvers/#overview","title":"Overview","text":"<p>Solvers integrate the ODE system from initial conditions.</p>"},{"location":"user-guide/solvers/#solver-protocol","title":"Solver Protocol","text":"<p>All solvers implement:</p> <ul> <li>Method: <code>integrate(ode_system, initial_conditions) -&gt; (t, y)</code></li> <li>Property: <code>device</code></li> </ul>"},{"location":"user-guide/solvers/#available-solvers","title":"Available Solvers","text":"Class Backend GPU Support Event Functions Recommended For <code>JaxSolver</code> JAX/Diffrax \u2705 CUDA \u2705 Yes Default for performance <code>TorchDiffEqSolver</code> torchdiffeq \u2705 CUDA \u274c Batch limitation PyTorch ecosystems <code>TorchOdeSolver</code> torchode \u2705 CUDA \u274c No Alternative PyTorch <code>SklearnParallelSolver</code> scipy/sklearn \u274c CPU only \u274c No Debugging, reference"},{"location":"user-guide/solvers/#jaxsolver-recommended","title":"JaxSolver (Recommended)","text":"<pre><code>from pybasin.solvers.jax_solver import JaxSolver\n\nsolver = JaxSolver(\n    device=\"cuda\",\n    t_span=(0.0, 1000.0),\n    n_steps=1000,\n    method=\"Dopri5\",  # or \"Tsit5\"\n    rtol=1e-8,\n    atol=1e-6,\n    event_fn=my_stop_event,  # Optional: stop unbounded\n)\n</code></pre>"},{"location":"user-guide/solvers/#event-functions-for-unbounded-detection","title":"Event Functions for Unbounded Detection","text":"<pre><code>import jax.numpy as jnp\n\ndef stop_event(t, y, args):\n    \"\"\"Stop when |y| &gt; 200.\"\"\"\n    return 200.0 - jnp.max(jnp.abs(y))\n</code></pre>"},{"location":"user-guide/solvers/#torchdiffeqsolver","title":"TorchDiffEqSolver","text":"<pre><code>from pybasin.solver import TorchDiffEqSolver\n\nsolver = TorchDiffEqSolver(\n    device=\"cuda\",\n    t_span=(0.0, 1000.0),\n    method=\"dopri5\",\n)\n</code></pre>"},{"location":"user-guide/solvers/#performance-comparison","title":"Performance Comparison","text":"<p>See the Solver Comparison benchmark for detailed performance data.</p>"}]}