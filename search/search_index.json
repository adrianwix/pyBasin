{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pyBasin","text":"<p>Basin stability estimation for dynamical systems</p> <p> </p> <p>pyBasin is a Python library for estimating basin stability in dynamical systems. It's a port of the MATLAB bSTAB library with additional features including adaptive sampling and neural network-based classification.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Basin Stability Estimation: Calculate the probability that a system ends up in a specific attractor</li> <li>Adaptive Sampling: Intelligent sampling strategies that focus on uncertain regions</li> <li>Multiple Solvers: Support for various ODE solvers including neural ODE</li> <li>Visualization Tools: Built-in plotting utilities for basin stability results</li> <li>Extensible: Easy to add custom feature extractors and classifiers</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install pybasin\n</code></pre> <p>For development:</p> <pre><code># Clone the repository\ngit clone https://github.com/adrianwix/pyBSTAB.git\ncd pyBasinWorkspace\n\n# Install with UV\nuv add -e \".[dev,docs]\"\n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>from pybasin import BasinStabilityEstimator, ODESystem\nimport numpy as np\n\n# Define your dynamical system\nclass MySystem(ODESystem):\n    def dynamics(self, t, state):\n        x, y = state\n        dx = -x + y\n        dy = -y - x**3\n        return np.array([dx, dy])\n\n    def classify_attractor(self, solution):\n        # Classify final state\n        final_state = solution.y[:, -1]\n        if np.linalg.norm(final_state) &lt; 0.1:\n            return 0  # Attractor 1\n        return 1  # Attractor 2\n\n# Create estimator\nsystem = MySystem()\nestimator = BasinStabilityEstimator(system)\n\n# Define sampling region\nbounds = [(-2, 2), (-2, 2)]  # x and y bounds\n\n# Estimate basin stability\nresults = estimator.estimate(bounds, n_samples=1000)\n\nprint(f\"Basin stability: {results.basin_stability}\")\nprint(f\"Attractor distribution: {results.attractor_counts}\")\n</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>Full documentation is available at https://adrianwix.github.io/pyBSTAB/</p>"},{"location":"#case-studies","title":"Case Studies","text":"<p>This repository includes several case studies from the original bSTAB paper:</p> <ul> <li>Duffing Oscillator: Forced oscillator with two attractors</li> <li>Lorenz System: Classic chaotic system</li> <li>Pendulum: Forced pendulum with bifurcations</li> <li>Friction System: System with friction effects</li> </ul> <p>See the <code>case_studies/</code> directory for implementations.</p>"},{"location":"#project-structure","title":"Project Structure","text":"<pre><code>pyBasinWorkspace/\n\u251c\u2500\u2500 src/pybasin/          # Main library code\n\u251c\u2500\u2500 case_studies/         # Research case studies\n\u251c\u2500\u2500 tests/                # Unit and integration tests\n\u251c\u2500\u2500 docs/                 # Documentation source\n\u251c\u2500\u2500 artifacts/            # Generated figures and results\n\u2514\u2500\u2500 notebooks/            # Jupyter notebook examples\n</code></pre>"},{"location":"#development","title":"Development","text":""},{"location":"#setup","title":"Setup","text":"<pre><code># Install all dependencies including dev tools\nuv add -e \".[all]\"\n</code></pre>"},{"location":"#running-tests","title":"Running Tests","text":"<pre><code>pytest\n</code></pre>"},{"location":"#building-documentation","title":"Building Documentation","text":"<pre><code>mkdocs serve  # Local preview\nmkdocs build  # Build static site\n</code></pre>"},{"location":"#related-projects","title":"Related Projects","text":"<ul> <li>bSTAB: Original MATLAB implementation - GitHub</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use pyBasin in your research, please cite:</p> <pre><code>@software{pybasin2025,\n  author = {Wix, Adrian},\n  title = {pyBasin: Basin Stability Estimation for Dynamical Systems},\n  year = {2025},\n  url = {https://github.com/adrianwix/pyBSTAB}\n}\n</code></pre>"},{"location":"#license","title":"License","text":"<p>This project is licensed under the MIT License - see the LICENSE file for details.</p>"},{"location":"#acknowledgments","title":"Acknowledgments","text":"<ul> <li>Based on the bSTAB MATLAB library</li> <li>Part of a bachelor thesis on basin stability estimation</li> </ul>"},{"location":"macros/","title":"Macros","text":"In\u00a0[\u00a0]: Copied! <pre>\"\"\"MkDocs macros for case study documentation.\n\nThis module provides macros for rendering comparison tables from JSON artifacts\nand loading code snippets from source files.\n\"\"\"\n</pre> \"\"\"MkDocs macros for case study documentation.  This module provides macros for rendering comparison tables from JSON artifacts and loading code snippets from source files. \"\"\" <p>pyright: reportUnknownMemberType=false, reportUnknownArgumentType=false pyright: reportUnknownVariableType=false, reportMissingTypeArgument=false</p> In\u00a0[\u00a0]: Copied! <pre>import ast\nimport json\nfrom pathlib import Path\nfrom typing import Any\n</pre> import ast import json from pathlib import Path from typing import Any In\u00a0[\u00a0]: Copied! <pre>ARTIFACTS_DIR = Path(__file__).parent.parent / \"artifacts\" / \"results\"\n</pre> ARTIFACTS_DIR = Path(__file__).parent.parent / \"artifacts\" / \"results\" In\u00a0[\u00a0]: Copied! <pre>Z_THRESHOLD_OK = 2.0\nZ_THRESHOLD_WARNING = 3.0\n</pre> Z_THRESHOLD_OK = 2.0 Z_THRESHOLD_WARNING = 3.0 In\u00a0[\u00a0]: Copied! <pre>def _status_emoji(confidence: str) -&gt; str:\n    \"\"\"Get status emoji based on confidence level.\n\n    :param confidence: Confidence level string (\"very_high\", \"high\", \"moderate\", \"low\", \"very_low\").\n    :return: Status emoji.\n    \"\"\"\n    if confidence == \"very_high\":\n        return \"\u2705\"  # p &gt; 0.10 (very likely same)\n    elif confidence == \"high\":\n        return \"\u2705\"  # p &gt; 0.05 (no significant difference)\n    elif confidence == \"moderate\":\n        return \"\u26a0\ufe0f\"  # p &gt; 0.01 (borderline)\n    elif confidence == \"low\":\n        return \"\u274c\"  # p &gt; 0.001 (significant difference)\n    else:  # very_low\n        return \"\u274c\"  # p &lt;= 0.001 (highly significant difference)\n</pre> def _status_emoji(confidence: str) -&gt; str:     \"\"\"Get status emoji based on confidence level.      :param confidence: Confidence level string (\"very_high\", \"high\", \"moderate\", \"low\", \"very_low\").     :return: Status emoji.     \"\"\"     if confidence == \"very_high\":         return \"\u2705\"  # p &gt; 0.10 (very likely same)     elif confidence == \"high\":         return \"\u2705\"  # p &gt; 0.05 (no significant difference)     elif confidence == \"moderate\":         return \"\u26a0\ufe0f\"  # p &gt; 0.01 (borderline)     elif confidence == \"low\":         return \"\u274c\"  # p &gt; 0.001 (significant difference)     else:  # very_low         return \"\u274c\"  # p &lt;= 0.001 (highly significant difference) In\u00a0[\u00a0]: Copied! <pre>def _format_bs_with_se(bs: float, se: float) -&gt; str:\n    \"\"\"Format basin stability with standard error.\"\"\"\n    return f\"{bs:.4f} \u00b1 {se:.4f}\"\n</pre> def _format_bs_with_se(bs: float, se: float) -&gt; str:     \"\"\"Format basin stability with standard error.\"\"\"     return f\"{bs:.4f} \u00b1 {se:.4f}\" In\u00a0[\u00a0]: Copied! <pre>def _format_ci(ci_lower: float, ci_upper: float) -&gt; str:\n    \"\"\"Format confidence interval.\"\"\"\n    return f\"[{ci_lower:.4f}, {ci_upper:.4f}]\"\n</pre> def _format_ci(ci_lower: float, ci_upper: float) -&gt; str:     \"\"\"Format confidence interval.\"\"\"     return f\"[{ci_lower:.4f}, {ci_upper:.4f}]\" In\u00a0[\u00a0]: Copied! <pre>def comparison_table(case_id: str) -&gt; str:\n    \"\"\"Render a comparison table from a JSON artifact.\n\n    For single-point tests, renders a table with columns:\n    Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z-score | Status\n\n    For parameter sweep tests, adds a Parameter column first:\n    Parameter | Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z-score | Status\n\n    For unsupervised tests, adds cluster quality metrics and purity column:\n    Attractor | DBSCAN | Purity | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z-score | Status\n\n    :param case_id: Case identifier (e.g., \"pendulum_case1\", \"pendulum_case2\").\n    :return: Markdown table string.\n    \"\"\"\n    json_path = ARTIFACTS_DIR / f\"{case_id}_comparison.json\"\n\n    if not json_path.exists():\n        return f'!!! warning \"Missing Data\"\\n    Comparison data not found: `{case_id}_comparison.json`\\n    Run tests with `--generate-artifacts` to generate.'\n\n    with open(json_path) as f:\n        data: dict[str, Any] = json.load(f)\n\n    if \"parameter_results\" in data:\n        return _render_parameter_sweep_table(data)\n    if \"overall_agreement\" in data:\n        return _render_unsupervised_table(data)\n    return _render_single_point_table(data)\n</pre> def comparison_table(case_id: str) -&gt; str:     \"\"\"Render a comparison table from a JSON artifact.      For single-point tests, renders a table with columns:     Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z-score | Status      For parameter sweep tests, adds a Parameter column first:     Parameter | Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z-score | Status      For unsupervised tests, adds cluster quality metrics and purity column:     Attractor | DBSCAN | Purity | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z-score | Status      :param case_id: Case identifier (e.g., \"pendulum_case1\", \"pendulum_case2\").     :return: Markdown table string.     \"\"\"     json_path = ARTIFACTS_DIR / f\"{case_id}_comparison.json\"      if not json_path.exists():         return f'!!! warning \"Missing Data\"\\n    Comparison data not found: `{case_id}_comparison.json`\\n    Run tests with `--generate-artifacts` to generate.'      with open(json_path) as f:         data: dict[str, Any] = json.load(f)      if \"parameter_results\" in data:         return _render_parameter_sweep_table(data)     if \"overall_agreement\" in data:         return _render_unsupervised_table(data)     return _render_single_point_table(data) In\u00a0[\u00a0]: Copied! <pre>def _render_single_point_table(data: dict[str, Any]) -&gt; str:\n    \"\"\"Render table for single-point comparison.\"\"\"\n    attractors: list[dict[str, Any]] = data.get(\"attractors\", [])\n\n    if not attractors:\n        return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'\n\n    lines: list[str] = [\n        \"| Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z | p-value | 95% CI (diff) | Confidence |\",\n        \"|-----------|-----------------|---------------|---|---------|---------------|------------|\",\n    ]\n\n    for a in attractors:\n        python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])\n        matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])\n        z_score: float = a[\"z_score\"]\n        p_value: float = a[\"p_value\"]\n        ci_str = _format_ci(a[\"ci_lower\"], a[\"ci_upper\"])\n        confidence: str = a[\"confidence\"]\n        status = _status_emoji(confidence)\n\n        lines.append(\n            f\"| {a['label']} | {python_str} | {matlab_str} | {z_score:.2f} | {p_value:.4f} | {ci_str} | {status}&amp;nbsp;{confidence} |\"\n        )\n\n    return \"\\n\".join(lines)\n</pre> def _render_single_point_table(data: dict[str, Any]) -&gt; str:     \"\"\"Render table for single-point comparison.\"\"\"     attractors: list[dict[str, Any]] = data.get(\"attractors\", [])      if not attractors:         return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'      lines: list[str] = [         \"| Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z | p-value | 95% CI (diff) | Confidence |\",         \"|-----------|-----------------|---------------|---|---------|---------------|------------|\",     ]      for a in attractors:         python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])         matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])         z_score: float = a[\"z_score\"]         p_value: float = a[\"p_value\"]         ci_str = _format_ci(a[\"ci_lower\"], a[\"ci_upper\"])         confidence: str = a[\"confidence\"]         status = _status_emoji(confidence)          lines.append(             f\"| {a['label']} | {python_str} | {matlab_str} | {z_score:.2f} | {p_value:.4f} | {ci_str} | {status}\u00a0{confidence} |\"         )      return \"\\n\".join(lines) In\u00a0[\u00a0]: Copied! <pre>def _render_unsupervised_table(data: dict[str, Any]) -&gt; str:\n    \"\"\"Render table for unsupervised clustering comparison.\"\"\"\n    attractors: list[dict[str, Any]] = data.get(\"attractors\", [])\n\n    if not attractors:\n        return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'\n\n    # Cluster quality metrics summary\n    n_found = data.get(\"n_clusters_found\", 0)\n    n_expected = data.get(\"n_clusters_expected\", 0)\n    agreement = data.get(\"overall_agreement\", 0.0)\n    ari = data.get(\"adjusted_rand_index\", 0.0)\n\n    summary_lines: list[str] = [\n        \"**Cluster Quality Metrics:**\",\n        \"\",\n        f\"- Clusters found: {n_found} (expected: {n_expected})\",\n        f\"- Overall agreement: {agreement:.1%}\",\n        f\"- Adjusted Rand Index: {ari:.4f}\",\n        \"\",\n    ]\n\n    # Attractor table with purity info\n    table_lines: list[str] = [\n        \"| Attractor | DBSCAN | Purity | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z | p-value | Confidence |\",\n        \"|-----------|--------|--------|-----------------|---------------|---|---------|------------|\",\n    ]\n\n    for a in attractors:\n        python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])\n        matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])\n        z_score: float = a[\"z_score\"]\n        p_value: float = a[\"p_value\"]\n        confidence: str = a[\"confidence\"]\n        status = _status_emoji(confidence)\n        dbscan_label = a.get(\"dbscan_label\", \"-\")\n        purity = a.get(\"purity\", 0.0)\n        purity_str = f\"{purity:.1%}\"\n\n        table_lines.append(\n            f\"| {a['label']} | {dbscan_label} | {purity_str} | {python_str} | {matlab_str} | {z_score:.2f} | {p_value:.4f} | {status}&amp;nbsp;{confidence} |\"\n        )\n\n    return \"\\n\".join(summary_lines + table_lines)\n</pre> def _render_unsupervised_table(data: dict[str, Any]) -&gt; str:     \"\"\"Render table for unsupervised clustering comparison.\"\"\"     attractors: list[dict[str, Any]] = data.get(\"attractors\", [])      if not attractors:         return '!!! warning \"No Data\"\\n    No attractor data found in comparison.'      # Cluster quality metrics summary     n_found = data.get(\"n_clusters_found\", 0)     n_expected = data.get(\"n_clusters_expected\", 0)     agreement = data.get(\"overall_agreement\", 0.0)     ari = data.get(\"adjusted_rand_index\", 0.0)      summary_lines: list[str] = [         \"**Cluster Quality Metrics:**\",         \"\",         f\"- Clusters found: {n_found} (expected: {n_expected})\",         f\"- Overall agreement: {agreement:.1%}\",         f\"- Adjusted Rand Index: {ari:.4f}\",         \"\",     ]      # Attractor table with purity info     table_lines: list[str] = [         \"| Attractor | DBSCAN | Purity | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z | p-value | Confidence |\",         \"|-----------|--------|--------|-----------------|---------------|---|---------|------------|\",     ]      for a in attractors:         python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])         matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])         z_score: float = a[\"z_score\"]         p_value: float = a[\"p_value\"]         confidence: str = a[\"confidence\"]         status = _status_emoji(confidence)         dbscan_label = a.get(\"dbscan_label\", \"-\")         purity = a.get(\"purity\", 0.0)         purity_str = f\"{purity:.1%}\"          table_lines.append(             f\"| {a['label']} | {dbscan_label} | {purity_str} | {python_str} | {matlab_str} | {z_score:.2f} | {p_value:.4f} | {status}\u00a0{confidence} |\"         )      return \"\\n\".join(summary_lines + table_lines) In\u00a0[\u00a0]: Copied! <pre>def _render_parameter_sweep_table(data: dict[str, Any]) -&gt; str:\n    \"\"\"Render table for parameter sweep comparison.\"\"\"\n    parameter_results: list[dict[str, Any]] = data.get(\"parameter_results\", [])\n\n    if not parameter_results:\n        return '!!! warning \"No Data\"\\n    No parameter data found in comparison.'\n\n    param_name: str = data.get(\"parameter_name\", \"Parameter\")\n    sections: list[str] = []\n\n    for result in parameter_results:\n        param_value: float | None = result.get(\"parameter_value\")\n        param_str = f\"{param_value:.4f}\" if param_value is not None else \"-\"\n\n        lines: list[str] = [\n            f\"#### {param_name} = {param_str}\",\n            \"\",\n            \"| Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z | p-value | 95% CI (diff) | Confidence |\",\n            \"|-----------|-----------------|---------------|---|---------|---------------|------------|\",\n        ]\n\n        attractors: list[dict[str, Any]] = result.get(\"attractors\", [])\n        for a in attractors:\n            python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])\n            matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])\n            z_score: float = a[\"z_score\"]\n            p_value: float = a[\"p_value\"]\n            ci_str = _format_ci(a[\"ci_lower\"], a[\"ci_upper\"])\n            confidence: str = a[\"confidence\"]\n            status = _status_emoji(confidence)\n\n            lines.append(\n                f\"| {a['label']} | {python_str} | {matlab_str} | {z_score:.2f} | {p_value:.4f} | {ci_str} | {status}&amp;nbsp;{confidence} |\"\n            )\n\n        sections.append(\"\\n\".join(lines))\n\n    return \"\\n\\n\".join(sections)\n</pre> def _render_parameter_sweep_table(data: dict[str, Any]) -&gt; str:     \"\"\"Render table for parameter sweep comparison.\"\"\"     parameter_results: list[dict[str, Any]] = data.get(\"parameter_results\", [])      if not parameter_results:         return '!!! warning \"No Data\"\\n    No parameter data found in comparison.'      param_name: str = data.get(\"parameter_name\", \"Parameter\")     sections: list[str] = []      for result in parameter_results:         param_value: float | None = result.get(\"parameter_value\")         param_str = f\"{param_value:.4f}\" if param_value is not None else \"-\"          lines: list[str] = [             f\"#### {param_name} = {param_str}\",             \"\",             \"| Attractor | pyBasin BS \u00b1 SE | bSTAB BS \u00b1 SE | z | p-value | 95% CI (diff) | Confidence |\",             \"|-----------|-----------------|---------------|---|---------|---------------|------------|\",         ]          attractors: list[dict[str, Any]] = result.get(\"attractors\", [])         for a in attractors:             python_str = _format_bs_with_se(a[\"python_bs\"], a[\"python_se\"])             matlab_str = _format_bs_with_se(a[\"matlab_bs\"], a[\"matlab_se\"])             z_score: float = a[\"z_score\"]             p_value: float = a[\"p_value\"]             ci_str = _format_ci(a[\"ci_lower\"], a[\"ci_upper\"])             confidence: str = a[\"confidence\"]             status = _status_emoji(confidence)              lines.append(                 f\"| {a['label']} | {python_str} | {matlab_str} | {z_score:.2f} | {p_value:.4f} | {ci_str} | {status}\u00a0{confidence} |\"             )          sections.append(\"\\n\".join(lines))      return \"\\n\\n\".join(sections) In\u00a0[\u00a0]: Copied! <pre>def load_snippet(spec: str) -&gt; str:\n    \"\"\"Load a code snippet from a source file.\n\n    :param spec: Specification in format \"path/to/file.py::function_name\"\n                 Path should be relative to the workspace root.\n    :return: Markdown-formatted code block with the extracted function.\n    \"\"\"\n    try:\n        file_path_str, func_name = spec.split(\"::\")\n    except ValueError:\n        return f'!!! error \"Invalid Format\"\\n    Expected format: `path/to/file.py::function_name`\\n    Got: `{spec}`'\n\n    workspace_root = Path(__file__).parent.parent\n    file_path = workspace_root / file_path_str\n\n    if not file_path.exists():\n        return f'!!! error \"File Not Found\"\\n    Could not find file: `{file_path_str}`'\n\n    try:\n        source_code = file_path.read_text()\n        tree = ast.parse(source_code)\n\n        for node in ast.walk(tree):\n            if isinstance(node, ast.FunctionDef) and node.name == func_name:\n                lines = source_code.splitlines()\n                start_line = node.lineno - 1\n                end_line = node.end_lineno if node.end_lineno else len(lines)\n\n                function_code = \"\\n\".join(lines[start_line:end_line])\n\n                return f\"```python\\n{function_code}\\n```\"\n\n        return f'!!! warning \"Function Not Found\"\\n    Could not find function `{func_name}` in `{file_path_str}`'\n\n    except SyntaxError as e:\n        return f'!!! error \"Syntax Error\"\\n    Failed to parse `{file_path_str}`: {e}'\n    except Exception as e:\n        return f'!!! error \"Error\"\\n    Failed to load snippet: {e}'\n</pre> def load_snippet(spec: str) -&gt; str:     \"\"\"Load a code snippet from a source file.      :param spec: Specification in format \"path/to/file.py::function_name\"                  Path should be relative to the workspace root.     :return: Markdown-formatted code block with the extracted function.     \"\"\"     try:         file_path_str, func_name = spec.split(\"::\")     except ValueError:         return f'!!! error \"Invalid Format\"\\n    Expected format: `path/to/file.py::function_name`\\n    Got: `{spec}`'      workspace_root = Path(__file__).parent.parent     file_path = workspace_root / file_path_str      if not file_path.exists():         return f'!!! error \"File Not Found\"\\n    Could not find file: `{file_path_str}`'      try:         source_code = file_path.read_text()         tree = ast.parse(source_code)          for node in ast.walk(tree):             if isinstance(node, ast.FunctionDef) and node.name == func_name:                 lines = source_code.splitlines()                 start_line = node.lineno - 1                 end_line = node.end_lineno if node.end_lineno else len(lines)                  function_code = \"\\n\".join(lines[start_line:end_line])                  return f\"```python\\n{function_code}\\n```\"          return f'!!! warning \"Function Not Found\"\\n    Could not find function `{func_name}` in `{file_path_str}`'      except SyntaxError as e:         return f'!!! error \"Syntax Error\"\\n    Failed to parse `{file_path_str}`: {e}'     except Exception as e:         return f'!!! error \"Error\"\\n    Failed to load snippet: {e}' In\u00a0[\u00a0]: Copied! <pre>def define_env(env: Any) -&gt; None:\n    \"\"\"Define macros for mkdocs-macros-plugin.\n\n    :param env: The macro environment.\n    \"\"\"\n    env.macro(comparison_table, \"comparison_table\")\n    env.macro(load_snippet, \"load_snippet\")\n</pre> def define_env(env: Any) -&gt; None:     \"\"\"Define macros for mkdocs-macros-plugin.      :param env: The macro environment.     \"\"\"     env.macro(comparison_table, \"comparison_table\")     env.macro(load_snippet, \"load_snippet\")"},{"location":"api/adaptive-sampling/","title":"ASBasinStabilityEstimator","text":""},{"location":"api/adaptive-sampling/#pybasin.as_basin_stability_estimator.ASBasinStabilityEstimator","title":"pybasin.as_basin_stability_estimator.ASBasinStabilityEstimator","text":"<p>Adaptive Study Basin Stability Estimator.</p>"},{"location":"api/adaptive-sampling/#pybasin.as_basin_stability_estimator.ASBasinStabilityEstimator-functions","title":"Functions","text":""},{"location":"api/adaptive-sampling/#pybasin.as_basin_stability_estimator.ASBasinStabilityEstimator.__init__","title":"__init__","text":"<pre><code>__init__(\n    n: int,\n    ode_system: ODESystemProtocol,\n    sampler: Sampler,\n    solver: SolverProtocol,\n    feature_extractor: FeatureExtractor,\n    cluster_classifier: LabelPredictor,\n    as_params: AdaptiveStudyParams,\n    save_to: str | None = \"results\",\n    verbose: bool = False,\n)\n</code></pre> <p>Initialize the Adaptive Study Basin Stability Estimator.</p> <p>Sets up the estimator for a parameter study where one parameter is systematically varied across multiple values. The parameter can be in any component (ODE system, sampler, solver, feature extractor, or predictor).</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of initial conditions (samples) to generate for each parameter value.</p> required <code>ode_system</code> <code>ODESystemProtocol</code> <p>The ODE system model (ODESystem or JaxODESystem).</p> required <code>sampler</code> <code>Sampler</code> <p>The Sampler object to generate initial conditions.</p> required <code>solver</code> <code>SolverProtocol</code> <p>The Solver object to integrate the ODE system (Solver or JaxSolver).</p> required <code>feature_extractor</code> <code>FeatureExtractor</code> <p>The FeatureExtractor object to extract features from trajectories.</p> required <code>cluster_classifier</code> <code>LabelPredictor</code> <p>The LabelPredictor object to assign attractor labels.</p> required <code>as_params</code> <code>AdaptiveStudyParams</code> <p>Dictionary specifying the parameter to vary and its values.</p> required <code>save_to</code> <code>str | None</code> <p>Folder path where results will be saved, or None to disable saving.</p> <code>'results'</code> <code>verbose</code> <code>bool</code> <p>If True, show detailed logs from BasinStabilityEstimator instances. If False, suppress INFO logs to reduce output clutter during parameter sweeps.</p> <code>False</code>"},{"location":"api/adaptive-sampling/#pybasin.as_basin_stability_estimator.ASBasinStabilityEstimator.estimate_as_bs","title":"estimate_as_bs","text":"<pre><code>estimate_as_bs() -&gt; tuple[\n    list[float],\n    list[dict[str, float]],\n    list[AdaptiveStudyResult],\n]\n</code></pre> <p>Estimate basin stability for each parameter value in the adaptive study.</p> <p>Performs basin stability estimation by systematically varying the specified parameter across the provided parameter values. For each parameter value:</p> <ol> <li>Updates the parameter in the ODE system, sampler, solver, or predictor</li> <li>Creates a new BasinStabilityEstimator instance</li> <li>Estimates basin stability and computes error estimates</li> <li>Stores results including basin stability values, errors, and solution metadata</li> </ol> <p>Uses GPU acceleration automatically when available for significant performance gains. Memory is explicitly freed after each iteration to prevent accumulation.</p> <p>Returns:</p> Type Description <code>tuple[list[float], list[dict[str, float]], list[AdaptiveStudyResult]]</code> <p>Tuple of three lists with matching indices:  - parameter_values: List of parameter values used - basin_stabilities: List of basin stability dictionaries (label -&gt; fraction) - results: List of AdaptiveStudyResult with complete information including errors</p>"},{"location":"api/adaptive-sampling/#pybasin.as_basin_stability_estimator.ASBasinStabilityEstimator.save","title":"save","text":"<pre><code>save() -&gt; None\n</code></pre> <p>Save the basin stability results to a JSON file. Handles numpy arrays and Solution objects by converting them to standard Python types.</p>"},{"location":"api/adaptive-sampling/#pybasin.as_basin_stability_estimator.ASBasinStabilityEstimator.get_errors","title":"get_errors","text":"<pre><code>get_errors(param_index: int) -&gt; dict[str, ErrorInfo]\n</code></pre> <p>Get error information for basin stability estimates at a specific parameter value.</p> <p>Retrieves the pre-computed error estimates (absolute and relative standard errors) for all attractor labels at the specified parameter index.</p> <p>Parameters:</p> Name Type Description Default <code>param_index</code> <code>int</code> <p>Index of the parameter value in the adaptive study (0-based).</p> required <p>Returns:</p> Type Description <code>dict[str, ErrorInfo]</code> <p>Dictionary mapping each attractor label to its ErrorInfo containing e_abs and e_rel.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If estimate_as_bs() has not been called yet.</p> <code>ValueError</code> <p>If param_index is out of range.</p>"},{"location":"api/adaptive-sampling/#pybasin.as_basin_stability_estimator.AdaptiveStudyParams","title":"pybasin.as_basin_stability_estimator.AdaptiveStudyParams","text":"<p>               Bases: <code>TypedDict</code></p> <p>Parameters for adaptive parameter study.</p>"},{"location":"api/adaptive-sampling/#result-types","title":"Result Types","text":"<p>options: heading_level: 3</p> <p>options: heading_level: 3</p>"},{"location":"api/adaptive-sampling/#pybasin.types.AdaptiveStudyResult","title":"pybasin.types.AdaptiveStudyResult","text":"<p>               Bases: <code>TypedDict</code></p> <p>Results for a single parameter value in an adaptive parameter study.</p> <p>Contains complete information about basin stability estimation at one parameter value, including the basin stability values, error estimates, sample metadata, and optional detailed solution data.</p> <p>Attributes:</p> Name Type Description <code>param_value</code> <code>float</code> <p>The parameter value used for this estimation.</p> <code>basin_stability</code> <code>dict[str, float]</code> <p>Dictionary mapping attractor labels to their basin stability values (fraction of samples).</p> <code>errors</code> <code>dict[str, ErrorInfo]</code> <p>Dictionary mapping attractor labels to their ErrorInfo (absolute and relative errors).</p> <code>n_samples</code> <code>int</code> <p>Number of initial conditions actually used (may differ from requested N due to grid rounding).</p> <code>labels</code> <code>ndarray[Any, Any] | None</code> <p>Array of attractor labels for each initial condition, or None if not available.</p> <code>bifurcation_amplitudes</code> <code>Tensor | None</code> <p>Amplitude values for bifurcation analysis, or None if not computed.</p>"},{"location":"api/adaptive-sampling/#pybasin.types.ErrorInfo","title":"pybasin.types.ErrorInfo","text":"<p>               Bases: <code>TypedDict</code></p> <p>Standard error information for basin stability estimates.</p> <p>Basin stability errors are computed using Bernoulli experiment statistics:</p> <ul> <li>e_abs = sqrt(S_B(A) * (1 - S_B(A)) / N) - absolute standard error</li> <li>e_rel = 1 / sqrt(N * S_B(A)) - relative standard error</li> </ul> <p>Attributes:</p> Name Type Description <code>e_abs</code> <code>float</code> <p>Absolute standard error of the basin stability estimate.</p> <code>e_rel</code> <code>float</code> <p>Relative standard error of the basin stability estimate.</p>"},{"location":"api/basin-stability-estimator/","title":"BasinStabilityEstimator","text":""},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator","title":"pybasin.basin_stability_estimator.BasinStabilityEstimator","text":"<p>Core class for basin stability analysis.</p> <p>Configures the analysis with an ODE system, sampler, and solver, and provides methods to estimate basin stability and save results.</p> <p>Attributes:</p> Name Type Description <code>bs_vals</code> <code>dict[str, float] | None</code> <p>Basin stability values (fraction of samples per class).</p> <code>y0</code> <code>Tensor | None</code> <p>Initial conditions tensor.</p> <code>solution</code> <code>Solution | None</code> <p>Solution instance containing trajectory and analysis results.</p>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator-functions","title":"Functions","text":""},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.__init__","title":"__init__","text":"<pre><code>__init__(\n    ode_system: ODESystemProtocol,\n    sampler: Sampler,\n    n: int = 10000,\n    solver: SolverProtocol | None = None,\n    feature_extractor: FeatureExtractor | None = None,\n    predictor: LabelPredictor | None = None,\n    feature_selector: BaseEstimator | None = _USE_DEFAULT,\n    detect_unbounded: bool = True,\n    save_to: str | None = None,\n)\n</code></pre> <p>Initialize the BasinStabilityEstimator.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of initial conditions (samples) to generate.</p> <code>10000</code> <code>ode_system</code> <code>ODESystemProtocol</code> <p>The ODE system model (ODESystem or JaxODESystem).</p> required <code>sampler</code> <code>Sampler</code> <p>The Sampler object to generate initial conditions.</p> required <code>solver</code> <code>SolverProtocol | None</code> <p>The Solver object to integrate the ODE system (Solver or JaxSolver). If None, automatically instantiates JaxSolver for JaxODESystem or TorchDiffEqSolver for ODESystem with time_span=(0, 1000), n_steps=1000, and device from sampler.</p> <code>None</code> <code>feature_extractor</code> <code>FeatureExtractor | None</code> <p>The FeatureExtractor object to extract features from trajectories. If None, defaults to TorchFeatureExtractor with minimal+dynamical features.</p> <code>None</code> <code>predictor</code> <code>LabelPredictor | None</code> <p>The LabelPredictor object to assign labels. If None, defaults to HDBSCANClusterer with auto_tune=True and assign_noise=True.</p> <code>None</code> <code>feature_selector</code> <code>BaseEstimator | None</code> <p>Feature filtering sklearn transformer with get_support() method. Defaults to DefaultFeatureSelector(). Pass None to disable filtering. Accepts any sklearn transformer (VarianceThreshold, SelectKBest, etc.) or Pipeline.</p> <code>_USE_DEFAULT</code> <code>detect_unbounded</code> <code>bool</code> <p>Enable unboundedness detection before feature extraction (default: True). Only activates when solver has event_fn configured (e.g., JaxSolver with event_fn). When enabled, unbounded trajectories are separated and labeled as \"unbounded\" before feature extraction to prevent imputed Inf values from contaminating features.</p> <code>True</code> <code>save_to</code> <code>str | None</code> <p>Optional file path to save results.</p> <code>None</code>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.estimate_bs","title":"estimate_bs","text":"<pre><code>estimate_bs(\n    parallel_integration: bool = True,\n) -&gt; dict[str, float]\n</code></pre> <p>Estimate basin stability by:     1. Generating initial conditions using the sampler.     2. Integrating the ODE system for each sample (in parallel) to produce a Solution.     3. Extracting features from each Solution.     4. Clustering/classifying the feature space.     5. Computing the fraction of samples in each basin.</p> <p>This method sets:     - self.y0     - self.solution     - self.bs_vals</p> <p>Parameters:</p> Name Type Description Default <code>parallel_integration</code> <code>bool</code> <p>If True and using ClassifierPredictor, run main integration and template integration in parallel (default: True).</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>A dictionary of basin stability values per class.</p>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.get_errors","title":"get_errors","text":"<pre><code>get_errors() -&gt; dict[str, ErrorInfo]\n</code></pre> <p>Compute absolute and relative errors for basin stability estimates.</p> <p>The errors are based on Bernoulli experiment statistics:</p> <ul> <li>e_abs = sqrt(S_B(A) * (1 - S_B(A)) / N) \u2014 absolute standard error</li> <li>e_rel = 1 / sqrt(N * S_B(A)) \u2014 relative error</li> </ul> <p>Returns:</p> Type Description <code>dict[str, ErrorInfo]</code> <p>Dictionary mapping each label to an ErrorInfo with <code>e_abs</code> and <code>e_rel</code> keys.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>estimate_bs()</code> has not been called yet.</p>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.save","title":"save","text":"<pre><code>save() -&gt; None\n</code></pre> <p>Save the basin stability results to a JSON file.</p> <p>Converts numpy arrays and Solution objects to standard Python types.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>estimate_bs()</code> has not been called yet.</p> <code>ValueError</code> <p>If <code>save_to</code> path is not defined.</p>"},{"location":"api/basin-stability-estimator/#pybasin.basin_stability_estimator.BasinStabilityEstimator.save_to_excel","title":"save_to_excel","text":"<pre><code>save_to_excel() -&gt; None\n</code></pre> <p>Save the basin stability results to an Excel file.</p> <p>Includes grid samples, labels, and bifurcation amplitudes.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>estimate_bs()</code> has not been called yet.</p> <code>ValueError</code> <p>If <code>save_to</code> path is not defined.</p> <code>ValueError</code> <p>If no solution data is available.</p>"},{"location":"api/feature-extractors/","title":"Feature Extractors","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor","title":"pybasin.feature_extractors.feature_extractor.FeatureExtractor","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for extracting features from ODE solutions.</p> <p>Feature extractors transform ODE solution trajectories into feature vectors that can be used for basin of attraction classification. This class provides utilities for filtering solutions by time (to remove transients).</p> <pre><code>class AmplitudeExtractor(FeatureExtractor):\n    def extract_features(self, solution: Solution) -&gt; torch.Tensor:\n        y_filtered = self.filter_time(solution)\n        return torch.max(torch.abs(y_filtered), dim=0)[0]\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Only data after this time will be used for feature extraction. Default of 0.0 uses the entire time series. A common choice is the last 10% of the integration time to avoid transient behavior.</p> <code>0.0</code>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names.</p> <p>If not explicitly set by a subclass, automatically generates names using the pattern: _. The class name is converted to snake_case and the suffix 'FeatureExtractor' is removed (if present). <p>Returns:</p> Type Description <code>list[str]</code> <p>List of feature names. Length must match the number of features (F) in the output tensor from extract_features().</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor.extract_features","title":"extract_features  <code>abstractmethod</code>","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract features from an ODE solution.</p> <p>This method must be implemented by subclasses to define how features are computed from solution trajectories.</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution containing time series data for one or more trajectories. The solution.y tensor has shape (N, B, S) where N is the number of time steps, B is the batch size (number of initial conditions), and S is the number of state variables.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Feature tensor of shape (B, F) where B is the batch size and F is the number of features extracted per trajectory.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.feature_extractor.FeatureExtractor.filter_time","title":"filter_time","text":"<pre><code>filter_time(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Filter out transient behavior by removing early time steps.</p> <p>Removes time steps before <code>time_steady</code> to exclude transient dynamics from feature extraction. This ensures features are computed only from steady-state or long-term behavior.</p> <pre><code># Extract features only from the last 10% of integration time\nextractor = FeatureExtractor(time_steady=9.0)  # if time_span=(0, 10)\nfiltered = extractor.filter_time(solution)\n# Only time points t &gt; 9.0 are included\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution with time tensor of shape (N,) and y tensor of shape (N, B, S) where N is time steps, B is batch size, and S is number of state variables.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Filtered tensor of shape (N', B, S) where N' is the number of time steps after time_steady. If time_steady is 0 or less than all time points, returns the original solution.y unchanged.</p>"},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor","title":"pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor","text":"<p>               Bases: <code>FeatureExtractor</code></p> <p>PyTorch-based feature extractor for time series features.</p> <p>Supports per-state variable feature configuration using tsfresh-style FCParameters dictionaries, allowing different feature sets for different state variables.</p> <p>For CPU extraction, uses multiprocessing to parallelize across batches. For GPU extraction, uses batched CUDA operations for optimal performance.</p> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Default 0.0.</p> <code>0.0</code> <code>features</code> <code>Literal['comprehensive', 'minimal'] | FCParameters | None</code> <p>Default feature configuration to apply to all states. Can be: - 'comprehensive': Use TORCH_COMPREHENSIVE_FC_PARAMETERS (default) - 'minimal': Use TORCH_MINIMAL_FC_PARAMETERS (10 basic features) - FCParameters dict: Custom feature configuration - None: Skip states not explicitly configured in features_per_state</p> <code>'comprehensive'</code> <code>features_per_state</code> <code>dict[int, FCParameters | None] | None</code> <p>Optional dict mapping state indices to FCParameters. Overrides <code>features</code> for specified states. Use None as value to skip a state. States not in this dict use the global <code>features</code> config.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>Whether to apply z-score normalization. Default True.</p> <code>True</code> <code>device</code> <code>Literal['cpu', 'gpu']</code> <p>Execution device ('cpu' or 'gpu'). Default 'cpu'.</p> <code>'cpu'</code> <code>n_jobs</code> <code>int | None</code> <p>Number of worker processes for CPU extraction. If None, uses all available CPU cores. Ignored when device='gpu'.</p> <code>None</code> <code>impute_method</code> <code>Literal['extreme', 'tsfresh']</code> <p>Method for handling NaN/inf values in features. Options: - 'extreme': Replace with extreme values (1e10) to distinguish unbounded trajectories. Best for systems with divergent solutions. (default) - 'tsfresh': Replace using tsfresh-style imputation (inf-&gt;max/min, NaN-&gt;median). Better when all trajectories are bounded.</p> <code>'extreme'</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If device='gpu' but CUDA is not available.  Examples: &gt;&gt;&gt; # Default: use comprehensive features for all states on CPU &gt;&gt;&gt; extractor = TorchFeatureExtractor(time_steady=9.0)  &gt;&gt;&gt; # GPU extraction with default features &gt;&gt;&gt; extractor = TorchFeatureExtractor(time_steady=9.0, device=\"gpu\")  &gt;&gt;&gt; # Custom features for specific states, skip others &gt;&gt;&gt; extractor = TorchFeatureExtractor( ...     time_steady=9.0, ...     features=None,  # Don't extract features by default ...     features_per_state={ ...         1: {\"maximum\": None, \"minimum\": None},  # Only extract for state 1 ...     }, ... )  &gt;&gt;&gt; # Global features with per-state override &gt;&gt;&gt; extractor = TorchFeatureExtractor( ...     time_steady=9.0, ...     features_per_state={ ...         0: {\"maximum\": None},  # Override state 0 ...         1: None,  # Skip state 1 ...     }, ... )</p>"},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names in the format 'state_X__feature_name'.</p>"},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor.extract_features","title":"extract_features","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract features from an ODE solution using PyTorch.</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution containing time series data with y tensor of shape (N, B, S) where N=timesteps, B=batch size, S=state variables.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Feature tensor of shape (B, F) where F is the total number of features.</p>"},{"location":"api/feature-extractors/#pybasin.ts_torch.torch_feature_extractor.TorchFeatureExtractor.reset_scaler","title":"reset_scaler","text":"<pre><code>reset_scaler() -&gt; None\n</code></pre> <p>Reset the normalization parameters.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor","title":"pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor","text":"<p>               Bases: <code>FeatureExtractor</code></p> <p>JAX-based feature extractor for time series features.</p> <p>Supports per-state variable feature configuration using tsfresh-style FCParameters dictionaries, allowing different feature sets for different state variables.</p> <p>Warning:     Using JAX_COMPREHENSIVE_FC_PARAMETERS may cause very long JIT compile times     (~40 minutes). Use JAX_MINIMAL_FC_PARAMETERS or a custom subset for faster     compilation.</p> <pre><code># Default: use minimal features for all states\nextractor = JaxFeatureExtractor(time_steady=9.0)\n\n# Custom features for specific states, skip others\nextractor = JaxFeatureExtractor(\n    time_steady=9.0,\n    features=None,  # Don't extract features by default\n    features_per_state={\n        1: {\"log_delta\": None},  # Only extract for state 1\n    },\n)\n\n# Global features with per-state override\nextractor = JaxFeatureExtractor(\n    time_steady=9.0,\n    features_per_state={\n        0: {\"maximum\": None},  # Override state 0\n        1: None,  # Skip state 1\n    },\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Default 0.0.</p> <code>0.0</code> <code>features</code> <code>FCParameters | None</code> <p>Default FCParameters configuration to apply to all states. Defaults to JAX_MINIMAL_FC_PARAMETERS. Set to None to skip states not explicitly configured in features_per_state.</p> <code>JAX_MINIMAL_FC_PARAMETERS</code> <code>features_per_state</code> <code>dict[int, FCParameters | None] | None</code> <p>Optional dict mapping state indices to FCParameters. Overrides <code>features</code> for specified states. Use None as value to skip a state. States not in this dict use the global <code>features</code> config.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>Whether to apply z-score normalization. Default True.</p> <code>True</code> <code>use_jit</code> <code>bool</code> <p>Whether to JIT-compile extraction. Default True.</p> <code>True</code> <code>device</code> <code>str | None</code> <p>JAX device to use ('cpu', 'gpu', 'cuda', 'cuda:N', or None for auto).</p> <code>None</code> <code>impute_method</code> <code>Literal['extreme', 'tsfresh']</code> <p>Method for handling NaN/inf values in features. Options:  - 'extreme': Replace with extreme values (1e10) to distinguish unbounded trajectories. Best for systems with divergent solutions. (default)  - 'tsfresh': Replace using tsfresh-style imputation (inf-&gt;max/min, NaN-&gt;median). Better when all trajectories are bounded.</p> <code>'extreme'</code>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names in the format 'state_X__feature_name'.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor.extract_features","title":"extract_features","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract features from an ODE solution using JAX.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.jax_feature_extractor.JaxFeatureExtractor.reset_scaler","title":"reset_scaler","text":"<pre><code>reset_scaler() -&gt; None\n</code></pre> <p>Reset the normalization parameters.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor","title":"pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor","text":"<p>               Bases: <code>FeatureExtractor</code></p> <p>Feature extractor using tsfresh for comprehensive time series analysis.</p> <p>This extractor uses the tsfresh library to automatically extract a large number of time series features from ODE solutions. It converts PyTorch/JAX tensors to pandas DataFrames for tsfresh processing, then converts the results back to tensors.</p> <p>Supports per-state variable feature configuration using tsfresh's kind_to_fc_parameters mechanism, allowing you to apply different feature sets to different state variables based on domain knowledge.</p> <pre><code># Same minimal features for all states\nextractor = TsfreshFeatureExtractor(\n    time_steady=9.0, default_fc_parameters=MinimalFCParameters(), n_jobs=-1, normalize=True\n)\n\n# Specific features for all states\nextractor = TsfreshFeatureExtractor(\n    time_steady=950.0,\n    default_fc_parameters={\"mean\": None, \"std\": None, \"maximum\": None},\n    n_jobs=-1,\n)\n\n# Different features per state (e.g., pendulum: position vs velocity)\nfrom tsfresh.feature_extraction import MinimalFCParameters, ComprehensiveFCParameters\n\nextractor = TsfreshFeatureExtractor(\n    time_steady=950.0,\n    kind_to_fc_parameters={\n        0: {\"mean\": None, \"maximum\": None, \"minimum\": None},  # Position: basic stats\n        1: ComprehensiveFCParameters(),  # Velocity: full spectral analysis\n    },\n    n_jobs=1,  # Use n_jobs=1 for deterministic results\n)\n</code></pre> <p>Note on parallelism:     Setting n_jobs &gt; 1 enables parallel feature extraction but introduces     non-determinism due to floating-point arithmetic order. This can cause     inconsistent classification results. Use n_jobs=1 for reproducible results.</p> <p>Note on normalization:     When normalize=True, the scaler is fitted on the FIRST dataset that calls     extract_features(). For best results with supervised classifiers:     - Either set normalize=False (recommended for KNN with few templates)     - Or call fit_scaler() explicitly with representative data before extraction</p> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Only data after this time will be used for feature extraction. Default of 0.0 uses the entire time series.</p> <code>0.0</code> <code>default_fc_parameters</code> <code>dict[str, Any] | Any | None</code> <p>Default feature extraction parameters for all states. Can be one of: - MinimalFCParameters() - Fast extraction with ~20 features - ComprehensiveFCParameters() - Full extraction with ~800 features - Custom dict like {\"mean\": None, \"maximum\": None} for specific features - None - must provide kind_to_fc_parameters Default is MinimalFCParameters().</p> <code>None</code> <code>kind_to_fc_parameters</code> <code>dict[int, dict[str, Any] | Any] | None</code> <p>Optional dict mapping state indices to FCParameters. Allows different feature sets per state variable. If provided, overrides default_fc_parameters for those states.</p> <code>None</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs for feature extraction. Default is 1. Set to -1 to use all available cores.</p> <code>1</code> <code>normalize</code> <code>bool</code> <p>Whether to apply StandardScaler normalization to features. Highly recommended for distance-based classifiers like KNN. Default is True.</p> <code>True</code>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of feature names from tsfresh extraction.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If extract_features has not been called yet.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor.reset_scaler","title":"reset_scaler","text":"<pre><code>reset_scaler() -&gt; None\n</code></pre> <p>Reset the scaler to unfitted state.</p> <p>Call this if you need to refit the scaler on different data.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.tsfresh_feature_extractor.TsfreshFeatureExtractor.extract_features","title":"extract_features","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract features from an ODE solution using tsfresh.</p> <p>Converts the solution tensor to pandas DataFrame format expected by tsfresh, extracts features for each trajectory and state variable, then converts back to PyTorch tensor.</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution with y tensor of shape (N, B, S) where N is time steps, B is batch size, and S is number of state variables.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Feature tensor of shape (B, F) where B is the batch size and F is the total number of features extracted by tsfresh across all state variables.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor","title":"pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor","text":"<p>               Bases: <code>FeatureExtractor</code></p> <p>Feature extractor using nolds for nonlinear dynamics analysis.</p> <p>Computes nonlinear dynamics features for each trajectory with multiprocessing parallelization. Uses tsfresh-style FCParameters configuration for specifying which features to extract and with what parameters.</p> <p>Available features (passed directly to nolds):     * <code>lyap_r</code>: Largest Lyapunov exponent (Rosenstein's algorithm)     * <code>lyap_e</code>: Largest Lyapunov exponent (Eckmann's algorithm)     * <code>sampen</code>: Sample entropy     * <code>hurst_rs</code>: Hurst exponent (R/S analysis)     * <code>corr_dim</code>: Correlation dimension     * <code>dfa</code>: Detrended fluctuation analysis     * <code>mfhurst_b</code>: Multifractal Hurst exponent (basic method)     * <code>mfhurst_dm</code>: Multifractal Hurst exponent (DM method)</p> <pre><code># Default: extract lyap_r and corr_dim from all states\nextractor = NoldsFeatureExtractor(time_steady=9.0)\n\n# Only extract Lyapunov exponents with custom parameters\nextractor = NoldsFeatureExtractor(\n    time_steady=9.0,\n    features={\"lyap_r\": [{\"emb_dim\": 15}]},\n)\n\n# Per-state configuration\nextractor = NoldsFeatureExtractor(\n    time_steady=9.0,\n    features=None,\n    features_per_state={\n        0: {\"lyap_r\": None},\n        1: {\"corr_dim\": [{\"emb_dim\": 10}]},\n    },\n)\n\n# Multiple parameter sets for same feature\nextractor = NoldsFeatureExtractor(\n    time_steady=9.0,\n    features={\n        \"lyap_r\": [\n            {\"emb_dim\": 5},\n            {\"emb_dim\": 10},\n        ],\n    },\n)\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>time_steady</code> <code>float</code> <p>Time threshold for filtering transients. Default 0.0.</p> <code>0.0</code> <code>features</code> <code>NoldsFCParameters | None</code> <p>Feature configuration for all states. Can be: * NoldsFCParameters dict: Feature names mapped to parameter lists * None: Skip states not in features_per_state Default extracts both lyap_r and corr_dim with nolds defaults.</p> <code>None</code> <code>features_per_state</code> <code>dict[int, NoldsFCParameters | None] | None</code> <p>Optional dict mapping state indices to FCParameters. Overrides <code>features</code> for specified states. Use None to skip a state.</p> <code>None</code> <code>n_jobs</code> <code>int | None</code> <p>Number of worker processes. If None, uses all CPU cores.</p> <code>None</code> <p>Raises:</p> Type Description <code>ImportError</code> <p>If nolds library is not installed.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor-attributes","title":"Attributes","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor.feature_names","title":"feature_names  <code>property</code>","text":"<pre><code>feature_names: list[str]\n</code></pre> <p>Return the list of feature names in format 'state_X__feature__params'.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If extract_features has not been called yet.</p>"},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor-functions","title":"Functions","text":""},{"location":"api/feature-extractors/#pybasin.feature_extractors.nolds_feature_extractor.NoldsFeatureExtractor.extract_features","title":"extract_features","text":"<pre><code>extract_features(solution: Solution) -&gt; torch.Tensor\n</code></pre> <p>Extract nolds features from an ODE solution.</p> <p>Parameters:</p> Name Type Description Default <code>solution</code> <code>Solution</code> <p>ODE solution with shape (N, B, S).</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Features tensor of shape (B, F) where F depends on configuration.</p>"},{"location":"api/feature-selector/","title":"Feature Selector","text":""},{"location":"api/feature-selector/#pybasin.feature_selector.default_feature_selector.DefaultFeatureSelector","title":"pybasin.feature_selector.default_feature_selector.DefaultFeatureSelector","text":"<p>               Bases: <code>Pipeline</code></p> <p>Feature selector combining variance threshold and correlation filtering.</p> <p>This class extends sklearn's Pipeline with two steps:</p> <ol> <li>VarianceThreshold: Removes features with variance below threshold</li> <li>CorrelationSelector: Removes highly correlated features (|corr| &gt; threshold)</li> </ol> <p>The correlation threshold uses absolute correlation values, meaning both positive and negative correlations above the threshold will trigger removal.</p> <p>As a Pipeline subclass, this implements the full sklearn transformer API: fit(), transform(), fit_transform(), get_params(), set_params(), etc.</p> <pre><code>selector = DefaultFeatureSelector(variance_threshold=0.01, correlation_threshold=0.95)\nfeatures_filtered = selector.fit_transform(features)\n</code></pre> <p>Attributes:</p> Name Type Description <code>variance_threshold</code> <code>float</code> <p>Minimum variance required to keep a feature.</p> <code>correlation_threshold</code> <code>float</code> <p>Maximum absolute correlation allowed between features. Features with |correlation| &gt; threshold will be removed.</p> <code>min_features</code> <code>int</code> <p>Minimum number of features to keep.</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.default_feature_selector.DefaultFeatureSelector-functions","title":"Functions","text":""},{"location":"api/feature-selector/#pybasin.feature_selector.default_feature_selector.DefaultFeatureSelector.get_support","title":"get_support","text":"<pre><code>get_support(indices: bool = False) -&gt; np.ndarray\n</code></pre> <p>Get mask or indices of features that passed the filter.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>bool</code> <p>If True, returns indices. If False, returns boolean mask.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>Boolean mask or integer indices of selected features.</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector","title":"pybasin.feature_selector.correlation_selector.CorrelationSelector","text":"<p>               Bases: <code>BaseEstimator</code>, <code>TransformerMixin</code></p> <p>Scikit-learn transformer to remove highly correlated features.</p> <p>This transformer removes features with high pairwise correlations, keeping only one feature from each correlated group.</p> <p>Attributes:</p> Name Type Description <code>threshold</code> <code>float</code> <p>Correlation threshold. Features with absolute correlation above this value will be considered redundant.</p> <code>min_features</code> <code>int</code> <p>Minimum number of features to keep. If removing correlated features would result in fewer than this many, some correlated features are retained.</p> <code>support_</code> <p>Boolean mask of selected features.</p> <code>n_features_in_</code> <p>Number of input features.</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector-functions","title":"Functions","text":""},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector.fit","title":"fit","text":"<pre><code>fit(X: ndarray, y: ndarray | None = None)\n</code></pre> <p>Compute which features to keep.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Training data of shape (n_samples, n_features).</p> required <code>y</code> <code>ndarray | None</code> <p>Not used, present for API consistency.</p> <code>None</code> <p>Returns:</p> Type Description <p>Fitted transformer.</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector.transform","title":"transform","text":"<pre><code>transform(X: ndarray) -&gt; np.ndarray\n</code></pre> <p>Remove correlated features.</p> <p>Parameters:</p> Name Type Description Default <code>X</code> <code>ndarray</code> <p>Input data of shape (n_samples, n_features).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Data with correlated features removed, shape (n_samples, n_features_out).</p>"},{"location":"api/feature-selector/#pybasin.feature_selector.correlation_selector.CorrelationSelector.get_support","title":"get_support","text":"<pre><code>get_support(indices: bool = False)\n</code></pre> <p>Get a mask or indices of selected features.</p> <p>Parameters:</p> Name Type Description Default <code>indices</code> <code>bool</code> <p>If True, return feature indices. Otherwise, return boolean mask.</p> <code>False</code> <p>Returns:</p> Type Description <p>Boolean mask or integer indices of selected features.</p>"},{"location":"api/plotters/","title":"Plotters","text":""},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter","title":"pybasin.plotters.matplotlib_plotter.MatplotlibPlotter","text":""},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter-functions","title":"Functions","text":""},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.__init__","title":"__init__","text":"<pre><code>__init__(bse: BasinStabilityEstimator)\n</code></pre> <p>Initialize the Plotter with a BasinStabilityEstimator instance.</p> <p>Parameters:</p> Name Type Description Default <code>bse</code> <code>BasinStabilityEstimator</code> <p>An instance of BasinStabilityEstimator.</p> required"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_basin_stability_bars","title":"plot_basin_stability_bars","text":"<pre><code>plot_basin_stability_bars(ax: Axes | None = None)\n</code></pre> <p>Plot basin stability values as a bar chart.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>Matplotlib axes to plot on. If None, creates a new figure.</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_state_space","title":"plot_state_space","text":"<pre><code>plot_state_space(ax: Axes | None = None)\n</code></pre> <p>Plot initial conditions in state space, colored by their attractor labels.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>Matplotlib axes to plot on. If None, creates a new figure.</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_feature_space","title":"plot_feature_space","text":"<pre><code>plot_feature_space(ax: Axes | None = None)\n</code></pre> <p>Plot feature space with classifier results.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes | None</code> <p>Matplotlib axes to plot on. If None, creates a new figure.</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_bse_results","title":"plot_bse_results","text":"<pre><code>plot_bse_results()\n</code></pre> <p>Generate diagnostic plots using the data stored in self.solution:     1. A bar plot of basin stability values.     2. A scatter plot of initial conditions (state space).     3. A scatter plot of the feature space with classifier results.     4. A placeholder plot for future use.</p> <p>This method combines the individual plotting functions into a 2x2 grid. For individual plots, use plot_basin_stability_bars(), plot_state_space(), or plot_feature_space() directly.</p>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_phase","title":"plot_phase","text":"<pre><code>plot_phase(\n    x_var: int = 0, y_var: int = 1, z_var: int | None = None\n)\n</code></pre> <p>Plot trajectories for the template initial conditions in 2D or 3D phase space.</p>"},{"location":"api/plotters/#pybasin.plotters.matplotlib_plotter.MatplotlibPlotter.plot_templates","title":"plot_templates","text":"<pre><code>plot_templates(\n    plotted_var: int,\n    time_span: tuple[float, float] | None = None,\n)\n</code></pre> <p>Plot trajectories for the template initial conditions.</p> <p>Parameters:</p> Name Type Description Default <code>plotted_var</code> <code>int</code> <p>Index of the variable to plot.</p> required <code>time_span</code> <code>tuple[float, float] | None</code> <p>Time range to plot (t_start, t_end).</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.interactive_plotter.plotter.InteractivePlotter","title":"pybasin.plotters.interactive_plotter.plotter.InteractivePlotter","text":"<p>Interactive web-based plotter for basin stability visualization.</p> <p>Uses Dash with Mantine components for a modern UI and Plotly for interactive visualizations. Each page owns its controls, plot, and callbacks.</p> <p>Attributes:</p> Name Type Description <code>bse</code> <code>BasinStabilityEstimator</code> <p>BasinStabilityEstimator instance with computed results.</p> <code>state_labels</code> <p>Optional mapping of state indices to custom labels.</p> <code>app</code> <code>Dash | None</code> <p>Dash application instance.</p>"},{"location":"api/plotters/#pybasin.plotters.interactive_plotter.plotter.InteractivePlotter-functions","title":"Functions","text":""},{"location":"api/plotters/#pybasin.plotters.interactive_plotter.plotter.InteractivePlotter.__init__","title":"__init__","text":"<pre><code>__init__(\n    bse: BasinStabilityEstimator\n    | ASBasinStabilityEstimator,\n    state_labels: dict[int, str] | None = None,\n    options: InteractivePlotterOptions | None = None,\n)\n</code></pre> <p>Initialize the Plotter.</p> <p>Parameters:</p> Name Type Description Default <code>bse</code> <code>BasinStabilityEstimator | ASBasinStabilityEstimator</code> <p>BasinStabilityEstimator or ASBasinStabilityEstimator instance.</p> required <code>state_labels</code> <code>dict[int, str] | None</code> <p>Optional dict mapping state indices to labels, e.g., {0: \"\u03b8\", 1: \"\u03c9\"} for a pendulum system.</p> <code>None</code> <code>options</code> <code>InteractivePlotterOptions | None</code> <p>Optional configuration for default control values.</p> <code>None</code>"},{"location":"api/plotters/#pybasin.plotters.interactive_plotter.plotter.InteractivePlotter.run","title":"run","text":"<pre><code>run(port: int = 8050, debug: bool = False) -&gt; None\n</code></pre> <p>Launch the interactive plotter as a standalone Dash server.</p> <p>Parameters:</p> Name Type Description Default <code>port</code> <code>int</code> <p>Port to run the server on (default: 8050).</p> <code>8050</code> <code>debug</code> <code>bool</code> <p>Enable Dash debug mode (default: False).</p> <code>False</code>"},{"location":"api/plotters/#pybasin.matplotlib_as_plotter.ASPlotter","title":"pybasin.matplotlib_as_plotter.ASPlotter","text":"<p>Matplotlib-based plotter for adaptive study basin stability results.</p> <p>Attributes:</p> Name Type Description <code>as_bse</code> <p>ASBasinStabilityEstimator instance with computed results.</p>"},{"location":"api/plotters/#pybasin.matplotlib_as_plotter.ASPlotter-functions","title":"Functions","text":""},{"location":"api/plotters/#pybasin.matplotlib_as_plotter.ASPlotter.__init__","title":"__init__","text":"<pre><code>__init__(as_bse: ASBasinStabilityEstimator)\n</code></pre> <p>Initialize the plotter with an ASBasinStabilityEstimator instance.</p> <p>Parameters:</p> Name Type Description Default <code>as_bse</code> <code>ASBasinStabilityEstimator</code> <p>An instance of ASBasinStabilityEstimator.</p> required"},{"location":"api/plotters/#pybasin.matplotlib_as_plotter.ASPlotter.plot_basin_stability_variation","title":"plot_basin_stability_variation","text":"<pre><code>plot_basin_stability_variation(\n    interval: Literal[\"linear\", \"log\"] = \"linear\",\n    show: bool = True,\n)\n</code></pre> <p>Plot all basin stability values against parameter variation in a single plot.</p> <p>Parameters:</p> Name Type Description Default <code>interval</code> <code>Literal['linear', 'log']</code> <p>Indicates whether the x-axis should use a linear or logarithmic scale. Options:  - 'linear': Default linear scale. - 'log': Logarithmic scale, e.g., when using <code>2 * np.logspace(...)</code>.</p> <code>'linear'</code> <code>show</code> <code>bool</code> <p>Whether to display the plot. If False, returns the figure without showing.</p> <code>True</code> <p>Returns:</p> Type Description <p>The matplotlib Figure object.</p>"},{"location":"api/plotters/#pybasin.matplotlib_as_plotter.ASPlotter.plot_bifurcation_diagram","title":"plot_bifurcation_diagram","text":"<pre><code>plot_bifurcation_diagram(dof: list[int], show: bool = True)\n</code></pre> <p>Plot bifurcation diagram showing attractor locations over parameter variation.</p> <p>For each parameter value, the method extracts the bifurcation amplitudes (i.e. solution.bifurcation_amplitudes), selects the desired DOFs, applies k-means clustering and then plots the cluster centers as a function of the parameter.</p> <p>Unbounded trajectories are automatically filtered out before clustering, as bifurcation amplitudes are only computed for bounded trajectories.</p> <p>Parameters:</p> Name Type Description Default <code>dof</code> <code>list[int]</code> <p>List of indices of the state variables (DOFs) to plot.</p> required <code>show</code> <code>bool</code> <p>Whether to display the plot. If False, returns the figure without showing.</p> <code>True</code> <p>Returns:</p> Type Description <p>The matplotlib Figure object.</p>"},{"location":"api/predictors/","title":"Predictors","text":""},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor","title":"pybasin.predictors.base.LabelPredictor","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for label prediction algorithms.</p> <p>This class provides a common interface for both supervised classifiers and unsupervised clusterers used in basin stability analysis.</p>"},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor.predict_labels","title":"predict_labels  <code>abstractmethod</code>","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels for the given features.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array to predict labels for.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of predicted labels.</p>"},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor.needs_feature_names","title":"needs_feature_names","text":"<pre><code>needs_feature_names() -&gt; bool\n</code></pre> <p>Check if this predictor requires feature names to be set before prediction.</p> <p>Override this method and return True if your predictor needs to parse feature names (e.g., to identify specific features like 'variance' or 'amplitude').</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if set_feature_names() must be called before predict_labels().</p>"},{"location":"api/predictors/#pybasin.predictors.base.LabelPredictor.set_feature_names","title":"set_feature_names","text":"<pre><code>set_feature_names(feature_names: list[str]) -&gt; None\n</code></pre> <p>Set feature names for predictors that require them.</p> <p>Called automatically by BasinStabilityEstimator if needs_feature_names() returns True. Override this method to parse and store feature name indices.</p> <p>Parameters:</p> Name Type Description Default <code>feature_names</code> <code>list[str]</code> <p>List of feature names matching the feature array columns.</p> required <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If called on a predictor that doesn't need feature names.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClustererPredictor","title":"pybasin.predictors.base.ClustererPredictor","text":"<p>               Bases: <code>LabelPredictor</code></p> <p>Base class for unsupervised clustering algorithms.</p> <p>Unsupervised learning: Discovers patterns and groups in data without requiring labeled examples. Use when attractors/basins are unknown and need to be discovered.</p> <p>Unlike ClassifierPredictor, this class does not require template initial conditions or ODE parameters, as unsupervised methods work directly on features without needing labeled training data.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor","title":"pybasin.predictors.base.ClassifierPredictor","text":"<p>               Bases: <code>LabelPredictor</code></p> <p>Base class for supervised classifiers that require labeled template data.</p> <p>Supervised learning: Requires example trajectories with known labels to learn the mapping from features to basin/attractor labels. Use when attractors are known.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor-attributes","title":"Attributes","text":""},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.has_dedicated_solver","title":"has_dedicated_solver  <code>property</code>","text":"<pre><code>has_dedicated_solver: bool\n</code></pre> <p>Check if the classifier has its own dedicated solver for template integration.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.__init__","title":"__init__","text":"<pre><code>__init__(\n    template_y0: list[list[float]],\n    labels: list[str],\n    ode_params: Mapping[str, Any],\n    solver: SolverProtocol | None = None,\n)\n</code></pre> <p>Initialize the supervised classifier.</p> <p>Parameters:</p> Name Type Description Default <code>template_y0</code> <code>list[list[float]]</code> <p>Template initial conditions as a list of lists (e.g., [[0.5, 0.0], [2.7, 0.0]]). Will be converted to tensor with appropriate device during integration.</p> required <code>labels</code> <code>list[str]</code> <p>Ground truth labels for template conditions.</p> required <code>ode_params</code> <code>Mapping[str, Any]</code> <p>ODE parameters mapping (dict or TypedDict with numeric values).</p> required <code>solver</code> <code>SolverProtocol | None</code> <p>Optional solver for template integration. If provided, this solver will be used instead of the main solver (useful for CPU-based template integration when templates are few).</p> <code>None</code>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.integrate_templates","title":"integrate_templates","text":"<pre><code>integrate_templates(\n    solver: SolverProtocol | None,\n    ode_system: ODESystemProtocol,\n) -&gt; None\n</code></pre> <p>Integrate ODE for template initial conditions (without feature extraction).</p> <p>This method should be called before fit_with_features() to allow the main feature extraction to fit the scaler first.</p> <p>By default, if no dedicated solver was provided at init, this method will automatically create a CPU variant of the passed solver. This is because CPU is typically faster than GPU for small batch sizes (like templates).</p> <p>Parameters:</p> Name Type Description Default <code>solver</code> <code>SolverProtocol | None</code> <p>Fallback solver if no solver was provided at init. Can be None if a solver was provided during classifier initialization.</p> required <code>ode_system</code> <code>ODESystemProtocol</code> <p>ODE system to integrate (ODESystem or JaxODESystem).</p> required"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.fit_with_features","title":"fit_with_features","text":"<pre><code>fit_with_features(\n    feature_extractor: FeatureExtractor,\n    feature_selector: Any | None = None,\n) -&gt; None\n</code></pre> <p>Fit the classifier using pre-integrated template solutions.</p> <p>Must call integrate_templates() first to populate self.solution.</p> <p>Parameters:</p> Name Type Description Default <code>feature_extractor</code> <code>FeatureExtractor</code> <p>Feature extractor to transform trajectories.</p> required <code>feature_selector</code> <code>Any | None</code> <p>Optional feature selector (already fitted on main data). If provided, applies the same filtering to template features.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If filtering removes all template features.</p>"},{"location":"api/predictors/#pybasin.predictors.base.ClassifierPredictor.fit","title":"fit","text":"<pre><code>fit(\n    solver: SolverProtocol,\n    ode_system: ODESystemProtocol,\n    feature_extractor: FeatureExtractor,\n) -&gt; None\n</code></pre> <p>Fit the classifier using template initial conditions.</p> <p>WARNING: This method extracts features from templates FIRST, which means the scaler will be fitted on template data (often just 2 samples). For better normalization, use integrate_templates() + fit_with_features() to allow the main data to fit the scaler first.</p> <p>Parameters:</p> Name Type Description Default <code>solver</code> <code>SolverProtocol</code> <p>Solver to integrate the ODE system (Solver or JaxSolver).</p> required <code>ode_system</code> <code>ODESystemProtocol</code> <p>ODE system to integrate (ODESystem or JaxODESystem).</p> required <code>feature_extractor</code> <code>FeatureExtractor</code> <p>Feature extractor to transform trajectories.</p> required"},{"location":"api/predictors/#pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer","title":"pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer","text":"<p>               Bases: <code>ClustererPredictor</code></p> <p>HDBSCAN clustering for basin stability analysis with optional auto-tuning and noise assignment (unsupervised learning).</p>"},{"location":"api/predictors/#pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer.__init__","title":"__init__","text":"<pre><code>__init__(\n    clusterer: Any = None,\n    assign_noise: bool = False,\n    k_neighbors: int = 5,\n    auto_tune: bool = False,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize HDBSCAN clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>clusterer</code> <code>Any</code> <p>HDBSCAN instance, or None to create default.</p> <code>None</code> <code>assign_noise</code> <code>bool</code> <p>Whether to assign noise points to nearest clusters using KNN.</p> <code>False</code> <code>k_neighbors</code> <code>int</code> <p>Number of neighbors for KNN noise assignment.</p> <code>5</code> <code>auto_tune</code> <code>bool</code> <p>Whether to automatically tune min_cluster_size using silhouette score.</p> <code>False</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for HDBSCAN if clusterer is None. Common: min_cluster_size=50, min_samples=10</p> <code>{}</code>"},{"location":"api/predictors/#pybasin.predictors.hdbscan_clusterer.HDBSCANClusterer.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels using HDBSCAN clustering with optional noise assignment.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array to cluster.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Cluster labels.</p>"},{"location":"api/predictors/#pybasin.predictors.dbscan_clusterer.DBSCANClusterer","title":"pybasin.predictors.dbscan_clusterer.DBSCANClusterer","text":"<p>               Bases: <code>ClustererPredictor</code></p> <p>DBSCAN clustering for basin stability analysis (unsupervised learning).</p>"},{"location":"api/predictors/#pybasin.predictors.dbscan_clusterer.DBSCANClusterer-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.dbscan_clusterer.DBSCANClusterer.__init__","title":"__init__","text":"<pre><code>__init__(clusterer: DBSCAN | None = None, **kwargs: Any)\n</code></pre> <p>Initialize DBSCAN clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>clusterer</code> <code>DBSCAN | None</code> <p>DBSCAN instance, or None to create default.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for DBSCAN if clusterer is None.</p> <code>{}</code>"},{"location":"api/predictors/#pybasin.predictors.dbscan_clusterer.DBSCANClusterer.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels using DBSCAN clustering.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array to cluster.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Cluster labels.</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer","title":"pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer","text":"<p>               Bases: <code>ClustererPredictor</code></p> <p>Two-stage hierarchical clustering for dynamical systems.</p> <p>This clusterer uses physics-based heuristics to classify trajectories into attractor types (Stage 1) and then sub-classifies within each type (Stage 2).</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer--stage-1-attractor-type-classification","title":"Stage 1: Attractor Type Classification","text":"<p>Fixed Point (FP) Detection:     Heuristic: variance &lt; fp_variance_threshold</p> <pre><code>A trajectory is classified as converging to a fixed point if the variance\nof its steady-state values is extremely low. The threshold should be set\nbased on the expected numerical precision of your integration.\n\nIMPORTANT: If features are normalized/scaled (e.g., StandardScaler), the\nvariance values will be transformed. For normalized features with unit\nvariance, use a threshold relative to 1.0 (e.g., 1e-4). For unnormalized\nfeatures, use absolute thresholds based on your system's scale.\n</code></pre> <p>Limit Cycle (LC) Detection:     Heuristic: (periodicity_strength &gt; lc_periodicity_threshold AND                variance &lt; chaos_variance_threshold) OR has_drift</p> <pre><code>A trajectory is classified as a limit cycle if:\n1. It shows strong periodic behavior (high autocorrelation periodicity)\n   AND has bounded variance (not chaotic), OR\n2. It shows monotonic drift (rotating solutions like pendulum rotations)\n\nThe periodicity_strength comes from autocorrelation analysis and ranges\nfrom 0 (no periodicity) to 1 (perfect periodicity). Values above 0.5\ntypically indicate clear periodic behavior.\n</code></pre> <p>Chaos Detection:     Heuristic: NOT FP AND NOT LC (default fallback)</p> <pre><code>Trajectories that don't meet FP or LC criteria are classified as chaotic.\nHigh variance combined with low periodicity strength indicates chaos.\n</code></pre>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer--stage-2-sub-classification","title":"Stage 2: Sub-classification","text":"<p>Within each attractor type, trajectories are further clustered: - FP: Clustered by steady-state location (mean values) - LC: Hierarchically clustered by period number, then amplitude/mean - Chaos: Clustered by spatial mean location</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer--required-features","title":"Required Features","text":"<p>Feature names must follow the convention: state_X__feature_name</p> <p>Required base features:     - variance: Steady-state variance (FP detection)     - amplitude: Peak-to-peak amplitude (LC sub-classification)     - mean: Steady-state mean (FP/chaos sub-classification)     - linear_trend__attr_slope: Linear drift rate (rotating LC detection)     - autocorrelation_periodicity__output_strength: Periodicity measure [0-1]     - autocorrelation_periodicity__output_period: Detected period     - spectral_frequency_ratio: Ratio for period-n detection</p> <p>Note: This clusterer requires feature names to be set via set_feature_names() before calling predict_labels(). The BasinStabilityEstimator handles this automatically during the estimation process.</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer.__init__","title":"__init__","text":"<pre><code>__init__(\n    drift_threshold: float = 0.1,\n    tiers: list[str] | None = None,\n    fp_variance_threshold: float = 1e-06,\n    fp_sub_classifier: LabelPredictor | None = None,\n    lc_periodicity_threshold: float = 0.5,\n    lc_sub_classifier: LabelPredictor | None = None,\n    chaos_variance_threshold: float = 5.0,\n    chaos_sub_classifier: LabelPredictor | None = None,\n)\n</code></pre> <p>Initialize the dynamical system clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>drift_threshold</code> <code>float</code> <p>Minimum |slope| to consider a dimension as drifting. Drifting dimensions (e.g., pendulum angle during rotation) are excluded from variance/mean calculations for FP and chaos sub-classification to avoid spurious splits. Also used to detect rotating limit cycles. Units: [state_units / time_units]. Default: 0.1.</p> <code>0.1</code> <code>tiers</code> <code>list[str] | None</code> <p>List of attractor types to detect, in priority order. First matching tier wins. Options: \"FP\", \"LC\", \"chaos\". Default: [\"FP\", \"LC\", \"chaos\"].</p> <code>None</code> <code>fp_variance_threshold</code> <code>float</code> <p>Maximum variance to classify as fixed point. For unnormalized features, set based on expected steady-state fluctuations (e.g., 1e-6 for well-converged integrations). For normalized features (unit variance), use relative threshold (e.g., 1e-4 meaning 0.01% of typical variance). Default: 1e-6.</p> <code>1e-06</code> <code>fp_sub_classifier</code> <code>LabelPredictor | None</code> <p>Custom sub-classifier for fixed points. Input: mean values per non-drifting dimension. Default: HDBSCAN with min_cluster_size=50.</p> <code>None</code> <code>lc_periodicity_threshold</code> <code>float</code> <p>Minimum periodicity strength [0-1] to classify as limit cycle. The periodicity strength measures how well the autocorrelation matches periodic behavior (0.0 = no periodic pattern, 0.3-0.5 = weak/noisy, 0.5-0.8 = clear periodic, 0.8-1.0 = strong/clean limit cycle). Default: 0.5.</p> <code>0.5</code> <code>lc_sub_classifier</code> <code>LabelPredictor | None</code> <p>Custom sub-classifier for limit cycles. Input: [freq_ratio, amplitude, mean] features. Default: Hierarchical period-based clustering.</p> <code>None</code> <code>chaos_variance_threshold</code> <code>float</code> <p>Maximum variance for limit cycle. Trajectories with variance above this AND low periodicity are classified as chaotic. Set based on expected LC amplitude range. For normalized features, typical LC variance is ~0.5-2.0. Default: 5.0.</p> <code>5.0</code> <code>chaos_sub_classifier</code> <code>LabelPredictor | None</code> <p>Custom sub-classifier for chaotic attractors. Input: mean values per dimension. Default: HDBSCAN with auto_tune=True.</p> <code>None</code>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer.needs_feature_names","title":"needs_feature_names","text":"<pre><code>needs_feature_names() -&gt; bool\n</code></pre> <p>This clusterer requires feature names to parse physics-based features.</p>"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer.set_feature_names","title":"set_feature_names","text":"<pre><code>set_feature_names(feature_names: list[str]) -&gt; None\n</code></pre> <p>Set feature names and build feature indices.</p> <p>Parameters:</p> Name Type Description Default <code>feature_names</code> <code>list[str]</code> <p>List of feature names matching the feature array columns.</p> required"},{"location":"api/predictors/#pybasin.predictors.dynamical_system_clusterer.DynamicalSystemClusterer.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels using two-stage hierarchical clustering.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array of shape (n_samples, n_features).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of predicted labels with format \"TYPE_subcluster\".</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If set_feature_names() was not called before prediction.</p>"},{"location":"api/predictors/#pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer","title":"pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer","text":"<p>               Bases: <code>ClustererPredictor</code></p> <p>Meta-clusterer for separately labeling unbounded trajectories.</p> <p>This meta-clusterer wraps another ClustererPredictor and handles unbounded trajectories separately. Unbounded trajectories are identified using a detector function and assigned a special label, while bounded trajectories are processed using the wrapped clusterer.</p> <p>This is particularly useful in basin stability calculations where some trajectories may diverge to infinity (e.g., in the Lorenz system). By excluding unbounded trajectories from clustering, the wrapped clusterer can focus on discovering patterns in bounded basins without contamination from divergent trajectories.</p> <p>Example usage:</p> <pre><code>from pybasin.predictors.unboundedness_clusterer import UnboundednessClusterer\nfrom pybasin.predictors.hdbscan_clusterer import HDBSCANClusterer\nimport numpy as np\n\n# Create features with some unbounded samples\nfeatures = np.random.randn(100, 10)\nfeatures[0, :] = np.inf  # Unbounded sample\nfeatures[1, :] = 1e10  # Unbounded sample\n\n# Wrap HDBSCAN with unboundedness handling\nbase_clusterer = HDBSCANClusterer(min_cluster_size=5)\nclusterer = UnboundednessClusterer(base_clusterer)\nlabels = clusterer.predict_labels(features)\nprint(f\"Unbounded samples: {np.sum(labels == 'unbounded')}\")\n</code></pre> <p>Notes:</p> <ul> <li>Only bounded samples are passed to the wrapped clusterer for clustering</li> <li>The unbounded label is automatically tracked and returned for unbounded samples</li> <li>If all samples are unbounded, all labels will be the unbounded label</li> <li>This prevents unbounded trajectories from distorting cluster centroids and boundaries</li> </ul> <p>Attributes:</p> Name Type Description <code>clusterer</code> <p>The wrapped clusterer instance.</p> <code>unbounded_detector</code> <p>Function used to detect unbounded trajectories.</p> <code>unbounded_label</code> <p>Label assigned to unbounded trajectories.</p>"},{"location":"api/predictors/#pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer.__init__","title":"__init__","text":"<pre><code>__init__(\n    clusterer: ClustererPredictor,\n    unbounded_detector: Callable[[ndarray], ndarray]\n    | None = None,\n    unbounded_label: int | str = \"unbounded\",\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize the unboundedness meta-clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>clusterer</code> <code>ClustererPredictor</code> <p>Base clusterer to use for bounded trajectories.</p> required <code>unbounded_detector</code> <code>Callable[[ndarray], ndarray] | None</code> <p>Function to detect unbounded trajectories.</p> <code>None</code> <code>unbounded_label</code> <code>int | str</code> <p>Label to assign to unbounded trajectories.</p> <code>'unbounded'</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments passed to ClustererPredictor base (unused).</p> <code>{}</code>"},{"location":"api/predictors/#pybasin.predictors.unboundedness_clusterer.UnboundednessClusterer.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels for features, separating unbounded trajectories.</p> <p>Unbounded trajectories are detected and labeled separately, while bounded trajectories are clustered using the wrapped clusterer.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array of shape (n_samples, n_features).</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Array of predicted labels with unbounded trajectories labeled separately.</p>"},{"location":"api/predictors/#pybasin.predictors.knn_classifier.KNNClassifier","title":"pybasin.predictors.knn_classifier.KNNClassifier","text":"<p>               Bases: <code>ClassifierPredictor</code></p> <p>K-Nearest Neighbors classifier for basin stability analysis (supervised learning).</p>"},{"location":"api/predictors/#pybasin.predictors.knn_classifier.KNNClassifier-functions","title":"Functions","text":""},{"location":"api/predictors/#pybasin.predictors.knn_classifier.KNNClassifier.__init__","title":"__init__","text":"<pre><code>__init__(\n    classifier: KNeighborsClassifier | None,\n    template_y0: list[list[float]],\n    labels: list[str],\n    ode_params: Mapping[str, Any],\n    solver: SolverProtocol | None = None,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize KNN classifier.</p> <p>Parameters:</p> Name Type Description Default <code>classifier</code> <code>KNeighborsClassifier | None</code> <p>KNeighborsClassifier instance, or None to create default.</p> required <code>template_y0</code> <code>list[list[float]]</code> <p>Template initial conditions as a list of lists.</p> required <code>labels</code> <code>list[str]</code> <p>Ground truth labels.</p> required <code>ode_params</code> <code>Mapping[str, Any]</code> <p>ODE parameters.</p> required <code>solver</code> <code>SolverProtocol | None</code> <p>Optional solver for template integration.</p> <code>None</code> <code>kwargs</code> <code>Any</code> <p>Additional arguments for KNeighborsClassifier if classifier is None.</p> <code>{}</code>"},{"location":"api/predictors/#pybasin.predictors.knn_classifier.KNNClassifier.predict_labels","title":"predict_labels","text":"<pre><code>predict_labels(features: ndarray) -&gt; np.ndarray\n</code></pre> <p>Predict labels using the fitted KNN classifier.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>ndarray</code> <p>Feature array to classify.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>Predicted labels.</p>"},{"location":"api/samplers/","title":"Samplers","text":""},{"location":"api/samplers/#pybasin.sampler.Sampler","title":"pybasin.sampler.Sampler","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for sampling initial conditions using PyTorch.</p>"},{"location":"api/samplers/#pybasin.sampler.Sampler-functions","title":"Functions","text":""},{"location":"api/samplers/#pybasin.sampler.Sampler.__init__","title":"__init__","text":"<pre><code>__init__(\n    min_limits: list[float],\n    max_limits: list[float],\n    device: str | None = None,\n)\n</code></pre> <p>Initialize the sampler.</p> <p>Parameters:</p> Name Type Description Default <code>min_limits</code> <code>list[float]</code> <p>List of minimum values for each state.</p> required <code>max_limits</code> <code>list[float]</code> <p>List of maximum values for each state.</p> required <code>device</code> <code>str | None</code> <p>Device to use ('cuda', 'cpu', or None for auto-detect).</p> <code>None</code>"},{"location":"api/samplers/#pybasin.sampler.Sampler.sample","title":"sample  <code>abstractmethod</code>","text":"<pre><code>sample(n: int) -&gt; torch.Tensor\n</code></pre> <p>Generate n samples for the initial conditions.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of samples.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>Sampled initial conditions as a tensor of shape (n, state_dim).</p>"},{"location":"api/samplers/#pybasin.sampler.UniformRandomSampler","title":"pybasin.sampler.UniformRandomSampler","text":"<p>               Bases: <code>Sampler</code></p> <p>Generates random samples using a uniform distribution within the specified range.</p>"},{"location":"api/samplers/#pybasin.sampler.GridSampler","title":"pybasin.sampler.GridSampler","text":"<p>               Bases: <code>Sampler</code></p> <p>Generates evenly spaced samples in a grid pattern within the specified range.</p> <p>Handles fixed dimensions (where min == max) by only distributing grid points along varying dimensions. For example, with limits [-10, 10], [-20, 20], [0, 0] and n=20000, the grid uses n^(1/2) \u2248 142 points per varying dimension (x, y) and a single point for the fixed dimension (z), yielding 142 x 142 x 1 = 20164 unique samples instead of 28 x 28 x 28 = 21952 with many duplicates.</p>"},{"location":"api/samplers/#pybasin.sampler.GaussianSampler","title":"pybasin.sampler.GaussianSampler","text":"<p>               Bases: <code>Sampler</code></p> <p>Generates samples using a Gaussian distribution around the midpoint.</p>"},{"location":"api/solution/","title":"Solution","text":""},{"location":"api/solution/#pybasin.solution.Solution","title":"pybasin.solution.Solution","text":"<p>Solution: Represents the time integration result for a single initial condition.</p> <p>This class stores:</p> <ul> <li>The initial condition used for integration.</li> <li>The time series result from integration.</li> <li>Features extracted from the trajectory.</li> <li>Optional labels/classification for each trajectory.</li> <li>Optional model parameters that were used in the integration.</li> <li>Optional bifurcation amplitudes extracted from the trajectory.</li> </ul> <p>Attributes:</p> Name Type Description <code>initial_condition</code> <code>Tensor</code> <p>The initial condition used for integration (shape: B, S).</p> <code>time</code> <code>Tensor</code> <p>Time points of the solution (shape: N).</p> <code>y</code> <code>Tensor</code> <p>State values over time (shape: N, B, S).</p> <code>features</code> <code>Tensor | None</code> <p>Filtered features used for classification.</p> <code>extracted_features</code> <code>Tensor | None</code> <p>Original extracted features before filtering.</p> <code>extracted_feature_names</code> <code>list[str] | None</code> <p>Names of extracted features.</p> <code>filtered_feature_names</code> <code>list[str] | None</code> <p>Names of filtered features.</p> <code>labels</code> <code>ndarray | None</code> <p>Labels assigned to each solution in the batch.</p> <code>model_params</code> <code>dict[str, Any] | None</code> <p>Parameters of the ODE model.</p> <code>bifurcation_amplitudes</code> <code>Tensor | None</code> <p>Maximum absolute values along time dimension.</p>"},{"location":"api/solution/#pybasin.solution.Solution-functions","title":"Functions","text":""},{"location":"api/solution/#pybasin.solution.Solution.__init__","title":"__init__","text":"<pre><code>__init__(\n    initial_condition: Tensor,\n    time: Tensor,\n    y: Tensor,\n    features: Tensor | None = None,\n    labels: ndarray | None = None,\n    model_params: dict[str, float] | None = None,\n)\n</code></pre> <p>Initialize the Solution object.</p> <p>Parameters:</p> Name Type Description Default <code>initial_condition</code> <code>Tensor</code> <p>shape: (B, S) =&gt; B batches, S state variables</p> required <code>time</code> <code>Tensor</code> <p>shape: (N,) =&gt; N time points</p> required <code>y</code> <code>Tensor</code> <p>shape: (N, B, S) =&gt; N time points, B batches, S state variables</p> required <code>features</code> <code>Tensor | None</code> <p>Optional features describing the trajectory.</p> <code>None</code> <code>labels</code> <code>ndarray | None</code> <p>Optional classification labels for the solutions.</p> <code>None</code> <code>model_params</code> <code>dict[str, float] | None</code> <p>Optional dictionary of model parameters used in the simulation.</p> <code>None</code>"},{"location":"api/solution/#pybasin.solution.Solution.set_labels","title":"set_labels","text":"<pre><code>set_labels(labels: ndarray)\n</code></pre> <p>Assign a label to this solution.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>ndarray</code> <p>The label to assign from the classification results.</p> required"},{"location":"api/solution/#pybasin.solution.Solution.set_extracted_features","title":"set_extracted_features","text":"<pre><code>set_extracted_features(features: Tensor, names: list[str])\n</code></pre> <p>Store extracted features before filtering.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>Tensor</code> <p>Extracted feature tensor.</p> required <code>names</code> <code>list[str]</code> <p>List of feature names.</p> required"},{"location":"api/solution/#pybasin.solution.Solution.set_features","title":"set_features","text":"<pre><code>set_features(\n    features: Tensor, names: list[str] | None = None\n)\n</code></pre> <p>Store features extracted from the trajectory.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>Tensor</code> <p>A feature vector describing the solution (typically filtered).</p> required <code>names</code> <code>list[str] | None</code> <p>Optional list of feature names (for filtered features).</p> <code>None</code>"},{"location":"api/solution/#pybasin.solution.Solution.get_summary","title":"get_summary","text":"<pre><code>get_summary() -&gt; dict[str, Any]\n</code></pre> <p>Return a summary of the solution.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>Dictionary with key information about the solution.</p>"},{"location":"api/solvers/","title":"Solvers","text":""},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver","title":"pybasin.solvers.jax_solver.JaxSolver","text":"<p>High-performance ODE solver using JAX and Diffrax for native JAX ODE systems.</p> <p>This solver is optimized for JaxODESystem instances and provides the fastest integration performance by avoiding any PyTorch callbacks. It uses JIT compilation and vmap for efficient batch processing.</p> <p>The interface is compatible with other solvers - it accepts PyTorch tensors and returns PyTorch tensors, but internally uses JAX for maximum performance.</p> <p>See also: Diffrax documentation</p> <p>Citation:</p> <pre><code>@phdthesis{kidger2021on,\n    title={{O}n {N}eural {D}ifferential {E}quations},\n    author={Patrick Kidger},\n    year={2021},\n    school={University of Oxford},\n}\n</code></pre> <p>Example usage:</p> <pre><code>from pybasin.jax_ode_system import JaxODESystem\nfrom pybasin.solvers import JaxSolver\nimport torch\n\nclass MyODE(JaxODESystem):\n    def ode(self, t, y):\n        return -y  # Simple decay\n    def get_str(self):\n        return \"decay\"\n\nsolver = JaxSolver(time_span=(0, 10), n_steps=100)\ny0 = torch.tensor([[1.0, 2.0]])  # batch=1, dims=2\nt, y = solver.integrate(MyODE({}), y0)\n</code></pre>"},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver-functions","title":"Functions","text":""},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver.__init__","title":"__init__","text":"<pre><code>__init__(\n    time_span: tuple[float, float] = (0, 1000),\n    n_steps: int | None = 1000,\n    device: str | None = None,\n    solver: Any | None = None,\n    rtol: float = 1e-08,\n    atol: float = 1e-06,\n    max_steps: int = 16**5,\n    use_cache: bool = True,\n    event_fn: Callable[[Any, Array, Any], Array]\n    | None = None,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize JaxSolver.</p> <p>Parameters:</p> Name Type Description Default <code>time_span</code> <code>tuple[float, float]</code> <p>Tuple (t_start, t_end) defining the integration interval. Defaults to (0, 1000).</p> <code>(0, 1000)</code> <code>n_steps</code> <code>int | None</code> <p>Number of evaluation points. Defaults to 1000.</p> <code>1000</code> <code>device</code> <code>str | None</code> <p>Device to use ('cuda', 'gpu', 'cpu', or None for auto-detect).</p> <code>None</code> <code>solver</code> <code>Any | None</code> <p>Diffrax solver instance (e.g., Dopri5(), Tsit5()). Defaults to Dopri5().</p> <code>None</code> <code>rtol</code> <code>float</code> <p>Relative tolerance for adaptive stepping. Defaults to 1e-8.</p> <code>1e-08</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for adaptive stepping. Defaults to 1e-6.</p> <code>1e-06</code> <code>max_steps</code> <code>int</code> <p>Maximum number of steps for the integrator.</p> <code>16 ** 5</code> <code>use_cache</code> <code>bool</code> <p>Whether to use caching for integration results. Defaults to True.</p> <code>True</code> <code>event_fn</code> <code>Callable[[Any, Array, Any], Array] | None</code> <p>Optional event function for early termination. Should return positive when integration should continue, negative/zero to stop. Signature: (t, y, args) -&gt; scalar Array.</p> <code>None</code>"},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver.with_device","title":"with_device","text":"<pre><code>with_device(device: str) -&gt; JaxSolver\n</code></pre> <p>Create a copy of this solver configured for a different device.</p> <p>Parameters:</p> Name Type Description Default <code>device</code> <code>str</code> <p>Target device ('cpu', 'cuda', 'gpu').</p> required <p>Returns:</p> Type Description <code>JaxSolver</code> <p>New JaxSolver instance with the same configuration but different device.</p>"},{"location":"api/solvers/#pybasin.solvers.jax_solver.JaxSolver.integrate","title":"integrate","text":"<pre><code>integrate(\n    ode_system: ODESystemProtocol, y0: Tensor\n) -&gt; tuple[torch.Tensor, torch.Tensor]\n</code></pre> <p>Solve the ODE system and return the evaluation time points and solution.</p> <p>Parameters:</p> Name Type Description Default <code>ode_system</code> <code>ODESystemProtocol</code> <p>An instance of JaxODESystem.</p> required <code>y0</code> <code>Tensor</code> <p>Initial conditions as PyTorch tensor with shape (batch, n_dims).</p> required <p>Returns:</p> Type Description <code>tuple[Tensor, Tensor]</code> <p>Tuple (t_eval, y_values) as PyTorch tensors where y_values has shape (n_steps, batch, n_dims).</p>"},{"location":"api/solvers/#pybasin.solver.TorchDiffEqSolver","title":"pybasin.solver.TorchDiffEqSolver","text":"<p>               Bases: <code>Solver</code></p> <p>Differentiable ODE solver with full GPU support and O(1)-memory backpropagation.</p> <p>Uses the adjoint method for memory-efficient gradient computation through ODE solutions. Supports adaptive-step (dopri5, dopri8, bosh3) and fixed-step (euler, rk4) methods.</p> <p>See also: torchdiffeq GitHub</p> <p>Citation:</p> <pre><code>@misc{torchdiffeq,\n    author={Chen, Ricky T. Q.},\n    title={torchdiffeq},\n    year={2018},\n    url={https://github.com/rtqichen/torchdiffeq},\n}\n</code></pre>"},{"location":"api/solvers/#pybasin.solver.TorchDiffEqSolver-functions","title":"Functions","text":""},{"location":"api/solvers/#pybasin.solver.TorchDiffEqSolver.__init__","title":"__init__","text":"<pre><code>__init__(\n    time_span: tuple[float, float],\n    fs: float | None = None,\n    n_steps: int | None = None,\n    device: str | None = None,\n    method: str = \"dopri5\",\n    rtol: float = 1e-08,\n    atol: float = 1e-06,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize TorchDiffEqSolver.</p> <p>Parameters:</p> Name Type Description Default <code>time_span</code> <code>tuple[float, float]</code> <p>Tuple (t_start, t_end) defining the integration interval.</p> required <code>fs</code> <code>float | None</code> <p>Sampling frequency (Hz). DEPRECATED: use n_steps instead.</p> <code>None</code> <code>n_steps</code> <code>int | None</code> <p>Number of evaluation points. If None, defaults to 500.</p> <code>None</code> <code>device</code> <code>str | None</code> <p>Device to use ('cuda', 'cpu', or None for auto-detect).</p> <code>None</code> <code>method</code> <code>str</code> <p>Integration method from tordiffeq.odeint.</p> <code>'dopri5'</code> <code>rtol</code> <code>float</code> <p>Relative tolerance for adaptive stepping.</p> <code>1e-08</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for adaptive stepping.</p> <code>1e-06</code>"},{"location":"api/solvers/#pybasin.solver.TorchDiffEqSolver.with_device","title":"with_device","text":"<pre><code>with_device(device: str) -&gt; TorchDiffEqSolver\n</code></pre> <p>Create a copy of this solver configured for a different device.</p>"},{"location":"api/solvers/#pybasin.solver.TorchOdeSolver","title":"pybasin.solver.TorchOdeSolver","text":"<p>               Bases: <code>Solver</code></p> <p>Parallel ODE solver with independent step sizes per batch element.</p> <p>Compatible with PyTorch's JIT compiler for performance optimization. Unlike other solvers, torchode can take different step sizes for each sample in a batch, avoiding performance traps for problems of varying stiffness.</p> <p>See also: torchode documentation</p> <p>Citation:</p> <pre><code>@inproceedings{lienen2022torchode,\n    title = {torchode: A Parallel {ODE} Solver for PyTorch},\n    author = {Marten Lienen and Stephan G{\"u}nnemann},\n    booktitle = {The Symbiosis of Deep Learning and Differential Equations II, NeurIPS},\n    year = {2022},\n    url = {https://openreview.net/forum?id=uiKVKTiUYB0}\n}\n</code></pre>"},{"location":"api/solvers/#pybasin.solver.TorchOdeSolver-functions","title":"Functions","text":""},{"location":"api/solvers/#pybasin.solver.TorchOdeSolver.__init__","title":"__init__","text":"<pre><code>__init__(\n    time_span: tuple[float, float],\n    fs: float | None = None,\n    n_steps: int | None = None,\n    device: str | None = None,\n    method: str = \"dopri5\",\n    rtol: float = 1e-08,\n    atol: float = 1e-06,\n    use_jit: bool = False,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize TorchOdeSolver.</p> <p>Parameters:</p> Name Type Description Default <code>time_span</code> <code>tuple[float, float]</code> <p>Tuple (t_start, t_end) defining the integration interval.</p> required <code>fs</code> <code>float | None</code> <p>Sampling frequency (Hz). DEPRECATED: use n_steps instead.</p> <code>None</code> <code>n_steps</code> <code>int | None</code> <p>Number of evaluation points. If None, defaults to 500.</p> <code>None</code> <code>device</code> <code>str | None</code> <p>Device to use ('cuda', 'cpu', or None for auto-detect).</p> <code>None</code> <code>method</code> <code>str</code> <p>Integration method ('dopri5', 'tsit5', 'euler', 'heun').</p> <code>'dopri5'</code> <code>rtol</code> <code>float</code> <p>Relative tolerance for adaptive stepping.</p> <code>1e-08</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for adaptive stepping.</p> <code>1e-06</code> <code>use_jit</code> <code>bool</code> <p>Whether to use JIT compilation (can improve performance).</p> <code>False</code>"},{"location":"api/solvers/#pybasin.solver.TorchOdeSolver.with_device","title":"with_device","text":"<pre><code>with_device(device: str) -&gt; TorchOdeSolver\n</code></pre> <p>Create a copy of this solver configured for a different device.</p>"},{"location":"api/solvers/#pybasin.solver.SklearnParallelSolver","title":"pybasin.solver.SklearnParallelSolver","text":"<p>               Bases: <code>Solver</code></p> <p>ODE solver using sklearn's parallel processing with scipy's solve_ivp.</p> <p>Uses multiprocessing (loky backend) to solve multiple initial conditions in parallel. Each worker solves one trajectory at a time using scipy's solve_ivp.</p> <p>See also: scipy.integrate.solve_ivp</p>"},{"location":"api/solvers/#pybasin.solver.SklearnParallelSolver-functions","title":"Functions","text":""},{"location":"api/solvers/#pybasin.solver.SklearnParallelSolver.__init__","title":"__init__","text":"<pre><code>__init__(\n    time_span: tuple[float, float],\n    fs: float,\n    device: str | None = None,\n    n_jobs: int = -1,\n    batch_size: int | None = None,\n    method: str = \"RK45\",\n    rtol: float = 1e-06,\n    atol: float = 1e-08,\n    max_step: float | None = None,\n    **kwargs: Any,\n)\n</code></pre> <p>Initialize SklearnParallelSolver.</p> <p>Parameters:</p> Name Type Description Default <code>time_span</code> <code>tuple[float, float]</code> <p>Integration interval (t_start, t_end).</p> required <code>fs</code> <code>float</code> <p>Sampling frequency (Hz).</p> required <code>device</code> <code>str | None</code> <p>Device to use (only 'cpu' supported).</p> <code>None</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs (-1 for all CPUs).</p> <code>-1</code> <code>batch_size</code> <code>int | None</code> <p>Unused, kept for API compatibility.</p> <code>None</code> <code>method</code> <code>str</code> <p>Integration method ('RK45', 'RK23', 'DOP853', 'Radau', 'BDF', 'LSODA', etc).</p> <code>'RK45'</code> <code>rtol</code> <code>float</code> <p>Relative tolerance for the solver.</p> <code>1e-06</code> <code>atol</code> <code>float</code> <p>Absolute tolerance for the solver.</p> <code>1e-08</code> <code>max_step</code> <code>float | None</code> <p>Maximum step size for the solver.</p> <code>None</code>"},{"location":"api/solvers/#pybasin.solver.SklearnParallelSolver.with_device","title":"with_device","text":"<pre><code>with_device(device: str) -&gt; SklearnParallelSolver\n</code></pre> <p>Create a copy of this solver configured for a different device.</p> <p>Note: SklearnParallelSolver only supports CPU, so this always returns a CPU solver.</p>"},{"location":"benchmarks/end-to-end/","title":"End-to-End Performance","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"benchmarks/end-to-end/#methodology","title":"Methodology","text":"<p>Compare full basin stability estimation times:</p> <ul> <li>Same ODE system (Pendulum)</li> <li>Same parameters (t_span, tolerances)</li> <li>Vary sample sizes: 10,000 / 50,000 / 100,000</li> </ul>"},{"location":"benchmarks/end-to-end/#implementations-compared","title":"Implementations Compared","text":"<ul> <li>MATLAB bSTAB-M (CPU)</li> <li>pyBasin + JaxSolver (CPU)</li> <li>pyBasin + JaxSolver (CUDA GPU)</li> </ul>"},{"location":"benchmarks/end-to-end/#results","title":"Results","text":"Samples MATLAB CPU pyBasin CPU pyBasin GPU GPU Speedup 10,000 ~11.3s ~9.3s ~11.7s 0.97x 100,000 ~122s ~56s ~11.7s 10.4x"},{"location":"benchmarks/end-to-end/#key-finding","title":"Key Finding","text":"<p>GPU time is nearly constant regardless of sample size due to parallelization.</p>"},{"location":"benchmarks/feature-extraction/","title":"Feature Extraction Benchmarks","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"benchmarks/feature-extraction/#implementations-compared","title":"Implementations Compared","text":"<ul> <li>tsfresh (reference, CPU)</li> <li>TorchFeatureExtractor (CPU parallel)</li> <li>TorchFeatureExtractor (CUDA GPU)</li> </ul>"},{"location":"benchmarks/feature-extraction/#results","title":"Results","text":"Backend Mode Device 10k batches time tsfresh parallel cpu 34,465 ms PyTorch parallel cpu 1,734 ms PyTorch sequential cpu 3,464 ms PyTorch gpu cuda 7,702 ms"},{"location":"benchmarks/feature-extraction/#key-finding","title":"Key Finding","text":"<p>PyTorch CPU parallel is ~20x faster than tsfresh.</p>"},{"location":"benchmarks/feature-extraction/#feature-accuracy","title":"Feature Accuracy","text":"<p>All features validated against tsfresh reference values.</p>"},{"location":"benchmarks/overview/","title":"Benchmarks Overview","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"benchmarks/overview/#purpose","title":"Purpose","text":"<p>Compare pyBasin performance against MATLAB bSTAB-M and evaluate different solver and feature extraction backends.</p>"},{"location":"benchmarks/overview/#test-hardware","title":"Test Hardware","text":"<ul> <li>CPU: (specify)</li> <li>GPU: (specify)</li> <li>Memory: (specify)</li> </ul>"},{"location":"benchmarks/overview/#key-findings","title":"Key Findings","text":"Benchmark pyBasin vs MATLAB Notes Solver (CPU) ~10-15x faster Dopri5 methods Solver (GPU) ~10x faster At 100k samples Feature Extraction ~20x faster PyTorch vs tsfresh End-to-End (GPU, 100k) ~10x faster Full BS estimation"},{"location":"benchmarks/overview/#detailed-results","title":"Detailed Results","text":"<ul> <li>End-to-End Performance</li> <li>Solver Comparison</li> <li>Feature Extraction</li> </ul>"},{"location":"benchmarks/solvers/","title":"Solver Comparison","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"benchmarks/solvers/#test-configuration","title":"Test Configuration","text":"<ul> <li>ODE: Driven damped pendulum</li> <li>t_span: (0, 1000)</li> <li>n_steps: 1000</li> <li>Tolerances: rtol=1e-8, atol=1e-6</li> </ul>"},{"location":"benchmarks/solvers/#results","title":"Results","text":"Solver Device Time (s) ms/integration Speedup vs MATLAB BS Valid torchdiffeq_rk4 cpu 0.156 0.016 779x \u274c torchdiffeq_dopri5 cpu 8.10 0.81 15x \u2705 jax_diffrax_dopri5 cpu 9.33 0.93 13x \u2705 matlab_ode45 cpu 11.33 1.13 baseline \u2705 jax_diffrax_dopri5 cuda 11.57 1.16 10.5x \u2705 jax_diffrax_tsit5 cpu 34.03 3.40 3.6x \u2705"},{"location":"benchmarks/solvers/#key-findings","title":"Key Findings","text":"<ul> <li>RK4 is fast but produces incorrect BS (insufficient accuracy)</li> <li>Dopri5 methods are ~10-15x faster than MATLAB ode45</li> <li>GPU benefit appears at larger sample sizes</li> </ul>"},{"location":"case-studies/duffing/","title":"Duffing Oscillator","text":""},{"location":"case-studies/duffing/#system-description","title":"System Description","text":"<p>Duffing oscillator with cubic nonlinearity:</p> \\[\\ddot{x} + \\delta \\dot{x} + \\alpha x + \\beta x^3 = \\gamma \\cos(\\omega t)\\]"},{"location":"case-studies/duffing/#attractors","title":"Attractors","text":"<ul> <li>y1-y5: Various n-cycle attractors (period-n oscillations)</li> </ul>"},{"location":"case-studies/duffing/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/duffing/#setup","title":"Setup","text":"<pre><code>def setup_duffing_oscillator_system() -&gt; SetupProperties:\n    n = 5000\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up Duffing oscillator system on device: {device}\")\n\n    params: DuffingParams = {\"delta\": 0.08, \"k3\": 1, \"A\": 0.2}\n    ode_system = DuffingJaxODE(params)\n\n    sampler = UniformRandomSampler(min_limits=[-1, -0.5], max_limits=[1, 1], device=device)\n\n    solver = JaxSolver(\n        time_span=(0, 1000),\n        n_steps=50000,\n        device=device,\n        rtol=1e-8,\n        atol=1e-6,\n        use_cache=True,\n    )\n\n    feature_extractor = TorchFeatureExtractor(\n        time_steady=900.0,\n        normalize=False,\n        features=None,\n        features_per_state={\n            0: {\"maximum\": None, \"standard_deviation\": None},\n        },\n    )\n\n    classifier_initial_conditions = [\n        [-0.21, 0.02],\n        [1.05, 0.77],\n        [-0.67, 0.02],\n        [-0.46, 0.30],\n        [-0.43, 0.12],\n    ]\n\n    classifier_labels = [\n        \"y1\",\n        \"y2\",\n        \"y3\",\n        \"y4\",\n        \"y5\",\n    ]\n\n    knn = KNeighborsClassifier(n_neighbors=1)\n\n    knn_cluster = KNNClassifier(\n        classifier=knn,\n        template_y0=classifier_initial_conditions,\n        labels=classifier_labels,\n        ode_params=params,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": knn_cluster,\n    }\n</code></pre>"},{"location":"case-studies/duffing/#main-estimation","title":"Main Estimation","text":"<p>File Not Found</p> <p>Could not find file: <code>case_studies/duffing_oscillator/main_duffing_case1.py</code></p>"},{"location":"case-studies/duffing/#case-1-baseline-results-supervised","title":"Case 1: Baseline Results (Supervised)","text":""},{"location":"case-studies/duffing/#comparison-with-matlab-bstab","title":"Comparison with MATLAB bSTAB","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence y1 0.1954 \u00b1 0.0056 0.1908 \u00b1 0.0056 0.58 0.5601 [-0.0109, 0.0201] \u2705\u00a0very_high y2 0.5104 \u00b1 0.0071 0.4994 \u00b1 0.0071 1.10 0.2713 [-0.0086, 0.0306] \u2705\u00a0very_high y3 0.0264 \u00b1 0.0023 0.0278 \u00b1 0.0023 0.43 0.6664 [-0.0078, 0.0050] \u2705\u00a0very_high y4 0.0264 \u00b1 0.0023 0.0220 \u00b1 0.0021 1.43 0.1522 [-0.0016, 0.0104] \u2705\u00a0very_high y5 0.2414 \u00b1 0.0061 0.2600 \u00b1 0.0062 2.15 0.0319 [-0.0356, -0.0016] \u26a0\ufe0f\u00a0moderate"},{"location":"case-studies/duffing/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/duffing/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/duffing/#state-space","title":"State Space","text":""},{"location":"case-studies/duffing/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/duffing/#case-2-unsupervised-clustering-with-template-relabeling","title":"Case 2: Unsupervised Clustering with Template Relabeling","text":"<p>This case demonstrates unsupervised attractor discovery using DBSCAN clustering, followed by relabeling using KNN template matching to assign meaningful attractor names.</p>"},{"location":"case-studies/duffing/#comparison-with-matlab-bstab_1","title":"Comparison with MATLAB bSTAB","text":"<p>Cluster Quality Metrics:</p> <ul> <li>Clusters found: 5 (expected: 5)</li> <li>Overall agreement: 100.0%</li> <li>Adjusted Rand Index: 1.0000</li> </ul> Attractor DBSCAN Purity pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value Confidence y1 1 100.0% 0.1954 \u00b1 0.0056 0.1908 \u00b1 0.0056 0.58 0.5601 \u2705\u00a0very_high y2 2 100.0% 0.5104 \u00b1 0.0071 0.4994 \u00b1 0.0071 1.10 0.2713 \u2705\u00a0very_high y3 4 100.0% 0.0264 \u00b1 0.0023 0.0278 \u00b1 0.0023 0.43 0.6664 \u2705\u00a0very_high y4 3 100.0% 0.0264 \u00b1 0.0023 0.0220 \u00b1 0.0021 1.43 0.1522 \u2705\u00a0very_high y5 0 100.0% 0.2414 \u00b1 0.0061 0.2600 \u00b1 0.0062 2.15 0.0319 \u26a0\ufe0f\u00a0moderate"},{"location":"case-studies/duffing/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/duffing/#basin-stability_1","title":"Basin Stability","text":""},{"location":"case-studies/duffing/#state-space_1","title":"State Space","text":""},{"location":"case-studies/duffing/#feature-space_1","title":"Feature Space","text":""},{"location":"case-studies/friction/","title":"Friction Oscillator","text":""},{"location":"case-studies/friction/#system-description","title":"System Description","text":"<p>Mass-spring-damper with friction:</p> \\[m\\ddot{x} + c\\dot{x} + kx = F_{friction}(v_{belt} - \\dot{x})\\]"},{"location":"case-studies/friction/#attractors","title":"Attractors","text":"<ul> <li>FP: Fixed point (stick state)</li> <li>LC: Limit cycle (stick-slip oscillation)</li> </ul>"},{"location":"case-studies/friction/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/friction/#setup","title":"Setup","text":"<pre><code>def setup_friction_system() -&gt; SetupProperties:\n    n = 5000\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up friction system on device: {device}\")\n\n    params: FrictionParams = {\n        \"v_d\": 1.5,  # Driving velocity\n        \"xi\": 0.05,  # Damping ratio\n        \"musd\": 2.0,  # Ratio static to dynamic friction coefficient\n        \"mud\": 0.5,  # Dynamic coefficient of friction\n        \"muv\": 0.0,  # Linear strengthening parameter\n        \"v0\": 0.5,  # Reference velocity for exponential decay\n    }\n\n    ode_system = FrictionJaxODE(params)\n\n    sampler = UniformRandomSampler(\n        min_limits=[-2.0, 0.0],\n        max_limits=[2.0, 2.0],\n        device=device,\n    )\n\n    solver = JaxSolver(\n        time_span=(0, 500),\n        n_steps=500,\n        device=device,\n        rtol=1e-8,\n        atol=1e-6,\n        use_cache=True,\n    )\n\n    feature_extractor = JaxFeatureExtractor(time_steady=400.0, normalize=False)\n\n    classifier_initial_conditions = [\n        [0.1, 0.1],\n        [2.0, 2.0],\n    ]\n\n    classifier_labels = [\"FP\", \"LC\"]\n\n    knn = KNeighborsClassifier(n_neighbors=1)\n\n    knn_cluster = KNNClassifier(\n        classifier=knn,\n        template_y0=classifier_initial_conditions,\n        labels=classifier_labels,\n        ode_params=params,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": knn_cluster,\n    }\n</code></pre>"},{"location":"case-studies/friction/#main-estimation","title":"Main Estimation","text":"<pre><code>def main():\n    props = setup_friction_system()\n\n    bse = BasinStabilityEstimator(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=props.get(\"solver\"),\n        feature_extractor=props.get(\"feature_extractor\"),\n        predictor=props.get(\"cluster_classifier\"),\n        save_to=\"results_friction\",\n        feature_selector=None,\n    )\n\n    basin_stability = bse.estimate_bs()\n    print(\"Basin Stability:\", basin_stability)\n\n    # bse.save()\n\n    return bse\n</code></pre>"},{"location":"case-studies/friction/#case-1-baseline-results","title":"Case 1: Baseline Results","text":""},{"location":"case-studies/friction/#comparison-with-matlab-bstab","title":"Comparison with MATLAB bSTAB","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.3012 \u00b1 0.0065 0.3040 \u00b1 0.0065 0.30 0.7606 [-0.0208, 0.0152] \u2705\u00a0very_high LC 0.6988 \u00b1 0.0065 0.6960 \u00b1 0.0065 0.30 0.7606 [-0.0152, 0.0208] \u2705\u00a0very_high"},{"location":"case-studies/friction/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/friction/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/friction/#state-space","title":"State Space","text":""},{"location":"case-studies/friction/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/friction/#case-2-v_d-parameter-sweep","title":"Case 2: v_d Parameter Sweep","text":""},{"location":"case-studies/friction/#comparison-with-matlab-bstab_1","title":"Comparison with MATLAB bSTAB","text":""},{"location":"case-studies/friction/#parameter-18500","title":"Parameter = 1.8500","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/friction/#parameter-18750","title":"Parameter = 1.8750","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/friction/#parameter-19000","title":"Parameter = 1.9000","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/friction/#parameter-19250","title":"Parameter = 1.9250","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/friction/#parameter-19500","title":"Parameter = 1.9500","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/friction/#parameter-19750","title":"Parameter = 1.9750","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/friction/#parameter-20000","title":"Parameter = 2.0000","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/friction/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/friction/#basin-stability-variation","title":"Basin Stability Variation","text":""},{"location":"case-studies/friction/#bifurcation-diagram","title":"Bifurcation Diagram","text":""},{"location":"case-studies/lorenz/","title":"Lorenz System","text":""},{"location":"case-studies/lorenz/#system-description","title":"System Description","text":"<p>Lorenz \"broken butterfly\" attractor:</p> \\[\\dot{x} = \\sigma(y - x)$$ $$\\dot{y} = rx - y - xz$$ $$\\dot{z} = xy - bz\\]"},{"location":"case-studies/lorenz/#attractors","title":"Attractors","text":"<ul> <li>chaos y_1: Positive x wing (butterfly1)</li> <li>chaos y_2: Negative x wing (butterfly2)</li> <li>unbounded: Trajectories that escape to infinity</li> </ul>"},{"location":"case-studies/lorenz/#key-feature","title":"Key Feature","text":"<p>Demonstrates unboundedness detection with <code>event_fn</code>.</p>"},{"location":"case-studies/lorenz/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/lorenz/#setup","title":"Setup","text":"<pre><code>def setup_lorenz_system() -&gt; SetupProperties:\n    n = 20_000\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up Lorenz system on device: {device}\")\n\n    params: LorenzParams = {\"sigma\": 0.12, \"r\": 0.0, \"b\": -0.6}\n\n    ode_system = LorenzJaxODE(params)\n\n    sampler = UniformRandomSampler(\n        min_limits=[-10.0, -20.0, 0.0], max_limits=[10.0, 20.0, 0.0], device=device\n    )\n\n    solver = JaxSolver(\n        time_span=(0, 1000),\n        n_steps=4000,\n        device=device,\n        rtol=1e-8,\n        atol=1e-6,\n        use_cache=True,\n        event_fn=lorenz_stop_event,\n    )\n\n    feature_extractor = JaxFeatureExtractor(\n        time_steady=900.0,\n        normalize=False,\n        features_per_state={\n            0: {\"mean\": None},\n            1: None,\n            2: None,\n        },\n    )\n\n    classifier_initial_conditions = [\n        [0.8, -3.0, 0.0],\n        [-0.8, 3.0, 0.0],\n        [10.0, 50.0, 0.0],\n    ]\n\n    classifier_labels = [\"chaos y_1\", \"chaos y_2\", \"unbounded\"]\n\n    knn = KNeighborsClassifier(n_neighbors=1)\n\n    knn_cluster = KNNClassifier(\n        classifier=knn,\n        template_y0=classifier_initial_conditions,\n        labels=classifier_labels,\n        ode_params=params,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": knn_cluster,\n    }\n</code></pre>"},{"location":"case-studies/lorenz/#main-estimation","title":"Main Estimation","text":"<pre><code>def main():\n    props = setup_lorenz_system()\n\n    bse = BasinStabilityEstimator(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=props.get(\"solver\"),\n        feature_extractor=props.get(\"feature_extractor\"),\n        predictor=props.get(\"cluster_classifier\"),\n        save_to=\"results_case1\",\n        # feature_selector=None,\n    )\n\n    basin_stability = bse.estimate_bs()\n    print(\"Basin Stability:\", basin_stability)\n\n    # bse.save()\n\n    return bse\n</code></pre>"},{"location":"case-studies/lorenz/#case-1-baseline-results","title":"Case 1: Baseline Results","text":""},{"location":"case-studies/lorenz/#comparison-with-matlab-bstab","title":"Comparison with MATLAB bSTAB","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.0885 \u00b1 0.0020 0.0894 \u00b1 0.0020 0.32 0.7519 [-0.0065, 0.0047] \u2705\u00a0very_high chaos y_2 0.0869 \u00b1 0.0020 0.0874 \u00b1 0.0020 0.19 0.8454 [-0.0061, 0.0050] \u2705\u00a0very_high unbounded 0.8246 \u00b1 0.0027 0.8232 \u00b1 0.0027 0.38 0.7035 [-0.0060, 0.0089] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/lorenz/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/lorenz/#state-space","title":"State Space","text":""},{"location":"case-studies/lorenz/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/lorenz/#case-2-sigma-parameter-sweep","title":"Case 2: Sigma Parameter Sweep","text":""},{"location":"case-studies/lorenz/#comparison-with-matlab-bstab_1","title":"Comparison with MATLAB bSTAB","text":""},{"location":"case-studies/lorenz/#parameter-01200","title":"Parameter = 0.1200","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.0885 \u00b1 0.0020 0.0843 \u00b1 0.0020 1.49 0.1349 [-0.0013, 0.0097] \u2705\u00a0very_high chaos y_2 0.0869 \u00b1 0.0020 0.0859 \u00b1 0.0020 0.36 0.7219 [-0.0045, 0.0065] \u2705\u00a0very_high unbounded 0.8246 \u00b1 0.0027 0.8298 \u00b1 0.0027 1.38 0.1690 [-0.0126, 0.0022] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01225","title":"Parameter = 0.1225","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1008 \u00b1 0.0021 0.1019 \u00b1 0.0021 0.36 0.7156 [-0.0070, 0.0048] \u2705\u00a0very_high chaos y_2 0.1058 \u00b1 0.0022 0.1047 \u00b1 0.0022 0.36 0.7200 [-0.0049, 0.0071] \u2705\u00a0very_high unbounded 0.7933 \u00b1 0.0029 0.7933 \u00b1 0.0029 0.00 1.0000 [-0.0079, 0.0079] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01250","title":"Parameter = 0.1250","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1129 \u00b1 0.0022 0.1122 \u00b1 0.0022 0.24 0.8124 [-0.0054, 0.0069] \u2705\u00a0very_high chaos y_2 0.1112 \u00b1 0.0022 0.1139 \u00b1 0.0022 0.84 0.4017 [-0.0088, 0.0035] \u2705\u00a0very_high unbounded 0.7759 \u00b1 0.0029 0.7740 \u00b1 0.0030 0.45 0.6492 [-0.0063, 0.0101] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01275","title":"Parameter = 0.1275","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1148 \u00b1 0.0023 0.1140 \u00b1 0.0022 0.24 0.8137 [-0.0055, 0.0070] \u2705\u00a0very_high chaos y_2 0.1142 \u00b1 0.0022 0.1163 \u00b1 0.0023 0.66 0.5107 [-0.0084, 0.0042] \u2705\u00a0very_high unbounded 0.7711 \u00b1 0.0030 0.7697 \u00b1 0.0030 0.32 0.7482 [-0.0069, 0.0096] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01300","title":"Parameter = 0.1300","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1148 \u00b1 0.0023 0.1148 \u00b1 0.0023 0.02 0.9875 [-0.0063, 0.0062] \u2705\u00a0very_high chaos y_2 0.1111 \u00b1 0.0022 0.1138 \u00b1 0.0022 0.82 0.4105 [-0.0088, 0.0036] \u2705\u00a0very_high unbounded 0.7741 \u00b1 0.0030 0.7714 \u00b1 0.0030 0.63 0.5271 [-0.0056, 0.0109] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01325","title":"Parameter = 0.1325","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1176 \u00b1 0.0023 0.1080 \u00b1 0.0022 3.05 0.0023 [0.0035, 0.0158] \u274c\u00a0low chaos y_2 0.1134 \u00b1 0.0022 0.1127 \u00b1 0.0022 0.25 0.8005 [-0.0054, 0.0070] \u2705\u00a0very_high unbounded 0.7690 \u00b1 0.0030 0.7794 \u00b1 0.0029 2.50 0.0124 [-0.0186, -0.0023] \u26a0\ufe0f\u00a0moderate"},{"location":"case-studies/lorenz/#parameter-01350","title":"Parameter = 0.1350","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1137 \u00b1 0.0022 0.1105 \u00b1 0.0022 1.01 0.3104 [-0.0030, 0.0094] \u2705\u00a0very_high chaos y_2 0.1138 \u00b1 0.0022 0.1106 \u00b1 0.0022 1.00 0.3182 [-0.0030, 0.0093] \u2705\u00a0very_high unbounded 0.7725 \u00b1 0.0030 0.7789 \u00b1 0.0029 1.52 0.1279 [-0.0145, 0.0018] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01375","title":"Parameter = 0.1375","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1149 \u00b1 0.0023 0.1118 \u00b1 0.0022 0.99 0.3204 [-0.0031, 0.0094] \u2705\u00a0very_high chaos y_2 0.1138 \u00b1 0.0022 0.1126 \u00b1 0.0022 0.36 0.7166 [-0.0051, 0.0074] \u2705\u00a0very_high unbounded 0.7713 \u00b1 0.0030 0.7756 \u00b1 0.0029 1.03 0.3043 [-0.0125, 0.0039] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01400","title":"Parameter = 0.1400","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1127 \u00b1 0.0022 0.1123 \u00b1 0.0022 0.13 0.8992 [-0.0058, 0.0066] \u2705\u00a0very_high chaos y_2 0.1132 \u00b1 0.0022 0.1103 \u00b1 0.0022 0.94 0.3490 [-0.0032, 0.0091] \u2705\u00a0very_high unbounded 0.7742 \u00b1 0.0030 0.7775 \u00b1 0.0029 0.80 0.4218 [-0.0115, 0.0048] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01425","title":"Parameter = 0.1425","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1116 \u00b1 0.0022 0.1119 \u00b1 0.0022 0.08 0.9368 [-0.0064, 0.0059] \u2705\u00a0very_high chaos y_2 0.1130 \u00b1 0.0022 0.1092 \u00b1 0.0022 1.21 0.2266 [-0.0024, 0.0100] \u2705\u00a0very_high unbounded 0.7753 \u00b1 0.0030 0.7789 \u00b1 0.0029 0.85 0.3937 [-0.0117, 0.0046] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01450","title":"Parameter = 0.1450","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1110 \u00b1 0.0022 0.1143 \u00b1 0.0022 1.03 0.3040 [-0.0094, 0.0029] \u2705\u00a0very_high chaos y_2 0.1114 \u00b1 0.0022 0.1093 \u00b1 0.0022 0.69 0.4926 [-0.0040, 0.0083] \u2705\u00a0very_high unbounded 0.7775 \u00b1 0.0029 0.7764 \u00b1 0.0029 0.26 0.7916 [-0.0071, 0.0093] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01475","title":"Parameter = 0.1475","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1119 \u00b1 0.0022 0.1134 \u00b1 0.0022 0.49 0.6240 [-0.0077, 0.0046] \u2705\u00a0very_high chaos y_2 0.1140 \u00b1 0.0022 0.1122 \u00b1 0.0022 0.57 0.5698 [-0.0044, 0.0080] \u2705\u00a0very_high unbounded 0.7741 \u00b1 0.0030 0.7743 \u00b1 0.0030 0.06 0.9523 [-0.0084, 0.0079] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01500","title":"Parameter = 0.1500","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1110 \u00b1 0.0022 0.1139 \u00b1 0.0022 0.89 0.3754 [-0.0090, 0.0034] \u2705\u00a0very_high chaos y_2 0.1155 \u00b1 0.0023 0.1081 \u00b1 0.0022 2.33 0.0197 [0.0012, 0.0135] \u26a0\ufe0f\u00a0moderate unbounded 0.7734 \u00b1 0.0030 0.7780 \u00b1 0.0029 1.09 0.2753 [-0.0127, 0.0036] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01525","title":"Parameter = 0.1525","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1134 \u00b1 0.0022 0.1155 \u00b1 0.0023 0.64 0.5197 [-0.0083, 0.0042] \u2705\u00a0very_high chaos y_2 0.1163 \u00b1 0.0023 0.1116 \u00b1 0.0022 1.48 0.1392 [-0.0015, 0.0109] \u2705\u00a0very_high unbounded 0.7702 \u00b1 0.0030 0.7729 \u00b1 0.0030 0.63 0.5279 [-0.0109, 0.0056] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01550","title":"Parameter = 0.1550","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1119 \u00b1 0.0022 0.1112 \u00b1 0.0022 0.24 0.8117 [-0.0054, 0.0069] \u2705\u00a0very_high chaos y_2 0.1153 \u00b1 0.0023 0.1163 \u00b1 0.0023 0.34 0.7310 [-0.0074, 0.0052] \u2705\u00a0very_high unbounded 0.7728 \u00b1 0.0030 0.7724 \u00b1 0.0030 0.08 0.9335 [-0.0079, 0.0086] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01575","title":"Parameter = 0.1575","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1138 \u00b1 0.0022 0.1116 \u00b1 0.0022 0.68 0.4965 [-0.0040, 0.0083] \u2705\u00a0very_high chaos y_2 0.1151 \u00b1 0.0023 0.1092 \u00b1 0.0022 1.87 0.0615 [-0.0003, 0.0121] \u2705\u00a0high unbounded 0.7712 \u00b1 0.0030 0.7792 \u00b1 0.0029 1.93 0.0538 [-0.0162, 0.0001] \u2705\u00a0high"},{"location":"case-studies/lorenz/#parameter-01600","title":"Parameter = 0.1600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1147 \u00b1 0.0023 0.1142 \u00b1 0.0022 0.17 0.8628 [-0.0057, 0.0068] \u2705\u00a0very_high chaos y_2 0.1148 \u00b1 0.0023 0.1114 \u00b1 0.0022 1.09 0.2761 [-0.0028, 0.0097] \u2705\u00a0very_high unbounded 0.7704 \u00b1 0.0030 0.7744 \u00b1 0.0030 0.95 0.3400 [-0.0122, 0.0042] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01625","title":"Parameter = 0.1625","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1120 \u00b1 0.0022 0.1131 \u00b1 0.0022 0.35 0.7278 [-0.0073, 0.0051] \u2705\u00a0very_high chaos y_2 0.1155 \u00b1 0.0023 0.1157 \u00b1 0.0023 0.05 0.9626 [-0.0064, 0.0061] \u2705\u00a0very_high unbounded 0.7725 \u00b1 0.0030 0.7712 \u00b1 0.0030 0.30 0.7658 [-0.0070, 0.0095] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01650","title":"Parameter = 0.1650","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1124 \u00b1 0.0022 0.1114 \u00b1 0.0022 0.35 0.7271 [-0.0051, 0.0073] \u2705\u00a0very_high chaos y_2 0.1120 \u00b1 0.0022 0.1121 \u00b1 0.0022 0.03 0.9747 [-0.0063, 0.0061] \u2705\u00a0very_high unbounded 0.7755 \u00b1 0.0030 0.7765 \u00b1 0.0029 0.24 0.8104 [-0.0092, 0.0072] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01675","title":"Parameter = 0.1675","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1124 \u00b1 0.0022 0.1123 \u00b1 0.0022 0.03 0.9747 [-0.0061, 0.0063] \u2705\u00a0very_high chaos y_2 0.1143 \u00b1 0.0022 0.1194 \u00b1 0.0023 1.59 0.1124 [-0.0114, 0.0012] \u2705\u00a0very_high unbounded 0.7733 \u00b1 0.0030 0.7683 \u00b1 0.0030 1.19 0.2342 [-0.0032, 0.0132] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01700","title":"Parameter = 0.1700","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1154 \u00b1 0.0023 0.1136 \u00b1 0.0022 0.57 0.5719 [-0.0044, 0.0080] \u2705\u00a0very_high chaos y_2 0.1148 \u00b1 0.0023 0.1182 \u00b1 0.0023 1.04 0.2963 [-0.0096, 0.0029] \u2705\u00a0very_high unbounded 0.7698 \u00b1 0.0030 0.7682 \u00b1 0.0030 0.37 0.7130 [-0.0067, 0.0098] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01725","title":"Parameter = 0.1725","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1177 \u00b1 0.0023 0.1201 \u00b1 0.0023 0.74 0.4583 [-0.0087, 0.0039] \u2705\u00a0very_high chaos y_2 0.1179 \u00b1 0.0023 0.1171 \u00b1 0.0023 0.26 0.7918 [-0.0055, 0.0072] \u2705\u00a0very_high unbounded 0.7644 \u00b1 0.0030 0.7629 \u00b1 0.0030 0.36 0.7152 [-0.0068, 0.0099] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01750","title":"Parameter = 0.1750","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1150 \u00b1 0.0023 0.1179 \u00b1 0.0023 0.90 0.3660 [-0.0092, 0.0034] \u2705\u00a0very_high chaos y_2 0.1176 \u00b1 0.0023 0.1118 \u00b1 0.0022 1.80 0.0711 [-0.0005, 0.0120] \u2705\u00a0high unbounded 0.7674 \u00b1 0.0030 0.7702 \u00b1 0.0030 0.68 0.4990 [-0.0111, 0.0054] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01775","title":"Parameter = 0.1775","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1158 \u00b1 0.0023 0.1162 \u00b1 0.0023 0.11 0.9130 [-0.0066, 0.0059] \u2705\u00a0very_high chaos y_2 0.1207 \u00b1 0.0023 0.1181 \u00b1 0.0023 0.80 0.4226 [-0.0038, 0.0090] \u2705\u00a0very_high unbounded 0.7634 \u00b1 0.0030 0.7657 \u00b1 0.0030 0.53 0.5959 [-0.0106, 0.0061] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-01800","title":"Parameter = 0.1800","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.1170 \u00b1 0.0023 0.1172 \u00b1 0.0023 0.06 0.9504 [-0.0065, 0.0061] \u2705\u00a0very_high chaos y_2 0.1181 \u00b1 0.0023 0.1220 \u00b1 0.0023 1.18 0.2361 [-0.0102, 0.0025] \u2705\u00a0very_high unbounded 0.7649 \u00b1 0.0030 0.7609 \u00b1 0.0030 0.95 0.3410 [-0.0043, 0.0124] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/lorenz/#basin-stability-variation","title":"Basin Stability Variation","text":""},{"location":"case-studies/lorenz/#bifurcation-diagram","title":"Bifurcation Diagram","text":""},{"location":"case-studies/lorenz/#case-3-solver-rtol-convergence-study","title":"Case 3: Solver rtol Convergence Study","text":"<p>This hyperparameter study demonstrates the effect of ODE solver relative tolerance on basin stability estimation. Coarse tolerances (rtol=1e-3) produce inaccurate results, while finer tolerances converge to consistent values.</p>"},{"location":"case-studies/lorenz/#comparison-with-matlab-bstab_2","title":"Comparison with MATLAB bSTAB","text":""},{"location":"case-studies/lorenz/#parameter-00010","title":"Parameter = 0.0010","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.0221 \u00b1 0.0010 0.0895 \u00b1 0.0020 29.66 0.0000 [-0.0718, -0.0629] \u2705\u00a0high chaos y_2 0.0245 \u00b1 0.0011 0.0858 \u00b1 0.0020 27.12 0.0000 [-0.0658, -0.0569] \u2705\u00a0high unbounded 0.9534 \u00b1 0.0015 0.8246 \u00b1 0.0027 41.86 0.0000 [0.1227, 0.1347] \u2705\u00a0high"},{"location":"case-studies/lorenz/#parameter-00001","title":"Parameter = 0.0001","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.0874 \u00b1 0.0020 0.0874 \u00b1 0.0020 0.02 0.9859 [-0.0056, 0.0055] \u2705\u00a0very_high chaos y_2 0.0865 \u00b1 0.0020 0.0862 \u00b1 0.0020 0.12 0.9008 [-0.0052, 0.0059] \u2705\u00a0very_high unbounded 0.8261 \u00b1 0.0027 0.8264 \u00b1 0.0027 0.08 0.9369 [-0.0077, 0.0071] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-00000","title":"Parameter = 0.0000","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.0884 \u00b1 0.0020 0.0871 \u00b1 0.0020 0.48 0.6332 [-0.0042, 0.0069] \u2705\u00a0very_high chaos y_2 0.0868 \u00b1 0.0020 0.0850 \u00b1 0.0020 0.66 0.5092 [-0.0036, 0.0073] \u2705\u00a0very_high unbounded 0.8247 \u00b1 0.0027 0.8279 \u00b1 0.0027 0.84 0.3982 [-0.0106, 0.0042] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-00000_1","title":"Parameter = 0.0000","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.0882 \u00b1 0.0020 0.0872 \u00b1 0.0020 0.37 0.7104 [-0.0045, 0.0066] \u2705\u00a0very_high chaos y_2 0.0870 \u00b1 0.0020 0.0887 \u00b1 0.0020 0.60 0.5481 [-0.0072, 0.0038] \u2705\u00a0very_high unbounded 0.8248 \u00b1 0.0027 0.8242 \u00b1 0.0027 0.17 0.8643 [-0.0068, 0.0081] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-00000_2","title":"Parameter = 0.0000","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.0883 \u00b1 0.0020 0.0862 \u00b1 0.0020 0.76 0.4462 [-0.0034, 0.0077] \u2705\u00a0very_high chaos y_2 0.0869 \u00b1 0.0020 0.0882 \u00b1 0.0020 0.46 0.6456 [-0.0068, 0.0042] \u2705\u00a0very_high unbounded 0.8247 \u00b1 0.0027 0.8256 \u00b1 0.0027 0.22 0.8229 [-0.0083, 0.0066] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#parameter-00000_3","title":"Parameter = 0.0000","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence chaos y_1 0.0885 \u00b1 0.0020 0.0874 \u00b1 0.0020 0.39 0.6977 [-0.0045, 0.0067] \u2705\u00a0very_high chaos y_2 0.0869 \u00b1 0.0020 0.0871 \u00b1 0.0020 0.07 0.9434 [-0.0057, 0.0053] \u2705\u00a0very_high unbounded 0.8246 \u00b1 0.0027 0.8255 \u00b1 0.0027 0.24 0.8127 [-0.0083, 0.0065] \u2705\u00a0very_high"},{"location":"case-studies/lorenz/#visualizations_2","title":"Visualizations","text":""},{"location":"case-studies/lorenz/#basin-stability-variation_1","title":"Basin Stability Variation","text":""},{"location":"case-studies/lorenz/#bifurcation-diagram_1","title":"Bifurcation Diagram","text":""},{"location":"case-studies/overview/","title":"Case Studies Overview","text":"<p>This section documents the case studies used to validate pyBasin against the original MATLAB bSTAB implementation.</p>"},{"location":"case-studies/overview/#statistical-comparison-method","title":"Statistical Comparison Method","text":"<p>All case study comparisons use a rigorous two-sample z-test for proportions to validate that pyBasin produces statistically equivalent results to MATLAB bSTAB.</p>"},{"location":"case-studies/overview/#methodology","title":"Methodology","text":"<p>Since both implementations use Monte Carlo sampling to estimate basin stability (a proportion), each estimate has an associated standard error:</p> \\[SE = \\sqrt{\\frac{p(1-p)}{N}}\\] <p>where \\(p\\) is the basin stability estimate and \\(N\\) is the number of samples.</p> <p>To compare two independent estimates (Python vs MATLAB), we compute:</p> <ol> <li>Z-score: Measures difference in standard deviations</li> </ol> <p>\\(\\(z = \\frac{|BS_{Python} - BS_{MATLAB}|}{\\sqrt{SE_{Python}^2 + SE_{MATLAB}^2}}\\)\\)</p> <ol> <li>P-value: Probability of observing this difference by chance</li> </ol> <p>\\(\\(p = 2 \\cdot \\Phi(-|z|)\\)\\)</p> <p>where \\(\\Phi\\) is the standard normal CDF (computed using <code>scipy.stats.norm.sf</code>)</p> <ol> <li>95% Confidence Interval: Range where true difference likely lies</li> </ol> <p>\\(\\(CI = (BS_{Python} - BS_{MATLAB}) \\pm z_{0.975} \\cdot \\sqrt{SE_{Python}^2 + SE_{MATLAB}^2}\\)\\)</p>"},{"location":"case-studies/overview/#confidence-levels","title":"Confidence Levels","text":"<p>Based on the p-value, we classify results into confidence levels:</p> Confidence P-value Interpretation Very High \u2705 p &gt; 0.10 Highly likely the same implementation High \u2705 p &gt; 0.05 No significant difference (standard significance level) Moderate \u26a0\ufe0f p &gt; 0.01 Borderline case, may warrant investigation Low \u274c p &gt; 0.001 Significant difference detected Very Low \u274c p \u2264 0.001 Highly significant difference <p>Interpretation:</p> <ul> <li>Lower p-values indicate implementations are more likely different</li> <li>Higher p-values indicate implementations are more likely equivalent</li> <li>A \"Very High\" or \"High\" confidence (\u2705) confirms correct implementation</li> </ul>"},{"location":"case-studies/overview/#reading-comparison-tables","title":"Reading Comparison Tables","text":"<p>The comparison tables in each case study show:</p> <ul> <li>pyBasin BS \u00b1 SE: Python implementation result with standard error</li> <li>bSTAB BS \u00b1 SE: MATLAB reference result with standard error</li> <li>z-score: How many combined standard errors apart</li> <li>p-value: Statistical significance of difference</li> <li>95% CI (diff): Confidence interval for the difference</li> <li>Confidence: Classification based on p-value</li> </ul>"},{"location":"case-studies/overview/#purpose","title":"Purpose","text":"<p>The case studies serve multiple purposes:</p> <ol> <li>Validation: Verify correctness by comparing results with MATLAB bSTAB</li> <li>Examples: Demonstrate usage patterns for different types of systems</li> <li>Thesis Artifacts: Generate figures and results for the bachelor thesis</li> <li>Benchmarking: Compare performance and accuracy</li> </ol>"},{"location":"case-studies/overview/#available-case-studies","title":"Available Case Studies","text":""},{"location":"case-studies/overview/#duffing-oscillator","title":"Duffing Oscillator","text":"<p>A forced Duffing oscillator exhibiting bistability with two coexisting attractors.</p> <p>Key Features:</p> <ul> <li>Two stable periodic attractors</li> <li>Parameter-dependent basin stability</li> <li>Supervised and unsupervised learning approaches</li> </ul> <p>Files: <code>case_studies/duffing_oscillator/</code></p>"},{"location":"case-studies/overview/#lorenz-system","title":"Lorenz System","text":"<p>The classic Lorenz system with parameter variations.</p> <p>Key Features:</p> <ul> <li>Chaotic dynamics</li> <li>Parameter sensitivity studies (\u03c3, \u03c1)</li> <li>High-dimensional state space</li> </ul> <p>Files: <code>case_studies/lorenz/</code></p>"},{"location":"case-studies/overview/#pendulum","title":"Pendulum","text":"<p>A forced pendulum system with different forcing parameters.</p> <p>Key Features:</p> <ul> <li>Multiple parameter cases</li> <li>Bifurcation analysis</li> <li>Grid-based sampling comparison</li> </ul> <p>Files: <code>case_studies/pendulum/</code></p>"},{"location":"case-studies/overview/#friction-system","title":"Friction System","text":"<p>A mechanical system with friction effects.</p> <p>Key Features:</p> <ul> <li>Non-smooth dynamics</li> <li>Velocity-dependent friction</li> <li>Parameter variation studies</li> </ul> <p>Files: <code>case_studies/friction/</code></p>"},{"location":"case-studies/overview/#running-case-studies","title":"Running Case Studies","text":"<p>All case studies can be run from the project root:</p> <pre><code># Navigate to project root\ncd /path/to/pyBasinWorkspace\n\n# Run a specific case study\nuv run python case_studies/duffing_oscillator/main_supervised.py\nuv run python case_studies/lorenz/main_lorenz.py\nuv run python case_studies/pendulum/main_case1.py\n</code></pre>"},{"location":"case-studies/overview/#comparison-with-matlab","title":"Comparison with MATLAB","text":"<p>Each case study includes validation against the MATLAB implementation:</p> Case Study MATLAB BS Python BS Difference Duffing (Case 1) TBD TBD TBD Lorenz (\u03c3=10) TBD TBD TBD Pendulum (Case 1) TBD TBD TBD Friction (v=1) TBD TBD TBD <p>Values to be filled after validation runs</p>"},{"location":"case-studies/overview/#generated-artifacts","title":"Generated Artifacts","text":"<p>All case studies save their outputs to the <code>artifacts/</code> directory:</p> <pre><code>artifacts/\n\u251c\u2500\u2500 figures/          # Generated plots\n\u251c\u2500\u2500 results/          # Numerical results (JSON, CSV)\n\u2514\u2500\u2500 reports/          # Summary reports\n</code></pre>"},{"location":"case-studies/overview/#integration-tests","title":"Integration Tests","text":"<p>The case studies are also converted into integration tests that automatically validate correctness:</p> <pre><code># Run all integration tests\npytest tests/integration/\n\n# Run specific case study test\npytest tests/integration/test_duffing.py\n</code></pre>"},{"location":"case-studies/overview/#contributing-new-case-studies","title":"Contributing New Case Studies","text":"<p>To add a new case study:</p> <ol> <li>Create a new directory under <code>case_studies/</code></li> <li>Implement the ODE system and feature extractor</li> <li>Create a main script that runs the analysis</li> <li>Add corresponding integration test</li> <li>Document in this section</li> </ol> <p>See Contributing Guide for details.</p>"},{"location":"case-studies/pendulum/","title":"Pendulum","text":""},{"location":"case-studies/pendulum/#system-description","title":"System Description","text":"<p>Driven damped pendulum:</p> \\[\\ddot{\\theta} + \\gamma \\dot{\\theta} + \\sin(\\theta) = A \\cos(\\omega t)\\]"},{"location":"case-studies/pendulum/#attractors","title":"Attractors","text":"<ul> <li>Fixed Point (FP): Pendulum settles to equilibrium</li> <li>Limit Cycle (LC): Periodic oscillation</li> </ul>"},{"location":"case-studies/pendulum/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/pendulum/#setup","title":"Setup","text":"<pre><code>def setup_pendulum_system() -&gt; SetupProperties:\n    n = 10000\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up pendulum system on device: {device}\")\n\n    params: PendulumParams = {\"alpha\": 0.1, \"T\": 0.5, \"K\": 1.0}\n\n    ode_system = PendulumJaxODE(params)\n\n    sampler = GridSampler(\n        min_limits=[-np.pi + np.arcsin(params[\"T\"] / params[\"K\"]), -10.0],\n        max_limits=[np.pi + np.arcsin(params[\"T\"] / params[\"K\"]), 10.0],\n        device=device,\n    )\n\n    solver = JaxSolver(\n        time_span=(0, 1000),\n        n_steps=1000,\n        device=device,\n        rtol=1e-8,\n        atol=1e-6,\n        use_cache=True,\n    )\n\n    feature_extractor = JaxFeatureExtractor(\n        time_steady=950.0,\n        features=None,\n        features_per_state={\n            1: {\"log_delta\": None},\n        },\n        normalize=False,\n    )\n\n    template_y0 = [\n        [0.5, 0.0],\n        [2.7, 0.0],\n    ]\n    classifier_labels = [\"FP\", \"LC\"]\n\n    knn = KNeighborsClassifier(n_neighbors=1)\n\n    knn_cluster = KNNClassifier(\n        classifier=knn,\n        template_y0=template_y0,\n        labels=classifier_labels,\n        ode_params=params,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": knn_cluster,\n    }\n</code></pre>"},{"location":"case-studies/pendulum/#main-estimation","title":"Main Estimation","text":"<pre><code>def main():\n    props = setup_pendulum_system()\n\n    bse = BasinStabilityEstimator(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=props.get(\"solver\"),\n        feature_extractor=props.get(\"feature_extractor\"),\n        predictor=props.get(\"cluster_classifier\"),\n        save_to=\"results_case1\",\n        feature_selector=None,\n    )\n\n    bse.estimate_bs()\n\n    return bse\n</code></pre>"},{"location":"case-studies/pendulum/#case-1-baseline-results","title":"Case 1: Baseline Results","text":""},{"location":"case-studies/pendulum/#comparison-with-matlab-bstab","title":"Comparison with MATLAB bSTAB","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.1563 \u00b1 0.0036 0.1520 \u00b1 0.0036 0.84 0.3998 [-0.0057, 0.0143] \u2705\u00a0very_high LC 0.8437 \u00b1 0.0036 0.8480 \u00b1 0.0036 0.84 0.3998 [-0.0143, 0.0057] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/pendulum/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/pendulum/#state-space","title":"State Space","text":""},{"location":"case-studies/pendulum/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/pendulum/#case-2-parameter-sweep","title":"Case 2: Parameter Sweep","text":""},{"location":"case-studies/pendulum/#comparison-with-matlab-bstab_1","title":"Comparison with MATLAB bSTAB","text":""},{"location":"case-studies/pendulum/#parameter-00100","title":"Parameter = 0.0100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-00600","title":"Parameter = 0.0600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-01100","title":"Parameter = 0.1100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 1.0000 \u00b1 0.0000 1.0000 \u00b1 0.0000 0.00 1.0000 [0.0000, 0.0000] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-01600","title":"Parameter = 0.1600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.4757 \u00b1 0.0050 0.4830 \u00b1 0.0050 1.03 0.3015 [-0.0211, 0.0065] \u2705\u00a0very_high LC 0.5243 \u00b1 0.0050 0.5170 \u00b1 0.0050 1.03 0.3015 [-0.0065, 0.0211] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-02100","title":"Parameter = 0.2100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.3868 \u00b1 0.0049 0.3967 \u00b1 0.0049 1.43 0.1515 [-0.0234, 0.0036] \u2705\u00a0very_high LC 0.6132 \u00b1 0.0049 0.6033 \u00b1 0.0049 1.43 0.1515 [-0.0036, 0.0234] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-02600","title":"Parameter = 0.2600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.3335 \u00b1 0.0047 0.3268 \u00b1 0.0047 1.01 0.3137 [-0.0063, 0.0197] \u2705\u00a0very_high LC 0.6665 \u00b1 0.0047 0.6732 \u00b1 0.0047 1.01 0.3137 [-0.0197, 0.0063] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-03100","title":"Parameter = 0.3100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.2818 \u00b1 0.0045 0.2756 \u00b1 0.0045 0.98 0.3282 [-0.0062, 0.0186] \u2705\u00a0very_high LC 0.7182 \u00b1 0.0045 0.7244 \u00b1 0.0045 0.98 0.3282 [-0.0186, 0.0062] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-03600","title":"Parameter = 0.3600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.2362 \u00b1 0.0042 0.2380 \u00b1 0.0043 0.30 0.7647 [-0.0136, 0.0100] \u2705\u00a0very_high LC 0.7638 \u00b1 0.0042 0.7620 \u00b1 0.0043 0.30 0.7647 [-0.0100, 0.0136] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-04100","title":"Parameter = 0.4100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.1985 \u00b1 0.0040 0.2065 \u00b1 0.0040 1.41 0.1592 [-0.0191, 0.0031] \u2705\u00a0very_high LC 0.8015 \u00b1 0.0040 0.7935 \u00b1 0.0040 1.41 0.1592 [-0.0031, 0.0191] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-04600","title":"Parameter = 0.4600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.1695 \u00b1 0.0038 0.1703 \u00b1 0.0038 0.15 0.8803 [-0.0112, 0.0096] \u2705\u00a0very_high LC 0.8305 \u00b1 0.0038 0.8297 \u00b1 0.0038 0.15 0.8803 [-0.0096, 0.0112] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-05100","title":"Parameter = 0.5100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.1499 \u00b1 0.0036 0.1470 \u00b1 0.0035 0.58 0.5641 [-0.0070, 0.0128] \u2705\u00a0very_high LC 0.8501 \u00b1 0.0036 0.8530 \u00b1 0.0035 0.58 0.5641 [-0.0128, 0.0070] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-05600","title":"Parameter = 0.5600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.1220 \u00b1 0.0033 0.1279 \u00b1 0.0033 1.26 0.2070 [-0.0151, 0.0033] \u2705\u00a0very_high LC 0.8780 \u00b1 0.0033 0.8721 \u00b1 0.0033 1.26 0.2070 [-0.0033, 0.0151] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-06100","title":"Parameter = 0.6100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.1021 \u00b1 0.0030 0.1034 \u00b1 0.0030 0.30 0.7621 [-0.0097, 0.0071] \u2705\u00a0very_high LC 0.8979 \u00b1 0.0030 0.8966 \u00b1 0.0030 0.30 0.7621 [-0.0071, 0.0097] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-06600","title":"Parameter = 0.6600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.0858 \u00b1 0.0028 0.0839 \u00b1 0.0028 0.48 0.6297 [-0.0058, 0.0096] \u2705\u00a0very_high LC 0.9142 \u00b1 0.0028 0.9161 \u00b1 0.0028 0.48 0.6297 [-0.0096, 0.0058] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-07100","title":"Parameter = 0.7100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.0702 \u00b1 0.0026 0.0653 \u00b1 0.0025 1.38 0.1680 [-0.0021, 0.0119] \u2705\u00a0very_high LC 0.9298 \u00b1 0.0026 0.9347 \u00b1 0.0025 1.38 0.1680 [-0.0119, 0.0021] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-07600","title":"Parameter = 0.7600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.0535 \u00b1 0.0023 0.0545 \u00b1 0.0023 0.31 0.7544 [-0.0073, 0.0053] \u2705\u00a0very_high LC 0.9465 \u00b1 0.0023 0.9455 \u00b1 0.0023 0.31 0.7544 [-0.0053, 0.0073] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-08100","title":"Parameter = 0.8100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.0396 \u00b1 0.0020 0.0391 \u00b1 0.0019 0.18 0.8557 [-0.0049, 0.0059] \u2705\u00a0very_high LC 0.9604 \u00b1 0.0020 0.9609 \u00b1 0.0019 0.18 0.8557 [-0.0059, 0.0049] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-08600","title":"Parameter = 0.8600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.0289 \u00b1 0.0017 0.0244 \u00b1 0.0015 1.98 0.0482 [0.0000, 0.0090] \u26a0\ufe0f\u00a0moderate LC 0.9711 \u00b1 0.0017 0.9756 \u00b1 0.0015 1.98 0.0482 [-0.0090, -0.0000] \u26a0\ufe0f\u00a0moderate"},{"location":"case-studies/pendulum/#parameter-09100","title":"Parameter = 0.9100","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.0165 \u00b1 0.0013 0.0172 \u00b1 0.0013 0.38 0.7006 [-0.0043, 0.0029] \u2705\u00a0very_high LC 0.9835 \u00b1 0.0013 0.9828 \u00b1 0.0013 0.38 0.7006 [-0.0029, 0.0043] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#parameter-09600","title":"Parameter = 0.9600","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence FP 0.0068 \u00b1 0.0008 0.0071 \u00b1 0.0008 0.26 0.7985 [-0.0026, 0.0020] \u2705\u00a0very_high LC 0.9932 \u00b1 0.0008 0.9929 \u00b1 0.0008 0.26 0.7985 [-0.0020, 0.0026] \u2705\u00a0very_high"},{"location":"case-studies/pendulum/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/pendulum/#basin-stability-variation","title":"Basin Stability Variation","text":""},{"location":"case-studies/pendulum/#bifurcation-diagram","title":"Bifurcation Diagram","text":""},{"location":"case-studies/rossler-network/","title":"R\u00f6ssler Network","text":""},{"location":"case-studies/rossler-network/#system-description","title":"System Description","text":"<p>Network of 100 coupled R\u00f6ssler oscillators studying synchronization dynamics:</p> \\[ \\begin{aligned} \\dot{x}_i &amp;= -y_i - z_i + K \\sum_{j \\in \\mathcal{N}_i} (x_j - x_i) \\\\ \\dot{y}_i &amp;= x_i + ay_i \\\\ \\dot{z}_i &amp;= b + z_i(x_i - c) \\end{aligned} \\] <p>where \\(i = 1, \\ldots, 100\\) and \\(\\mathcal{N}_i\\) denotes the neighbors of node \\(i\\) in the network.</p> <p>Parameters:</p> <ul> <li>\\(a = 0.2\\), \\(b = 0.2\\), \\(c = 7.0\\) (R\u00f6ssler system parameters)</li> <li>\\(K\\) = coupling strength (varied from 0.119 to 0.317)</li> <li>Network topology: Scale-free network with 100 nodes</li> </ul>"},{"location":"case-studies/rossler-network/#attractors","title":"Attractors","text":"<p>The system exhibits three types of behavior:</p> <ul> <li>Synchronized: All oscillators converge to a common trajectory</li> <li>Desynchronized: Oscillators remain coupled but do not synchronize</li> <li>Unbounded: Some trajectories diverge to infinity</li> </ul> <p>Basin stability is computed for non-unbounded states (synchronized + desynchronized).</p>"},{"location":"case-studies/rossler-network/#key-features","title":"Key Features","text":"<p>This case study uses custom feature extraction and classification:</p> <ul> <li><code>SynchronizationFeatureExtractor</code>: Computes maximum pairwise deviation across all node pairs</li> <li><code>SynchronizationClassifier</code>: Classifies based on synchronization threshold</li> </ul>"},{"location":"case-studies/rossler-network/#reproduction-code","title":"Reproduction Code","text":""},{"location":"case-studies/rossler-network/#setup","title":"Setup","text":"<pre><code>def setup_rossler_network_system(k: float = 0.218) -&gt; SetupProperties:\n    \"\"\"\n    Setup the R\u00f6ssler network system for basin stability estimation.\n\n    Parameters\n    ----------\n    k : float\n        Coupling strength. Must be in the stability interval (0.100, 0.336).\n        Default is 0.218, which has expected S_B \u2248 0.496 from the reference paper.\n\n    Returns\n    -------\n    SetupProperties\n        Configuration dictionary for BasinStabilityEstimator.\n\n    Notes\n    -----\n    Reference values from the paper:\n        K=0.119: S_B=0.226    K=0.238: S_B=0.594\n        K=0.139: S_B=0.274    K=0.258: S_B=0.628\n        K=0.159: S_B=0.330    K=0.278: S_B=0.656\n        K=0.179: S_B=0.346    K=0.297: S_B=0.694\n        K=0.198: S_B=0.472    K=0.317: S_B=0.690\n        K=0.218: S_B=0.496\n    \"\"\"\n    n = 500\n\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up R\u00f6ssler network system on device: {device}\")\n    print(f\"  N = {N_NODES} nodes, k = {k}\")\n\n    params: RosslerNetworkParams = {\n        \"a\": 0.2,\n        \"b\": 0.2,\n        \"c\": 7.0,\n        \"K\": k,\n        \"edges_i\": EDGES_I,\n        \"edges_j\": EDGES_J,\n        \"N\": N_NODES,\n    }\n\n    ode_system = RosslerNetworkJaxODE(params)\n\n    min_limits = (\n        [-15.0] * N_NODES  # x_i in [-15, 15]\n        + [-15.0] * N_NODES  # y_i in [-15, 15]\n        + [-5.0] * N_NODES  # z_i in [-5, 35]\n    )\n    max_limits = (\n        [15.0] * N_NODES  # x_i\n        + [15.0] * N_NODES  # y_i\n        + [35.0] * N_NODES  # z_i\n    )\n\n    sampler = UniformRandomSampler(\n        min_limits=min_limits,\n        max_limits=max_limits,\n        device=device,\n    )\n\n    solver = JaxSolver(\n        time_span=(0, 1000),\n        n_steps=1000,\n        device=device,\n        rtol=1e-3,\n        atol=1e-6,\n        use_cache=True,\n        event_fn=rossler_stop_event,\n    )\n\n    feature_extractor = SynchronizationFeatureExtractor(\n        n_nodes=N_NODES,\n        time_steady=950,\n        device=device,\n    )\n\n    sync_classifier = SynchronizationClassifier(\n        epsilon=1.5,\n    )\n\n    return {\n        \"n\": n,\n        \"ode_system\": ode_system,\n        \"sampler\": sampler,\n        \"solver\": solver,\n        \"feature_extractor\": feature_extractor,\n        \"cluster_classifier\": sync_classifier,\n    }\n</code></pre>"},{"location":"case-studies/rossler-network/#single-k-value","title":"Single K Value","text":"<pre><code>def main(k: float = 0.218):\n    props = setup_rossler_network_system(k=k)\n\n    bse = BasinStabilityEstimator(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=props.get(\"solver\"),\n        feature_extractor=props.get(\"feature_extractor\"),\n        predictor=props.get(\"cluster_classifier\"),\n        save_to=\"results\",\n        feature_selector=None,\n        detect_unbounded=False,\n    )\n\n    basin_stability = bse.estimate_bs()\n    print(f\"\\nBasin Stability for k={k}:\")\n    print(basin_stability)\n\n    expected_sb = {\n        0.119: 0.226,\n        0.139: 0.274,\n        0.159: 0.330,\n        0.179: 0.346,\n        0.198: 0.472,\n        0.218: 0.496,\n        0.238: 0.594,\n        0.258: 0.628,\n        0.278: 0.656,\n        0.297: 0.694,\n        0.317: 0.690,\n    }\n    if k in expected_sb:\n        print(f\"\\nExpected S_B (synchronized) from paper: {expected_sb[k]}\")\n\n    return bse\n</code></pre>"},{"location":"case-studies/rossler-network/#k-parameter-sweep","title":"K Parameter Sweep","text":"<pre><code>def main():\n    props = setup_rossler_network_system(k=0.119)\n\n    k_values = np.array(\n        [0.119, 0.139, 0.159, 0.179, 0.198, 0.218, 0.238, 0.258, 0.278, 0.297, 0.317]\n    )\n\n    as_params = AdaptiveStudyParams(\n        adaptative_parameter_values=k_values,\n        adaptative_parameter_name='ode_system.params[\"K\"]',\n    )\n\n    solver = props.get(\"solver\")\n    feature_extractor = props.get(\"feature_extractor\")\n    cluster_classifier = props.get(\"cluster_classifier\")\n    assert solver is not None\n    assert feature_extractor is not None\n    assert cluster_classifier is not None\n\n    bse = ASBasinStabilityEstimator(\n        n=props[\"n\"],\n        ode_system=props[\"ode_system\"],\n        sampler=props[\"sampler\"],\n        solver=solver,\n        feature_extractor=feature_extractor,\n        cluster_classifier=cluster_classifier,\n        as_params=as_params,\n        save_to=\"results_k_study\",\n    )\n\n    bse.estimate_as_bs()\n\n    print(\"\\n\" + \"=\" * 60)\n    print(\"COMPARISON WITH PAPER RESULTS\")\n    print(\"=\" * 60)\n\n    expected = {\n        0.119: 0.226,\n        0.139: 0.274,\n        0.159: 0.330,\n        0.179: 0.346,\n        0.198: 0.472,\n        0.218: 0.496,\n        0.238: 0.594,\n        0.258: 0.628,\n        0.278: 0.656,\n        0.297: 0.694,\n        0.317: 0.690,\n    }\n\n    n_samples = props[\"n\"]\n\n    print(f\"{'K':&gt;8} | {'Expected':&gt;8} | {'Computed':&gt;8} | {'Diff':&gt;7} | {'e_abs':&gt;6} | {'2\u03c3':&gt;6}\")\n    print(\"-\" * 60)\n\n    computed_sync: list[float] = []\n    within_2sigma = 0\n    for param_val, bs_dict in zip(bse.parameter_values, bse.basin_stabilities, strict=True):\n        sync_val = bs_dict.get(\"synchronized\", 0.0)\n        computed_sync.append(sync_val)\n        diff = sync_val - expected[param_val]\n\n        e_abs = np.sqrt(sync_val * (1 - sync_val) / n_samples)\n        e_combined = e_abs * np.sqrt(2)\n        within = abs(diff) &lt;= 2 * e_combined\n        within_2sigma += int(within)\n        status = \"\u2713\" if within else \"\u2717\"\n\n        print(\n            f\"{param_val:&gt;8.3f} | {expected[param_val]:&gt;8.3f} | {sync_val:&gt;8.3f} | {diff:&gt;+7.3f} | {e_abs:&gt;6.3f} | {status:&gt;6}\"\n        )\n\n    if computed_sync:\n        mean_sb = np.mean(computed_sync)\n        e_mean = np.std(computed_sync, ddof=1) / np.sqrt(len(computed_sync))\n        mean_diff = mean_sb - 0.490\n        mean_within = abs(mean_diff) &lt;= 2 * e_mean\n        mean_status = \"\u2713\" if mean_within else \"\u2717\"\n        print(\"-\" * 60)\n        print(\n            f\"{'Mean S_B':&gt;8} | {'0.490':&gt;8} | {mean_sb:&gt;8.3f} | {mean_diff:&gt;+7.3f} | {e_mean:&gt;6.3f} | {mean_status:&gt;6}\"\n        )\n        print(\n            f\"\\nWithin 2\u03c3: {within_2sigma}/{len(expected)} ({within_2sigma / len(expected) * 100:.0f}%)\"\n        )\n        print(f\"Note: e_abs = sqrt(S_B*(1-S_B)/N), N={n_samples}; e_mean = std(S_B)/sqrt(K)\")\n\n    bse.save()\n\n    return bse\n</code></pre>"},{"location":"case-studies/rossler-network/#baseline-results-k0218","title":"Baseline Results (K=0.218)","text":""},{"location":"case-studies/rossler-network/#comparison-with-paper-results","title":"Comparison with Paper Results","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.4840 \u00b1 0.0223 0.4960 \u00b1 0.0224 0.38 0.7043 [-0.0740, 0.0500] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#visualizations","title":"Visualizations","text":""},{"location":"case-studies/rossler-network/#basin-stability","title":"Basin Stability","text":""},{"location":"case-studies/rossler-network/#state-space","title":"State Space","text":""},{"location":"case-studies/rossler-network/#feature-space","title":"Feature Space","text":""},{"location":"case-studies/rossler-network/#k-parameter-sweep_1","title":"K Parameter Sweep","text":""},{"location":"case-studies/rossler-network/#comparison-with-paper-results_1","title":"Comparison with Paper Results","text":""},{"location":"case-studies/rossler-network/#parameter-01190","title":"Parameter = 0.1190","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.2020 \u00b1 0.0180 0.2260 \u00b1 0.0187 0.93 0.3546 [-0.0748, 0.0268] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#parameter-01390","title":"Parameter = 0.1390","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.2480 \u00b1 0.0193 0.2740 \u00b1 0.0199 0.94 0.3490 [-0.0804, 0.0284] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#parameter-01590","title":"Parameter = 0.1590","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.3080 \u00b1 0.0206 0.3300 \u00b1 0.0210 0.75 0.4553 [-0.0798, 0.0358] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#parameter-01790","title":"Parameter = 0.1790","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.3620 \u00b1 0.0215 0.3460 \u00b1 0.0213 0.53 0.5967 [-0.0433, 0.0753] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#parameter-01980","title":"Parameter = 0.1980","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.4200 \u00b1 0.0221 0.4720 \u00b1 0.0223 1.66 0.0977 [-0.1135, 0.0095] \u2705\u00a0high"},{"location":"case-studies/rossler-network/#parameter-02180","title":"Parameter = 0.2180","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.4840 \u00b1 0.0223 0.4960 \u00b1 0.0224 0.38 0.7043 [-0.0740, 0.0500] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#parameter-02380","title":"Parameter = 0.2380","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.5500 \u00b1 0.0222 0.5940 \u00b1 0.0220 1.41 0.1593 [-0.1053, 0.0173] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#parameter-02580","title":"Parameter = 0.2580","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.6080 \u00b1 0.0218 0.6280 \u00b1 0.0216 0.65 0.5151 [-0.0802, 0.0402] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#parameter-02780","title":"Parameter = 0.2780","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.6560 \u00b1 0.0212 0.6560 \u00b1 0.0212 0.00 1.0000 [-0.0589, 0.0589] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#parameter-02970","title":"Parameter = 0.2970","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.7120 \u00b1 0.0203 0.6940 \u00b1 0.0206 0.62 0.5333 [-0.0386, 0.0746] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#parameter-03170","title":"Parameter = 0.3170","text":"Attractor pyBasin BS \u00b1 SE bSTAB BS \u00b1 SE z p-value 95% CI (diff) Confidence synchronized 0.7280 \u00b1 0.0199 0.6900 \u00b1 0.0207 1.32 0.1855 [-0.0183, 0.0943] \u2705\u00a0very_high"},{"location":"case-studies/rossler-network/#visualizations_1","title":"Visualizations","text":""},{"location":"case-studies/rossler-network/#basin-stability-variation","title":"Basin Stability Variation","text":""},{"location":"case-studies/rossler-network/#references","title":"References","text":"<p>Menck, P. J., Heitzig, J., Marwan, N., &amp; Kurths, J. (2013). How basin stability complements the linear-stability paradigm. Nature Physics, 9(2), 89-92.</p>"},{"location":"development/contributing/","title":"Contributing","text":"<p>TODO</p> <p>This section is under development.</p>"},{"location":"development/contributing/#adding-a-new-case-study","title":"Adding a New Case Study","text":"<p>To add a new case study:</p> <ol> <li>Create a new directory under <code>case_studies/</code></li> <li>Implement the ODE system and feature extractor</li> <li>Create a main script that runs the analysis</li> <li>Add corresponding integration test</li> <li>Document in the case studies section</li> </ol>"},{"location":"development/contributing/#development-guidelines","title":"Development Guidelines","text":"<p>More information coming soon.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.11 or higher</li> <li>pip or uv package manager</li> </ul>"},{"location":"getting-started/installation/#install-from-pypi","title":"Install from PyPI","text":"<p>Once published, you'll be able to install pyBasin using pip:</p> <pre><code>pip install pybasin\n</code></pre>"},{"location":"getting-started/installation/#install-from-source","title":"Install from Source","text":""},{"location":"getting-started/installation/#using-uv-recommended","title":"Using UV (Recommended)","text":"<pre><code># Clone the repository\ngit clone https://github.com/adrianwix/pyBSTAB.git\ncd pyBasinWorkspace\n\n# Install with UV\nuv add -e .\n\n# Or install with all optional dependencies\nuv add -e \".[all]\"\n</code></pre>"},{"location":"getting-started/installation/#using-pip","title":"Using pip","text":"<pre><code># Clone the repository\ngit clone https://github.com/adrianwix/pyBSTAB.git\ncd pyBasinWorkspace\n\n# Install in editable mode\npip install -e .\n\n# Or install with all optional dependencies\npip install -e \".[all]\"\n</code></pre>"},{"location":"getting-started/installation/#optional-dependencies","title":"Optional Dependencies","text":""},{"location":"getting-started/installation/#development-tools","title":"Development Tools","text":"<p>Install testing and linting tools:</p> <pre><code>uv add -e \".[dev]\"\n</code></pre> <p>Includes:</p> <ul> <li>pytest</li> <li>pytest-cov</li> <li>mypy</li> <li>ruff</li> <li>black</li> </ul>"},{"location":"getting-started/installation/#documentation","title":"Documentation","text":"<p>Install documentation building tools:</p> <pre><code>uv add -e \".[docs]\"\n</code></pre> <p>Includes:</p> <ul> <li>mkdocs-material</li> <li>mkdocstrings</li> <li>mkdocs-jupyter</li> </ul>"},{"location":"getting-started/installation/#case-studies","title":"Case Studies","text":"<p>Install additional dependencies for running case studies:</p> <pre><code>uv add -e \".[case-studies]\"\n</code></pre> <p>Includes:</p> <ul> <li>jupyter</li> <li>openpyxl</li> <li>notebook</li> </ul>"},{"location":"getting-started/installation/#verification","title":"Verification","text":"<p>Verify your installation:</p> <pre><code>import pybasin\nprint(pybasin.__version__)\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<ul> <li>Check out the Quick Start guide</li> <li>Explore the API Reference</li> <li>Run the Case Studies</li> </ul>"},{"location":"getting-started/quickstart/","title":"Quick Start","text":"<p>This guide will help you get started with pyBasin in just a few minutes.</p>"},{"location":"getting-started/quickstart/#basic-example","title":"Basic Example","text":"<p>Here's a simple example of estimating basin stability for a 2D dynamical system:</p> <pre><code>import numpy as np\nfrom pybasin import BasinStabilityEstimator, ODESystem\n\n# Step 1: Define your dynamical system\nclass SimpleSystem(ODESystem):\n    \"\"\"A simple 2D system with two stable fixed points.\"\"\"\n\n    def dynamics(self, t, state):\n        \"\"\"Define the differential equations.\"\"\"\n        x, y = state\n        dx = x * (1 - x**2 - y**2)\n        dy = y * (1 - x**2 - y**2)\n        return np.array([dx, dy])\n\n    def classify_attractor(self, solution):\n        \"\"\"Classify which attractor the solution reached.\"\"\"\n        final_state = solution.y[:, -1]\n        x_final, y_final = final_state\n\n        # Classify based on final position\n        if x_final &gt; 0:\n            return 0  # Right attractor\n        else:\n            return 1  # Left attractor\n\n# Step 2: Create the estimator\nsystem = SimpleSystem()\nestimator = BasinStabilityEstimator(\n    system=system,\n    t_span=(0, 50),  # Integration time\n    n_samples=1000   # Number of initial conditions\n)\n\n# Step 3: Define the sampling region\nbounds = [(-2, 2), (-2, 2)]  # [x_min, x_max], [y_min, y_max]\n\n# Step 4: Estimate basin stability\nresults = estimator.estimate(bounds)\n\n# Step 5: Analyze results\nprint(f\"Basin Stability (Attractor 0): {results.basin_stability[0]:.3f}\")\nprint(f\"Basin Stability (Attractor 1): {results.basin_stability[1]:.3f}\")\nprint(f\"Total samples: {results.n_samples}\")\nprint(f\"Attractor distribution: {results.attractor_counts}\")\n\n# Step 6: Visualize\nresults.plot_basin_2d()\n</code></pre>"},{"location":"getting-started/quickstart/#using-adaptive-sampling","title":"Using Adaptive Sampling","text":"<p>For more efficient sampling, use the adaptive sampling estimator:</p> <pre><code>from pybasin import ASBasinStabilityEstimator\n\n# Create adaptive sampling estimator\nas_estimator = ASBasinStabilityEstimator(\n    system=system,\n    initial_samples=100,\n    max_samples=1000,\n    uncertainty_threshold=0.1\n)\n\n# Estimate with adaptive sampling\nas_results = as_estimator.estimate(bounds)\n\nprint(f\"Samples used: {as_results.n_samples}\")\nprint(f\"Convergence achieved: {as_results.converged}\")\n</code></pre>"},{"location":"getting-started/quickstart/#custom-feature-extraction","title":"Custom Feature Extraction","text":"<p>You can define custom features for better classification:</p> <pre><code>from pybasin import FeatureExtractor\n\nclass MyFeatureExtractor(FeatureExtractor):\n    \"\"\"Extract custom features from solutions.\"\"\"\n\n    def extract(self, solution):\n        \"\"\"Extract features from the solution.\"\"\"\n        t = solution.t\n        y = solution.y\n\n        features = {\n            'final_x': y[0, -1],\n            'final_y': y[1, -1],\n            'max_distance': np.max(np.sqrt(y[0]**2 + y[1]**2)),\n            'period': self._estimate_period(t, y),\n        }\n        return features\n\n    def _estimate_period(self, t, y):\n        \"\"\"Estimate the period of oscillation.\"\"\"\n        # Your period estimation logic here\n        return 0.0\n\n# Use custom feature extractor\nestimator = BasinStabilityEstimator(\n    system=system,\n    feature_extractor=MyFeatureExtractor()\n)\n</code></pre>"},{"location":"getting-started/quickstart/#working-with-high-dimensional-systems","title":"Working with High-Dimensional Systems","text":"<p>For systems with more than 2 dimensions:</p> <pre><code>class LorenzSystem(ODESystem):\n    \"\"\"The Lorenz system.\"\"\"\n\n    def __init__(self, sigma=10, rho=28, beta=8/3):\n        self.sigma = sigma\n        self.rho = rho\n        self.beta = beta\n\n    def dynamics(self, t, state):\n        x, y, z = state\n        dx = self.sigma * (y - x)\n        dy = x * (self.rho - z) - y\n        dz = x * y - self.beta * z\n        return np.array([dx, dy, dz])\n\n    def classify_attractor(self, solution):\n        # Classification logic for Lorenz attractors\n        final_state = solution.y[:, -1]\n        if final_state[2] &gt; 20:\n            return 0\n        return 1\n\n# Sample in 3D space\nlorenz = LorenzSystem()\nestimator = BasinStabilityEstimator(lorenz)\nbounds = [(-20, 20), (-30, 30), (0, 50)]\nresults = estimator.estimate(bounds)\n</code></pre>"},{"location":"getting-started/quickstart/#saving-and-loading-results","title":"Saving and Loading Results","text":"<pre><code># Save results\nresults.save('my_results.json')\n\n# Load results\nfrom pybasin import BasinStabilityResult\nloaded_results = BasinStabilityResult.load('my_results.json')\n</code></pre>"},{"location":"getting-started/quickstart/#next-steps","title":"Next Steps","text":"<ul> <li>Explore the API Reference</li> <li>Check out the Case Studies for real-world examples</li> </ul>"},{"location":"guides/custom-feature-extractor/","title":"Creating Custom Feature Extractors","text":"<p>Feature extractors transform ODE solution trajectories into feature vectors used for basin of attraction classification. This guide shows how to create your own.</p>"},{"location":"guides/custom-feature-extractor/#basic-implementation","title":"Basic Implementation","text":"<p>To create a custom feature extractor, subclass <code>FeatureExtractor</code> and implement the <code>extract_features</code> method:</p> <pre><code>import torch\nfrom pybasin.feature_extractors.feature_extractor import FeatureExtractor\nfrom pybasin.solution import Solution\n\n\nclass AmplitudeFeatureExtractor(FeatureExtractor):\n    def extract_features(self, solution: Solution) -&gt; torch.Tensor:\n        # Filter out transient behavior\n        y_filtered: torch.Tensor = self.filter_time(solution)\n\n        # Compute features - here we extract max amplitude per state\n        # y_filtered shape: (n_times, n_samples, n_states)\n        max_amplitude: torch.Tensor = torch.max(torch.abs(y_filtered), dim=0).values\n\n        # Set _num_features for automatic feature naming\n        self._num_features = max_amplitude.shape[1]\n\n        # Return shape: (n_samples, n_features)\n        return max_amplitude\n</code></pre>"},{"location":"guides/custom-feature-extractor/#key-points","title":"Key Points","text":"<ol> <li>Use <code>filter_time</code>: Call <code>self.filter_time(solution)</code> to remove transient dynamics based on <code>time_steady</code></li> <li>Return a tensor: The return type must be <code>torch.Tensor</code> with shape <code>(n_samples, n_features)</code></li> <li>Set <code>_num_features</code>: Assign <code>self._num_features</code> to enable automatic feature naming</li> <li>Do NOT modify the Solution object: The <code>extract_features</code> method should be pure - read from the solution, compute features, and return them. Never assign to <code>solution.features</code>, <code>solution.extracted_features</code>, or any other solution attributes.</li> </ol>"},{"location":"guides/custom-feature-extractor/#using-the-extractor","title":"Using the Extractor","text":"<pre><code>extractor = AmplitudeFeatureExtractor(time_steady=100.0)\nfeatures = extractor.extract_features(solution)\n\n# Feature names are automatically generated\nprint(extractor.feature_names)  # ['amplitude_1', 'amplitude_2', ...]\n</code></pre>"},{"location":"guides/custom-feature-extractor/#custom-feature-names","title":"Custom Feature Names","text":"<p>By default, feature names are generated automatically from the class name:</p> <ul> <li><code>AmplitudeFeatureExtractor</code> \u2192 <code>amplitude_1</code>, <code>amplitude_2</code>, ...</li> <li><code>SynchronizationFeatureExtractor</code> \u2192 <code>synchronization_1</code>, <code>synchronization_2</code>, ...</li> </ul>"},{"location":"guides/custom-feature-extractor/#overriding-feature-names","title":"Overriding Feature Names","text":"<p>To use custom, meaningful names, set <code>_feature_names</code> in <code>__init__</code>:</p> <pre><code>class SynchronizationFeatureExtractor(FeatureExtractor):\n    def __init__(\n        self,\n        n_nodes: int,\n        time_steady: float = 1000.0,\n    ):\n        super().__init__(time_steady=time_steady)\n        self.n_nodes = n_nodes\n        # Define custom feature names\n        self._feature_names = [\n            \"max_deviation_x\",\n            \"max_deviation_y\",\n            \"max_deviation_z\",\n            \"max_deviation_all\",\n        ]\n\n    def extract_features(self, solution: Solution) -&gt; torch.Tensor:\n        y_filtered: torch.Tensor = self.filter_time(solution)\n        # ... compute features ...\n        return features  # shape: (n_samples, 4)\n</code></pre> <p>When <code>_feature_names</code> is set, it takes precedence over automatic name generation.</p>"},{"location":"guides/custom-feature-extractor/#complete-example","title":"Complete Example","text":"<pre><code>import torch\nfrom pybasin.feature_extractors.feature_extractor import FeatureExtractor\nfrom pybasin.solution import Solution\n\n\nclass MeanAndStdFeatureExtractor(FeatureExtractor):\n    \"\"\"Extract mean and standard deviation of each state variable.\"\"\"\n\n    def __init__(self, n_states: int, time_steady: float = 0.0):\n        super().__init__(time_steady=time_steady)\n        self.n_states = n_states\n        # Custom names: mean_0, std_0, mean_1, std_1, ...\n        self._feature_names = []\n        for i in range(n_states):\n            self._feature_names.extend([f\"mean_{i}\", f\"std_{i}\"])\n\n    def extract_features(self, solution: Solution) -&gt; torch.Tensor:\n        y_filtered: torch.Tensor = self.filter_time(solution)\n        # y_filtered: (n_times, n_samples, n_states)\n\n        mean_vals: torch.Tensor = y_filtered.mean(dim=0)  # (n_samples, n_states)\n        std_vals: torch.Tensor = y_filtered.std(dim=0)    # (n_samples, n_states)\n\n        # Interleave: [mean_0, std_0, mean_1, std_1, ...]\n        features: torch.Tensor = torch.stack(\n            [mean_vals, std_vals], dim=2\n        ).reshape(mean_vals.shape[0], -1)\n\n        return features\n</code></pre>"},{"location":"guides/torchode-solver/","title":"TorchOdeSolver - Alternative ODE Solver","text":"<p>This document explains the <code>TorchOdeSolver</code> implementation, an alternative to <code>TorchDiffEqSolver</code>.</p>"},{"location":"guides/torchode-solver/#overview","title":"Overview","text":"<p><code>TorchOdeSolver</code> is a PyTorch-based ODE solver that uses the torchode library. It provides:</p> <ul> <li>JIT Compilation: Optional PyTorch JIT compilation for better performance</li> <li>Batch Parallelization: Efficient parallel solving across batches</li> <li>Multiple Methods: Various integration methods (dopri5, tsit5, euler, etc.)</li> <li>GPU Support: Full CUDA support like TorchDiffEqSolver</li> </ul>"},{"location":"guides/torchode-solver/#performance-comparison","title":"Performance Comparison","text":"<p>\u26a0\ufe0f Important: In the current implementation, TorchDiffEqSolver is faster than TorchOdeSolver for single-trajectory integration:</p> <ul> <li>TorchDiffEqSolver: ~76 seconds for 10,000 samples (pendulum case study)</li> <li>TorchOdeSolver: ~119 seconds for 10,000 samples (pendulum case study)</li> </ul> <p>This is because:</p> <ol> <li>The current architecture integrates one trajectory at a time (batch_size=1)</li> <li>torchode's batch parallelization doesn't help with batch_size=1</li> <li>torchdiffeq is more optimized for single-trajectory integration</li> </ol> <p>When TorchOdeSolver would be faster:</p> <ul> <li>When integrating multiple trajectories in parallel (requires code restructuring)</li> <li>When using JIT compilation with repeated solves of the same system</li> <li>For problems where variable step sizes per trajectory are needed</li> </ul>"},{"location":"guides/torchode-solver/#installation","title":"Installation","text":"<p>To use <code>TorchOdeSolver</code>, you need to install the <code>torchode</code> package:</p> <pre><code># Using pip\npip install torchode\n\n# Using uv\nuv add torchode\n\n# Or install with the optional solvers dependency\npip install -e \".[solvers]\"\n</code></pre>"},{"location":"guides/torchode-solver/#comparison-torchdiffeqsolver-vs-torchodesolver","title":"Comparison: TorchDiffEqSolver vs TorchOdeSolver","text":""},{"location":"guides/torchode-solver/#torchdiffeqsolver-torchdiffeq","title":"TorchDiffEqSolver (torchdiffeq)","text":"<ul> <li>Default Solver: dopri5 (Dormand-Prince 5(4))</li> <li>Similar to: MATLAB's ode45</li> <li>Pros:</li> <li>Well-established, widely used</li> <li>Adjoint method for memory-efficient backpropagation</li> <li>Simple API</li> <li>Cons:</li> <li>No batch parallelization</li> <li>No JIT compilation support</li> </ul>"},{"location":"guides/torchode-solver/#torchodesolver-torchode","title":"TorchOdeSolver (torchode)","text":"<ul> <li>Default Solver: dopri5 (Dormand-Prince 5(4))</li> <li>Pros:</li> <li>JIT compilation support for performance</li> <li>Batch parallelization (different step sizes per sample)</li> <li>Modern PyTorch integration</li> <li>Multiple solver methods</li> <li>Cons:</li> <li>Newer library, less widespread adoption</li> <li>More complex API</li> </ul>"},{"location":"guides/torchode-solver/#available-methods","title":"Available Methods","text":""},{"location":"guides/torchode-solver/#adaptive-step-methods","title":"Adaptive-Step Methods","text":"<ul> <li><code>dopri5</code> (default): Dormand-Prince 5(4) - similar to MATLAB's ode45</li> <li><code>tsit5</code>: Tsitouras 5(4) - often more efficient than dopri5</li> </ul>"},{"location":"guides/torchode-solver/#fixed-step-methods","title":"Fixed-Step Methods","text":"<ul> <li><code>euler</code>: Explicit Euler (1st order)</li> <li><code>midpoint</code>: Explicit midpoint (2nd order)</li> <li><code>heun</code>: Heun's method (2nd order)</li> </ul>"},{"location":"guides/torchode-solver/#usage-example","title":"Usage Example","text":""},{"location":"guides/torchode-solver/#basic-usage","title":"Basic Usage","text":"<pre><code>from pybasin.solver import TorchOdeSolver\n\n# Create solver with default settings (dopri5)\nsolver = TorchOdeSolver(\n    time_span=(0, 1000),\n    fs=25,\n    device=\"cuda\"\n)\n</code></pre>"},{"location":"guides/torchode-solver/#with-custom-settings","title":"With Custom Settings","text":"<pre><code>solver = TorchOdeSolver(\n    time_span=(0, 1000),\n    fs=25,\n    device=\"cuda\",\n    method=\"tsit5\",      # Use Tsitouras method\n    rtol=1e-8,           # Relative tolerance\n    atol=1e-6,           # Absolute tolerance\n    use_jit=True         # Enable JIT compilation\n)\n</code></pre>"},{"location":"guides/torchode-solver/#complete-example","title":"Complete Example","text":"<p>See <code>case_studies/pendulum/main_pendulum_case1_torchode.py</code> for a complete working example.</p> <pre><code>from case_studies.pendulum.setup_pendulum_system_torchode import (\n    setup_pendulum_system_torchode,\n)\nfrom pybasin.basin_stability_estimator import BasinStabilityEstimator\n\n# Setup system with TorchOdeSolver\nprops = setup_pendulum_system_torchode()\n\n# Create estimator\nbse = BasinStabilityEstimator(\n    n=props[\"n\"],\n    ode_system=props[\"ode_system\"],\n    sampler=props[\"sampler\"],\n    solver=props[\"solver\"],  # Using TorchOdeSolver\n    feature_extractor=props[\"feature_extractor\"],\n    cluster_classifier=props[\"cluster_classifier\"],\n)\n\n# Estimate basin stability\nbasin_stability = bse.estimate_bs()\n</code></pre>"},{"location":"guides/torchode-solver/#running-the-test-case-study","title":"Running the Test Case Study","text":"<p>To test the TorchOdeSolver implementation:</p> <pre><code># First, install torchode\nuv add torchode\n\n# Run the pendulum case study with TorchOdeSolver\npython case_studies/pendulum/main_pendulum_case1_torchode.py\n</code></pre>"},{"location":"guides/torchode-solver/#performance-tips","title":"Performance Tips","text":"<ol> <li>Enable JIT Compilation: Set <code>use_jit=True</code> for repeated solves with the same system</li> </ol> <pre><code>solver = TorchOdeSolver(time_span=(0, 1000), fs=25, use_jit=True)\n</code></pre> <ol> <li> <p>Choose the Right Method:</p> </li> <li> <p>For general problems: <code>dopri5</code> (default)</p> </li> <li>For better efficiency: <code>tsit5</code></li> <li> <p>For simple/fast problems: <code>euler</code> or <code>midpoint</code> (fixed step)</p> </li> <li> <p>Adjust Tolerances:</p> </li> <li> <p>Tighter tolerances (smaller rtol/atol) = more accurate but slower</p> </li> <li> <p>Looser tolerances = faster but less accurate</p> </li> <li> <p>GPU Acceleration: Always specify <code>device=\"cuda\"</code> if available</p> </li> </ol>"},{"location":"guides/torchode-solver/#implementation-details","title":"Implementation Details","text":"<p>The <code>TorchOdeSolver</code> class:</p> <ul> <li>Inherits from the abstract <code>Solver</code> base class</li> <li>Implements the <code>_integrate()</code> method</li> <li>Handles batch dimension conversion (torchode expects batched inputs)</li> <li>Supports caching like TorchDiffEqSolver</li> <li>Falls back gracefully if torchode is not installed</li> </ul>"},{"location":"guides/torchode-solver/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/torchode-solver/#import-error","title":"Import Error","text":"<pre><code>ImportError: torchode is not installed\n</code></pre> <p>Solution: Install torchode with <code>pip install torchode</code></p>"},{"location":"guides/torchode-solver/#unknown-method-error","title":"Unknown Method Error","text":"<pre><code>ValueError: Unknown method: xyz\n</code></pre> <p>Solution: Use one of the available methods: dopri5, tsit5, euler, midpoint, heun</p>"},{"location":"guides/torchode-solver/#integration-failed","title":"Integration Failed","text":"<pre><code>RuntimeError: torchode integration failed\n</code></pre> <p>Solution: Try adjusting tolerances or using a different method</p>"},{"location":"guides/torchode-solver/#references","title":"References","text":"<ul> <li>torchode GitHub</li> <li>torchode Documentation</li> <li>torchode Paper</li> <li>torchdiffeq GitHub (for comparison)</li> </ul>"},{"location":"guides/type-safety-generics/","title":"Type Safety and Generics in pyBasin","text":""},{"location":"guides/type-safety-generics/#overview","title":"Overview","text":"<p>pyBasin uses Python's generic type system to provide strong type safety for ODE parameters across the entire library. This guide explains how to use generics effectively when extending pyBasin with your own ODE systems.</p>"},{"location":"guides/type-safety-generics/#why-generics","title":"Why Generics?","text":"<p>The generic type system provides:</p> <ol> <li>Type Safety: Static type checkers (mypy, pyright) can verify parameter types at development time</li> <li>IDE Autocomplete: Your IDE will know exactly which parameters are available</li> <li>Self-Documentation: Types serve as documentation for what parameters an ODE system expects</li> <li>Refactoring Safety: Renaming or changing parameter types will show errors across your codebase</li> </ol>"},{"location":"guides/type-safety-generics/#how-to-define-a-new-ode-system","title":"How to Define a New ODE System","text":""},{"location":"guides/type-safety-generics/#step-1-define-your-parameter-type","title":"Step 1: Define Your Parameter Type","text":"<p>Use <code>TypedDict</code> to define the exact parameters your ODE system needs:</p> <pre><code>from typing import TypedDict\n\nclass MyODEParams(TypedDict):\n    \"\"\"Parameters for my ODE system.\"\"\"\n    alpha: float      # damping coefficient\n    beta: float       # forcing amplitude\n    omega: float      # forcing frequency\n    initial_mass: float  # initial mass\n</code></pre> <p>Benefits:</p> <ul> <li>Type checkers will enforce that all required keys are present</li> <li>IDE will autocomplete parameter names</li> <li>Docstrings on each field document what they mean</li> </ul>"},{"location":"guides/type-safety-generics/#step-2-create-your-ode-system","title":"Step 2: Create Your ODE System","text":"<p>Inherit from <code>ODESystem[YourParamsType]</code>:</p> <pre><code>from pybasin.ode_system import ODESystem\nimport torch\n\nclass MyODE(ODESystem[MyODEParams]):\n    def __init__(self, params: MyODEParams):\n        super().__init__(params)\n        # self.params is now typed as MyODEParams!\n\n    def ode(self, t: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n        # Type checker knows these keys exist\n        alpha = self.params[\"alpha\"]\n        beta = self.params[\"beta\"]\n        omega = self.params[\"omega\"]\n\n        # ... your ODE logic here ...\n        dy_dt = -alpha * y + beta * torch.sin(omega * t)\n        return dy_dt\n\n    def get_str(self) -&gt; str:\n        return f\"My ODE with \u03b1={self.params['alpha']}\"\n</code></pre>"},{"location":"guides/type-safety-generics/#step-3-use-type-safe-parameters-everywhere","title":"Step 3: Use Type-Safe Parameters Everywhere","text":"<p>When creating classifiers or other components, you can pass your typed parameters:</p> <pre><code>from pybasin.predictors.knn_classifier import KNNClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Create your parameters with full type safety\nparams: MyODEParams = {\n    \"alpha\": 0.1,\n    \"beta\": 1.0,\n    \"omega\": 2.0,\n    \"initial_mass\": 1.5,\n}\n\n# Type checker ensures params matches MyODEParams\node_system = MyODE(params)\n\n# Pass the parameters to the classifier\nknn_classifier = KNNClassifier(\n    classifier=KNeighborsClassifier(n_neighbors=3),\n    template_y0=[[0.0, 1.0], [1.0, 0.0]],\n    labels=[\"stable\", \"unstable\"],\n    ode_params=params,\n)\n</code></pre>"},{"location":"guides/type-safety-generics/#complete-example-pendulum-system","title":"Complete Example: Pendulum System","text":"<p>Here's the pendulum example showing full type safety:</p> <pre><code># 1. Define parameters\nfrom typing import TypedDict\n\nclass PendulumParams(TypedDict):\n    \"\"\"Parameters for the pendulum ODE system.\"\"\"\n    alpha: float  # damping coefficient\n    T: float      # external torque\n    K: float      # stiffness coefficient\n\n# 2. Create ODE system\nfrom pybasin.ode_system import ODESystem\nimport torch\n\nclass PendulumODE(ODESystem[PendulumParams]):\n    def __init__(self, params: PendulumParams):\n        super().__init__(params)\n\n    def ode(self, t: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n        # IDE autocompletes these parameter names!\n        alpha = self.params[\"alpha\"]\n        T = self.params[\"T\"]\n        K = self.params[\"K\"]\n\n        theta = y[..., 0]\n        theta_dot = y[..., 1]\n\n        dtheta_dt = theta_dot\n        dtheta_dot_dt = -alpha * theta_dot + T - K * torch.sin(theta)\n\n        return torch.stack([dtheta_dt, dtheta_dot_dt], dim=-1)\n\n    def get_str(self) -&gt; str:\n        return (\n            f\"Pendulum ODE:\\n\"\n            f\"  d\u03b8/dt = \u03c9\\n\"\n            f\"  d\u03c9/dt = -{self.params['alpha']}\u03c9 + \"\n            f\"{self.params['T']} - {self.params['K']}sin(\u03b8)\"\n        )\n\n# 3. Use with type safety\ndef setup_pendulum():\n    # Type checker verifies all required keys are present\n    params: PendulumParams = {\n        \"alpha\": 0.1,\n        \"T\": 0.5,\n        \"K\": 1.0,\n    }\n\n    # If you forget a parameter or misspell it, you'll get a type error!\n    # params: PendulumParams = {\"alpha\": 0.1}  # ERROR: Missing 'T' and 'K'\n\n    ode = PendulumODE(params)\n    return ode\n</code></pre>"},{"location":"guides/type-safety-generics/#comparison-with-typescript","title":"Comparison with TypeScript","text":"<p>If you're familiar with TypeScript, here's how the concepts map:</p>"},{"location":"guides/type-safety-generics/#typescript","title":"TypeScript:","text":"<pre><code>interface PendulumParams {\n  alpha: number;\n  T: number;\n  K: number;\n}\n\nclass PendulumODE extends ODESystem&lt;PendulumParams&gt; {\n  constructor(params: PendulumParams) {\n    super(params);\n    // this.params is typed as PendulumParams\n  }\n}\n</code></pre>"},{"location":"guides/type-safety-generics/#python-pybasin","title":"Python (pyBasin):","text":"<pre><code>class PendulumParams(TypedDict):\n    alpha: float\n    T: float\n    K: float\n\nclass PendulumODE(ODESystem[PendulumParams]):\n    def __init__(self, params: PendulumParams):\n        super().__init__(params)\n        # self.params is typed as PendulumParams\n</code></pre> <p>The main difference is that Python uses <code>TypedDict</code> instead of <code>interface</code>, and square brackets <code>[]</code> for generics instead of angle brackets <code>&lt;&gt;</code>.</p>"},{"location":"guides/type-safety-generics/#type-checking","title":"Type Checking","text":"<p>To verify your types are correct, run:</p> <pre><code># With pyright (recommended for VS Code)\nuv run pyright\n\n# Or with mypy\nuv run mypy src/\n</code></pre>"},{"location":"guides/type-safety-generics/#common-patterns","title":"Common Patterns","text":""},{"location":"guides/type-safety-generics/#optional-parameters","title":"Optional Parameters","text":"<pre><code>from typing import TypedDict, NotRequired\n\nclass OptionalParams(TypedDict):\n    alpha: float                    # Required\n    beta: NotRequired[float]        # Optional (Python 3.11+)\n</code></pre>"},{"location":"guides/type-safety-generics/#multiple-parameter-types","title":"Multiple Parameter Types","text":"<p>If you need to support multiple parameter configurations:</p> <pre><code>from typing import Union\n\nParamVariant1 = TypedDict(\"ParamVariant1\", {\"a\": float, \"b\": float})\nParamVariant2 = TypedDict(\"ParamVariant2\", {\"x\": float, \"y\": float})\n\nclass FlexibleODE(ODESystem[Union[ParamVariant1, ParamVariant2]]):\n    def ode(self, t, y):\n        if \"a\" in self.params:\n            # Handle variant 1\n            pass\n        else:\n            # Handle variant 2\n            pass\n</code></pre>"},{"location":"guides/type-safety-generics/#best-practices","title":"Best Practices","text":"<ol> <li>Always use TypedDict for parameters: Don't use plain <code>dict[str, float]</code></li> <li>Document your parameter fields: Add docstrings or comments to each field</li> <li>Be specific with types: Use <code>float</code>, <code>int</code>, <code>str</code> instead of <code>Any</code></li> <li>Run type checkers regularly: Integrate <code>pyright</code> or <code>mypy</code> into your workflow</li> <li>Keep parameters immutable: Don't modify <code>self.params</code> after initialization</li> </ol>"},{"location":"guides/type-safety-generics/#troubleshooting","title":"Troubleshooting","text":""},{"location":"guides/type-safety-generics/#type-is-not-assignable-to-typevar","title":"\"Type is not assignable to TypeVar\"","text":"<p>If you see this error, make sure:</p> <ul> <li>Your parameter type is a <code>TypedDict</code> or plain <code>dict</code></li> <li>You're consistently using the same generic type throughout</li> </ul>"},{"location":"guides/type-safety-generics/#ide-not-showing-autocomplete","title":"IDE not showing autocomplete","text":"<ul> <li>Restart your Python language server</li> <li>Ensure your <code>TypedDict</code> is properly defined</li> <li>Check that you're using the latest version of your type checker</li> </ul>"},{"location":"guides/type-safety-generics/#further-reading","title":"Further Reading","text":"<ul> <li>Python TypedDict documentation</li> <li>PEP 589 \u2013 TypedDict</li> <li>Pyright documentation</li> </ul>"},{"location":"guides/unbounded-trajectories/","title":"Handling Unbounded Trajectories","text":""},{"location":"guides/unbounded-trajectories/#overview","title":"Overview","text":"<p>When computing basin stability, some initial conditions may lead to unbounded trajectories that diverge to infinity. These trajectories need special handling to:</p> <ol> <li>Stop integration early to save computation time</li> <li>Classify correctly as a distinct attractor state</li> <li>Avoid numerical overflow in the solver</li> </ol> <p>This guide explains the recommended approaches for handling unbounded trajectories in pyBasin.</p> <p>Quick Recommendation</p> <p>Use JaxSolver with event functions for the best performance and flexibility when dealing with unbounded trajectories.</p>"},{"location":"guides/unbounded-trajectories/#understanding-the-problem","title":"Understanding the Problem","text":"<p>In dynamical systems like the Lorenz system, some regions of the state space lead to trajectories that grow without bound:</p> <pre><code># Example: Lorenz \"broken butterfly\" system\nparams = {\"sigma\": 0.12, \"r\": 0.0, \"b\": -0.6}\n\n# Some initial conditions lead to bounded attractors:\nic_butterfly1 = [0.8, -3.0, 0.0]   # \u2192 bounded attractor\nic_butterfly2 = [-0.8, 3.0, 0.0]   # \u2192 bounded attractor\n\n# Others lead to unbounded trajectories:\nic_unbounded = [10.0, 50.0, 0.0]   # \u2192 |y| \u2192 \u221e\n</code></pre> <p>Without proper handling, unbounded trajectories will:</p> <ul> <li>Waste computation time integrating to large values</li> <li>Risk numerical overflow errors</li> <li>Contaminate basin stability estimates</li> </ul>"},{"location":"guides/unbounded-trajectories/#recommended-approach-jaxsolver-with-event-functions","title":"Recommended Approach: JaxSolver with Event Functions","text":"<p>The recommended solution is to use <code>JaxSolver</code> with an event function that stops integration when trajectories exceed a threshold.</p>"},{"location":"guides/unbounded-trajectories/#why-jaxsolver","title":"Why JaxSolver?","text":"<p>JAX's <code>diffrax</code> library supports event-based termination where each trajectory in a batch can stop independently:</p> <ul> <li>\u2705 Individual termination: Each trajectory stops when it meets the condition</li> <li>\u2705 Efficient: Other trajectories continue integrating</li> <li>\u2705 Clean classification: Stopped trajectories are marked appropriately</li> </ul>"},{"location":"guides/unbounded-trajectories/#complete-example","title":"Complete Example","text":"<p>Here's a complete example from the Lorenz case study:</p> <pre><code>import torch\nfrom case_studies.lorenz.lorenz_jax_ode import LorenzJaxODE, LorenzParams\nfrom case_studies.lorenz.setup_lorenz_system import lorenz_stop_event\nfrom pybasin.basin_stability_estimator import BasinStabilityEstimator\nfrom pybasin.sampler import UniformRandomSampler\nfrom pybasin.solvers.jax_solver import JaxSolver\n\ndef main():\n    # Number of initial conditions to sample\n    n = 10_000\n\n    # Auto-detect device (use GPU if available)\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Setting up Lorenz system on device: {device}\")\n\n    # Parameters for broken butterfly system\n    params: LorenzParams = {\"sigma\": 0.12, \"r\": 0.0, \"b\": -0.6}\n    ode_system = LorenzJaxODE(params)\n\n    # Sample uniformly in the region of interest\n    sampler = UniformRandomSampler(\n        min_limits=[-10.0, -20.0, 0.0],\n        max_limits=[10.0, 20.0, 0.0],\n        device=device\n    )\n\n    # JaxSolver with event function to stop unbounded trajectories\n    solver = JaxSolver(\n        device=device,\n        event_fn=lorenz_stop_event,  # \u2190 Key: event function\n    )\n\n    # Estimate basin stability\n    bse = BasinStabilityEstimator(\n        n=n,\n        ode_system=ode_system,\n        sampler=sampler,\n        solver=solver,\n        save_to=\"results_lorenz\",\n    )\n\n    basin_stability = bse.estimate_bs()\n    print(\"Basin Stability:\", basin_stability)\n\n    return bse\n\nif __name__ == \"__main__\":\n    bse = main()\n</code></pre>"},{"location":"guides/unbounded-trajectories/#defining-event-functions","title":"Defining Event Functions","text":"<p>The event function determines when to stop integration. Here's the <code>lorenz_stop_event</code> example:</p> <pre><code>import jax.numpy as jnp\nfrom diffrax import Event\n\ndef lorenz_stop_event(t, y, args):\n    \"\"\"\n    Stop integration when trajectory magnitude exceeds 200.\n\n    Args:\n        t: Current time\n        y: Current state [x, y, z]\n        args: Additional arguments (unused)\n\n    Returns:\n        Scalar value that triggers event when it crosses zero.\n        Negative = continue, positive = stop.\n    \"\"\"\n    # Compute maximum absolute value across all state components\n    max_magnitude = jnp.max(jnp.abs(y))\n\n    # Return (threshold - magnitude)\n    # When magnitude &gt; 200, this becomes negative \u2192 event triggers\n    return 200.0 - max_magnitude\n</code></pre> <p>Event Function Behavior</p> <p>The event triggers when the returned value crosses zero from positive to negative. Design your function accordingly:</p> <pre><code>- `threshold - magnitude`: triggers when magnitude exceeds threshold\n- `magnitude - threshold`: triggers when magnitude falls below threshold\n</code></pre>"},{"location":"guides/unbounded-trajectories/#benefits","title":"Benefits","text":"<p>\u2705 Performance: Only unbounded trajectories stop early \u2705 Accuracy: Bounded trajectories integrate to full completion \u2705 Simplicity: Clean, declarative API \u2705 Flexibility: Custom event functions for any stopping condition</p>"},{"location":"guides/unbounded-trajectories/#alternative-approach-zero-masking-with-torchdiffeq","title":"Alternative Approach: Zero Masking with TorchDiffEq","text":"<p>An alternative approach uses zero masking where derivatives are set to zero once a stopping condition is met. This \"freezes\" the solution at the threshold value.</p> <p>Performance Considerations</p> <p>This approach is slower than JaxSolver with events because:</p> <pre><code>- All trajectories integrate for the full time span (no early stopping)\n- The solver continues stepping even though derivatives are zero\n- Better suited for systems where most trajectories are bounded\n</code></pre>"},{"location":"guides/unbounded-trajectories/#how-zero-masking-works","title":"How Zero Masking Works","text":"<p>The ODE system returns zero derivatives when a trajectory exceeds the threshold:</p> <pre><code>import torch\nfrom pybasin.ode_system import ODESystem\n\nclass LorenzODE(ODESystem):\n    def ode(self, t: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:\n        \"\"\"\n        Compute Lorenz dynamics with zero masking for unbounded trajectories.\n        \"\"\"\n        # Compute standard Lorenz dynamics\n        sigma = self.params[\"sigma\"]\n        r = self.params[\"r\"]\n        b = self.params[\"b\"]\n\n        x, y_coord, z = y[..., 0], y[..., 1], y[..., 2]\n\n        dx_dt = sigma * (y_coord - x)\n        dy_dt = r * x - x * z - y_coord\n        dz_dt = x * y_coord - b * z\n\n        dydt = torch.stack([dx_dt, dy_dt, dz_dt], dim=-1)\n\n        # Create mask: 1 if |y| &lt; 200, otherwise 0\n        mask = (torch.max(torch.abs(y), dim=-1)[0] &lt; 200).float().unsqueeze(-1)\n\n        # Return masked derivatives (zeros for unbounded trajectories)\n        return dydt * mask\n</code></pre>"},{"location":"guides/unbounded-trajectories/#key-points","title":"Key Points","text":"<ul> <li>Freezing behavior: When <code>|y| \u2265 200</code>, derivatives become zero, \"freezing\" the solution</li> <li>No early termination: Integration continues for the full time span</li> <li>Post-processing: Feature extraction must detect frozen trajectories by checking final magnitude</li> </ul>"},{"location":"guides/unbounded-trajectories/#using-with-torchdiffeqsolver","title":"Using with TorchDiffEqSolver","text":"<pre><code>from pybasin.solvers.torchdiffeq_solver import TorchDiffEqSolver\n\nsolver = TorchDiffEqSolver(\n    device=device,\n    t_span=(0.0, 1000.0),\n    method=\"dopri5\",\n    rtol=1e-8,\n    atol=1e-6,\n)\n\n# Use with LorenzODE that has zero masking\nbse = BasinStabilityEstimator(\n    n=n,\n    ode_system=LorenzODE(params),  # Has zero masking in ode()\n    sampler=sampler,\n    solver=solver,\n)\n</code></pre>"},{"location":"guides/unbounded-trajectories/#limitations-of-torchdiffeq-event-handling","title":"Limitations of TorchDiffEq Event Handling","text":"<p>TorchDiffEq Limitation</p> <p><code>torchdiffeq.odeint_event()</code> does not support individual trajectory termination. When the event condition is met for any trajectory in a batch, all integrations stop simultaneously.</p> <pre><code>This makes `odeint_event` unsuitable for basin stability estimation where different trajectories should stop at different times.\n</code></pre>"},{"location":"guides/unbounded-trajectories/#comparison","title":"Comparison","text":"Feature JaxSolver + Event TorchDiffEq + Zero Mask Individual termination \u2705 Yes \u274c No (zero masking workaround) Performance \u2705 Fast (early stopping) \u26a0\ufe0f Slower (full integration) Setup complexity \ud83d\udfe2 Simple (event function) \ud83d\udfe2 Simple (mask in ODE) GPU support \u2705 Yes \u2705 Yes Batch processing \u2705 Efficient \u26a0\ufe0f Less efficient Best for Most use cases Systems with few unbounded trajectories"},{"location":"guides/unbounded-trajectories/#best-practices","title":"Best Practices","text":""},{"location":"guides/unbounded-trajectories/#1-choose-the-right-threshold","title":"1. Choose the Right Threshold","text":"<p>Set your stopping threshold based on your system's dynamics:</p> <pre><code># Too low: May incorrectly classify bounded trajectories\nthreshold = 10.0  # \u274c May catch transient behavior\n\n# Good: Well above bounded attractor magnitudes\nthreshold = 200.0  # \u2705 Clear separation\n\n# Check your attractors first:\n# - Bounded attractors: |y| &lt; 50\n# - Set threshold at 4\u00d7 max bounded value\n</code></pre>"},{"location":"guides/unbounded-trajectories/#2-verify-event-triggering","title":"2. Verify Event Triggering","text":"<p>Test your event function with known unbounded initial conditions:</p> <pre><code>def test_event_function():\n    \"\"\"Verify event triggers for unbounded IC.\"\"\"\n    unbounded_ic = torch.tensor([10.0, 50.0, 0.0])\n\n    solution = solver.solve(\n        ode_system=ode_system,\n        initial_conditions=unbounded_ic,\n    )\n\n    # Check if integration stopped early\n    assert solution.t[-1] &lt; t_final, \"Event should trigger before t_final\"\n    assert torch.max(torch.abs(solution.y[-1])) &gt;= threshold\n</code></pre>"},{"location":"guides/unbounded-trajectories/#3-handle-classification-correctly","title":"3. Handle Classification Correctly","text":"<p>Ensure your feature extractor identifies unbounded trajectories:</p> <pre><code>def extract_features(solution):\n    \"\"\"Extract features, handling unbounded trajectories.\"\"\"\n    max_magnitude = torch.max(torch.abs(solution.y), dim=0)[0]\n\n    if max_magnitude &gt;= 200.0:\n        # Unbounded trajectory\n        return torch.tensor([0.0, 0.0])  # Special marker\n    else:\n        # Bounded trajectory - extract features from attractor\n        tail = solution.y[-100:]  # Last 100 points\n        mean_x = torch.mean(tail[:, 0])\n\n        if mean_x &gt; 0:\n            return torch.tensor([1.0, 0.0])  # Attractor 1\n        else:\n            return torch.tensor([0.0, 1.0])  # Attractor 2\n</code></pre>"},{"location":"guides/unbounded-trajectories/#summary","title":"Summary","text":"<ul> <li>Recommended: Use <code>JaxSolver</code> with event functions for efficient, individual trajectory termination</li> <li>Alternative: Use zero masking with <code>TorchDiffEqSolver</code> if you need PyTorch-only solution</li> <li>Avoid: Using <code>odeint_event()</code> for basin stability (stops all trajectories simultaneously)</li> <li>Test: Always verify your event function or masking logic with known unbounded cases</li> </ul> <p>For more examples, see the Lorenz case study.</p>"},{"location":"user-guide/adaptive-studies/","title":"Adaptive Parameter Studies","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/adaptive-studies/#use-case","title":"Use Case","text":"<p>Study how basin stability changes with a system parameter using <code>ASBasinStabilityEstimator</code>.</p>"},{"location":"user-guide/adaptive-studies/#the-asbasinstabilityestimator-class","title":"The <code>ASBasinStabilityEstimator</code> Class","text":"<p>Runs BSE multiple times for different parameter values, returning parameter values, BS values, and full results per run.</p>"},{"location":"user-guide/adaptive-studies/#example-pendulum-damping-study","title":"Example: Pendulum Damping Study","text":"<pre><code>from pybasin.as_basin_stability_estimator import ASBasinStabilityEstimator\n\nas_bse = ASBasinStabilityEstimator(\n    n=10_000,\n    ode_system=pendulum_ode,\n    sampler=sampler,\n    as_params={\"gamma\": np.linspace(0.1, 0.5, 10)},\n)\nparams, bs_vals, results = as_bse.estimate_as_bs()\n</code></pre>"},{"location":"user-guide/adaptive-studies/#visualization-with-asplotter","title":"Visualization with <code>ASPlotter</code>","text":"<p>Use the <code>ASPlotter</code> class to create parameter vs BS bifurcation diagrams.</p>"},{"location":"user-guide/bse-overview/","title":"Basin Stability Estimator Overview","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/bse-overview/#what-is-basin-stability","title":"What is Basin Stability?","text":"<p>Basin stability is a nonlinear measure of stability that quantifies the probability that a system returns to a given attractor when perturbed with random initial conditions.</p>"},{"location":"user-guide/bse-overview/#the-basinstabilityestimator-class","title":"The <code>BasinStabilityEstimator</code> Class","text":"<p>The <code>BasinStabilityEstimator</code> is the core class for computing basin stability values.</p>"},{"location":"user-guide/bse-overview/#constructor-parameters","title":"Constructor Parameters","text":"Parameter Type Default Description <code>ode_system</code> <code>ODESystemProtocol</code> Required The dynamical system <code>sampler</code> <code>Sampler</code> Required Initial condition generator <code>n</code> <code>int</code> <code>10_000</code> Number of samples <code>solver</code> <code>SolverProtocol</code> Auto-detect ODE integrator <code>feature_extractor</code> <code>FeatureExtractor</code> <code>TorchFeatureExtractor</code> Feature computation <code>predictor</code> <code>LabelPredictor</code> <code>HDBSCANClusterer</code> Classification method <code>feature_selector</code> <code>BaseEstimator</code> <code>DefaultFeatureSelector</code> Feature filtering <code>detect_unbounded</code> <code>bool</code> <code>True</code> Stop diverging trajectories <code>save_to</code> <code>str</code> <code>None</code> Output directory"},{"location":"user-guide/bse-overview/#default-flow","title":"Default Flow","text":"<pre><code>Sample ICs \u2192 Integrate ODEs \u2192 Detect Unbounded \u2192 Extract Features\n\u2192 Filter Features \u2192 Cluster/Classify \u2192 Compute BS Values\n</code></pre>"},{"location":"user-guide/bse-overview/#automatic-solver-selection","title":"Automatic Solver Selection","text":"<ul> <li>If <code>ode_system</code> is <code>JaxODESystem</code> \u2192 uses <code>JaxSolver</code></li> <li>If <code>ode_system</code> is <code>ODESystem</code> \u2192 uses <code>TorchDiffEqSolver</code></li> </ul>"},{"location":"user-guide/bse-overview/#unboundedness-detection","title":"Unboundedness Detection","text":"<p>Only active when <code>detect_unbounded=True</code> AND solver is <code>JaxSolver</code> with <code>event_fn</code>.</p> <p>See Handling Unbounded Trajectories for details.</p>"},{"location":"user-guide/bse-overview/#output-attributes","title":"Output Attributes","text":"<ul> <li><code>bse.bs_vals</code>: Dict of basin stability values per class</li> <li><code>bse.y0</code>: Initial conditions tensor</li> <li><code>bse.solution</code>: Solution object with trajectories, features, labels</li> </ul>"},{"location":"user-guide/feature-extractors/","title":"Feature Extractors","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/feature-extractors/#overview","title":"Overview","text":"<p>Feature extractors compute time-series characteristics from trajectories that distinguish different attractor types.</p>"},{"location":"user-guide/feature-extractors/#base-class","title":"Base Class","text":"<p>All extractors inherit from <code>FeatureExtractor</code> and implement:</p> <ul> <li>Method: <code>extract_features(solution: Solution) -&gt; torch.Tensor</code></li> <li>Property: <code>feature_names</code></li> </ul>"},{"location":"user-guide/feature-extractors/#available-extractors","title":"Available Extractors","text":"Class Features GPU Speed Use Case <code>TorchFeatureExtractor</code> ~700 \u2705 Fast Default <code>JaxFeatureExtractor</code> ~50 \u2705 Fastest JAX-only workflows <code>TsFreshFeatureExtractor</code> ~700 \u274c Slow Reference/validation <code>NoldsFeatureExtractor</code> ~10 \u274c Slow Dynamical features only"},{"location":"user-guide/feature-extractors/#torchfeatureextractor-default","title":"TorchFeatureExtractor (Default)","text":"<pre><code>from pybasin.feature_extractors import TorchFeatureExtractor\n\nextractor = TorchFeatureExtractor(\n    fc_parameters=\"minimal\",  # or \"comprehensive\", custom dict\n    time_steady=800.0,  # Discard transient\n    device=\"cuda\",\n)\n</code></pre>"},{"location":"user-guide/feature-extractors/#creating-custom-feature-extractors","title":"Creating Custom Feature Extractors","text":"<p>See the Custom Feature Extractor guide.</p>"},{"location":"user-guide/feature-selectors/","title":"Feature Selectors","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/feature-selectors/#overview","title":"Overview","text":"<p>Feature selectors filter features before classification to remove constant, low-variance, or correlated features.</p>"},{"location":"user-guide/feature-selectors/#default-behavior","title":"Default Behavior","text":"<p><code>DefaultFeatureSelector</code> removes features with zero variance.</p>"},{"location":"user-guide/feature-selectors/#using-sklearn-transformers","title":"Using sklearn Transformers","text":"<pre><code>from sklearn.feature_selection import VarianceThreshold\n\nbse = BasinStabilityEstimator(\n    ...,\n    feature_selector=VarianceThreshold(threshold=0.01),\n)\n</code></pre>"},{"location":"user-guide/feature-selectors/#correlationselector","title":"CorrelationSelector","text":"<pre><code>from pybasin.feature_selector.correlation_selector import CorrelationSelector\n\nselector = CorrelationSelector(threshold=0.95)\n</code></pre>"},{"location":"user-guide/feature-selectors/#disabling-feature-selection","title":"Disabling Feature Selection","text":"<pre><code>bse = BasinStabilityEstimator(..., feature_selector=None)\n</code></pre>"},{"location":"user-guide/plotters/","title":"Plotters","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/plotters/#overview","title":"Overview","text":"<p>Plotters visualize basin stability results.</p>"},{"location":"user-guide/plotters/#available-plotters","title":"Available Plotters","text":"Class Type Use Case <code>MatplotlibPlotter</code> Static Publication figures, quick inspection <code>InteractivePlotter</code> Web app Exploration, presentations <code>ASPlotter</code> Static Parameter study bifurcation diagrams"},{"location":"user-guide/plotters/#matplotlibplotter","title":"MatplotlibPlotter","text":"<pre><code>from pybasin.plotters.matplotlib_plotter import MatplotlibPlotter\n\nplotter = MatplotlibPlotter(bse)\nplotter.plot_bse_results()      # 4-panel diagnostic plot\nplotter.plot_phase(x_var=0, y_var=1)  # Phase space\nplotter.plot_templates(plotted_var=0) # Template time series\n</code></pre>"},{"location":"user-guide/plotters/#interactiveplotter","title":"InteractivePlotter","text":"<pre><code>from pybasin.plotters.interactive_plotter import InteractivePlotter\n\nplotter = InteractivePlotter(\n    bse,\n    state_labels={0: \"\u03b8\", 1: \"\u03c9\"},\n)\nplotter.run(port=8050)  # Opens web browser\n</code></pre>"},{"location":"user-guide/plotters/#asplotter","title":"ASPlotter","text":"<p>Used for visualizing parameter study results from <code>ASBasinStabilityEstimator</code>.</p>"},{"location":"user-guide/predictors/","title":"Predictors","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/predictors/#overview","title":"Overview","text":"<p>Predictors classify trajectories into attractor classes based on extracted features.</p>"},{"location":"user-guide/predictors/#predictor-types","title":"Predictor Types","text":"<ul> <li>Unsupervised (<code>ClustererPredictor</code>): Discovers attractor classes automatically</li> <li>Supervised (<code>ClassifierPredictor</code>): Uses known template trajectories</li> </ul>"},{"location":"user-guide/predictors/#available-predictors","title":"Available Predictors","text":"Class Type Description <code>HDBSCANClusterer</code> Unsupervised Default, density-based, auto-tunes parameters <code>DBSCANClusterer</code> Unsupervised Classic DBSCAN <code>DynamicalClusterer</code> Unsupervised Physics-based two-stage clustering <code>KNNClassifier</code> Supervised K-nearest neighbors with templates <code>UnboundednessClusterer</code> Hybrid Detects unbounded trajectories"},{"location":"user-guide/predictors/#hdbscanclusterer-default","title":"HDBSCANClusterer (Default)","text":"<pre><code>from pybasin.predictors.hdbscan_clusterer import HDBSCANClusterer\n\npredictor = HDBSCANClusterer(\n    auto_tune=True,      # Auto-select min_cluster_size\n    assign_noise=True,   # Assign noise points to nearest cluster\n    min_cluster_size=50, # If auto_tune=False\n)\n</code></pre>"},{"location":"user-guide/predictors/#knnclassifier-supervised","title":"KNNClassifier (Supervised)","text":"<pre><code>from pybasin.predictors.knn_classifier import KNNClassifier\n\npredictor = KNNClassifier(\n    template_y0=[[0.0, 0.0], [1.0, 0.0]],  # Template ICs\n    labels=[\"FP\", \"LC\"],\n    k=5,\n)\n</code></pre>"},{"location":"user-guide/samplers/","title":"Samplers","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/samplers/#overview","title":"Overview","text":"<p>Samplers generate initial conditions for basin stability estimation.</p>"},{"location":"user-guide/samplers/#base-class","title":"Base Class","text":"<p>All samplers inherit from <code>Sampler</code> and implement:</p> <pre><code>def sample(n: int) -&gt; torch.Tensor\n</code></pre>"},{"location":"user-guide/samplers/#available-samplers","title":"Available Samplers","text":"Class Description Use Case <code>UniformRandomSampler</code> Uniform random in hypercube General purpose, most common <code>GridSampler</code> Evenly spaced grid 2D visualization, deterministic"},{"location":"user-guide/samplers/#uniformrandomsampler","title":"UniformRandomSampler","text":"<pre><code>from pybasin.sampler import UniformRandomSampler\n\nsampler = UniformRandomSampler(\n    min_limits=[-np.pi, -2.0],\n    max_limits=[np.pi, 2.0],\n    device=\"cuda\",  # optional\n)\n</code></pre>"},{"location":"user-guide/samplers/#gridsampler","title":"GridSampler","text":"<pre><code>from pybasin.sampler import GridSampler\n\nsampler = GridSampler(\n    min_limits=[-np.pi, -2.0],\n    max_limits=[np.pi, 2.0],\n    fixed_dims={2: 0.0},  # Fix 3rd dimension to 0\n)\n</code></pre>"},{"location":"user-guide/samplers/#creating-custom-samplers","title":"Creating Custom Samplers","text":"<p>Inherit from <code>Sampler</code> and implement the <code>sample(n: int) -&gt; torch.Tensor</code> method.</p>"},{"location":"user-guide/solvers/","title":"Solvers","text":"<p>Documentation in Progress</p> <p>This page is under construction.</p>"},{"location":"user-guide/solvers/#overview","title":"Overview","text":"<p>Solvers integrate the ODE system from initial conditions.</p>"},{"location":"user-guide/solvers/#solver-protocol","title":"Solver Protocol","text":"<p>All solvers implement:</p> <ul> <li>Method: <code>integrate(ode_system, initial_conditions) -&gt; (t, y)</code></li> <li>Property: <code>device</code></li> </ul>"},{"location":"user-guide/solvers/#available-solvers","title":"Available Solvers","text":"Class Backend GPU Support Event Functions Recommended For <code>JaxSolver</code> JAX/Diffrax \u2705 CUDA \u2705 Yes Default for performance <code>TorchDiffEqSolver</code> torchdiffeq \u2705 CUDA \u274c Batch limitation PyTorch ecosystems <code>TorchOdeSolver</code> torchode \u2705 CUDA \u274c No Alternative PyTorch <code>SklearnParallelSolver</code> scipy/sklearn \u274c CPU only \u274c No Debugging, reference"},{"location":"user-guide/solvers/#jaxsolver-recommended","title":"JaxSolver (Recommended)","text":"<pre><code>from pybasin.solvers.jax_solver import JaxSolver\n\nsolver = JaxSolver(\n    device=\"cuda\",\n    t_span=(0.0, 1000.0),\n    n_steps=1000,\n    method=\"Dopri5\",  # or \"Tsit5\"\n    rtol=1e-8,\n    atol=1e-6,\n    event_fn=my_stop_event,  # Optional: stop unbounded\n)\n</code></pre>"},{"location":"user-guide/solvers/#event-functions-for-unbounded-detection","title":"Event Functions for Unbounded Detection","text":"<pre><code>import jax.numpy as jnp\n\ndef stop_event(t, y, args):\n    \"\"\"Stop when |y| &gt; 200.\"\"\"\n    return 200.0 - jnp.max(jnp.abs(y))\n</code></pre>"},{"location":"user-guide/solvers/#torchdiffeqsolver","title":"TorchDiffEqSolver","text":"<pre><code>from pybasin.solver import TorchDiffEqSolver\n\nsolver = TorchDiffEqSolver(\n    device=\"cuda\",\n    t_span=(0.0, 1000.0),\n    method=\"dopri5\",\n)\n</code></pre>"},{"location":"user-guide/solvers/#performance-comparison","title":"Performance Comparison","text":"<p>See the Solver Comparison benchmark for detailed performance data.</p>"}]}